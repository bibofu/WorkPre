# 项目：

## 1：SpringCloud的几大组件

![](https://pic.imgdb.cn/item/6230319c5baa1a80ab419bf9.png)



### nacos

```properties
# nacos服务地址
spring.cloud.nacos.discovery.server-addr=47.106.211.174:8848

#开启熔断机制
feign.hystrix.enabled=true
# 设置hystrix超时时间，默认1000ms
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=6000
```

使用nacos作为服务注册中心



### feign

```java
@FeignClient(name="service-ucenter",fallback = UcenterClientFallback.class)
@Component
public interface UcenterClient {
    //根据用户id获取用户登录信息
    @GetMapping("/ucenter/member/getCommentInfo/{id}")
    public LoginInfoVo getUcenterInfo(@PathVariable("id") String id);
}
```



### hystrix

熔断器，远程调用超时fallback

```java
@Component
public class OrdersClientFallback implements OrdersClient{
    @Override
    public boolean isBuyCourse(String courseId, String memberId) {
        return false;
    }

    @Override
    public List<String> findCourse(String memberId) {
        return null;
    }
}
```



启动类

```java
@SpringBootApplication
@EnableDiscoveryClient //服务注册
@EnableFeignClients //服务调用
@ComponentScan(basePackages = {"com.cqu"})
public class EduApplication {
    public static void main(String[] args) {
        SpringApplication.run(EduApplication.class,args);
    }
}
```



### nacos作为配置中心

在分布式系统中动态配置中，可以避免重复重启服务，动态更改服务参数等。 Nacos作为Spring 推荐的分布式调度系统其也具备配置中心的功能， 我们也可以利用其作为配置中心，其client端主动定时发起与配置中心同步机制，实现动态配置的的更新。

### 负载均衡Ribbon



### 网关Spring Gateway(zuul)



## 2：项目数据库设计



## 3：项目功能模块



## 4：项目难点及解决方案

# 算法：

## LRU LFU实现

```java
package cache;

import java.util.HashMap;
import java.util.Map;

/**
 * @author fubibo
 * @create 2021-03-31 21:21
 */
public class LRUCache {
    class Node{
        int key;
        int value;
        Node prev;
        Node next;
        public Node(int k,int v){
            key=k;
            value=v;
        }

    }
    Node head;
    Node tail;
    Map<Integer,Node> map;
    int size;
    int capacity;

    public LRUCache(int capacity){
        head=new Node(0,0);
        tail=new Node(0,0);
        head.next=tail;
        tail.prev=head;
        map=new HashMap<>();
        size=0;
        this.capacity=capacity;
    }

    public int get(int key){
        if(!map.containsKey(key)){
            return -1;
        }else{
            Node node=map.get(key);
            remove(key);
            addHead(key,node.value);
            return node.value;
        }
    }

    public void put(int key,int value){
        if (map.containsKey(key)){
            remove(key);
            addHead(key,value);
        }else{
            addHead(key,value);
        }
    }

    private void remove(int key){
        Node cur=map.get(key);
        Node next=cur.next;
        Node prev=cur.prev;
        prev.next=next;
        next.prev=prev;
        size--;
        map.remove(key);

    }

    private void addHead(int key,int value){
        Node node=new Node(key,value);
        Node next=head.next;
        head.next=node;
        node.next=next;
        next.prev=node;
        node.prev=head;
        size++;
        map.put(key,node);

        if(size>capacity){
            Node preTail=tail.prev;
            remove(preTail.key);
        }

    }



}

```

## 生产者消费者

## 线程顺序执行

## 1、排序

1：快排

```java
/**
 * 快排递归写法
 */
public class QuickSort {
    public static void main(String[] args) {
        int[] test={4,2,3,5,1,9,8,6,7};
        int[] quick = quick(test, 0, test.length - 1);
        for (int i:quick){
            System.out.print(i+" ");
        }

    }

    public static int[] quick(int[] arr,int left,int right){
        if (left<right){
            int mid=partition(arr,left,right);
            arr=quick(arr,left,mid-1);
            arr=quick(arr,mid+1,right);
        }
        return arr;

    }

    private static int partition(int[] arr, int left, int right) {
        int pivot=arr[left];
        int start=left;
        while (left<right){
            while (left<right&&arr[right]>=pivot){
                right--;
            }

            while (left<right&&arr[left]<=pivot){
                left++;
            }

            if (left>=right){
                break;
            }

            swap(arr,left,right);
        }

        swap(arr,start,left);
        return left;

    }

    private static void swap(int[] arr, int left, int right) {
        int temp=arr[left];
        arr[left]=arr[right];
        arr[right]=temp;
    }

}
```



```java
/**
 * 快排非递归
 */
public class QuickSort2 {
    public static void main(String[] args) {
        int[] test={4,2,3,5,1,9,8,6,7};
        int[] quickSort2 = quickSort2(test);
        for (int i:quickSort2){
            System.out.print(i+" ");
        }

    }

    public static int[] quickSort2(int[] arr){
        Stack<Integer> stack=new Stack<>();
        stack.push(arr.length-1);
        stack.push(0);
        while (!stack.isEmpty()){
            int low=stack.pop();
            int height=stack.pop();

            if (low<height){
                int index=partition(arr,low,height);
                stack.push(index-1);
                stack.push(low);
                stack.push(height);
                stack.push(index+1);
            }
        }
        return arr;
    }

    private static int partition(int[] arr, int left, int right) {
        int pivot=arr[left];
        int start=left;
        while (left<right){
            while (left<right&&arr[right]>=pivot){
                right--;
            }

            while (left<right&&arr[left]<=pivot){
                left++;
            }

            if (left>=right){
                break;
            }

            swap(arr,left,right);
        }

        swap(arr,start,left);
        return left;

    }

    private static void swap(int[] arr, int left, int right) {
        int temp=arr[left];
        arr[left]=arr[right];
        arr[right]=temp;
    }
}
```



2：归并排序

```java
public static int[] sort(int[] arr){
    int[] temp=new int[arr.length];
    sort(arr,0,arr.length-1,temp);
    return arr;
}

private static void sort(int[] arr, int left, int right, int[] temp) {
    if (left<right){
        int mid=(left+right)/2;
        sort(arr,left,mid,temp);
        sort(arr,mid+1,right,temp);
        merge(arr,left,mid,right,temp);

    }

}

private static void merge(int[] arr, int left, int mid, int right, int[] temp) {
    int i=left;
    int j=mid+1;
    int t=0;
    while (i<=mid&&j<=right){
        if (arr[i]<arr[j]){
            temp[t]=arr[i];
            i++;
            t++;
        }else {
            temp[t]=arr[j];
            j++;
            t++;
        }

    }

    while (i<=mid){
        temp[t]=arr[i];
        i++;
        t++;
    }

    while (j<=right){
        temp[t]=arr[j];
        j++;
        t++;
    }

    t=0;
    while (left<=right){
        arr[left]=temp[t];
        left++;
        t++;
    }
}
```

3：逆序对

```java
public static int[] sort(int[] arr){
    int[] temp=new int[arr.length];
    sort(arr,0,arr.length-1,temp);
    return arr;
}

private static void sort(int[] arr, int left, int right, int[] temp) {
    if (left<right){
        int mid=(left+right)/2;
        sort(arr,left,mid,temp);
        sort(arr,mid+1,right,temp);
        merge(arr,left,mid,right,temp);

    }

}

private static void merge(int[] arr, int left, int mid, int right, int[] temp) {
    int i=left;
    int j=mid+1;
    int t=0;
    while (i<=mid&&j<=right){
        if (arr[i]<arr[j]){
            temp[t]=arr[i];
            i++;
            t++;
        }else {
            temp[t]=arr[j];
            j++;
            t++;
            /**
            加入这一行
            */
            count+=mid-i+1;
        }

    }

    while (i<=mid){
        temp[t]=arr[i];
        i++;
        t++;
    }

    while (j<=right){
        temp[t]=arr[j];
        j++;
        t++;
    }

    t=0;
    while (left<=right){
        arr[left]=temp[t];
        left++;
        t++;
    }
}
```

4：堆排序

```java
/**
 * 创建堆，
 * @param arr 待排序列
 */
private static void heapSort(int[] arr) {
    //创建堆
    for (int i = (arr.length - 1) / 2; i >= 0; i--) {
        //从第一个非叶子结点从下至上，从右至左调整结构
        adjustHeap(arr, i, arr.length);
    }

    //调整堆结构+交换堆顶元素与末尾元素
    for (int i = arr.length - 1; i > 0; i--) {
        //将堆顶元素与末尾元素进行交换
        int temp = arr[i];
        arr[i] = arr[0];
        arr[0] = temp;

        //重新对堆进行调整
        adjustHeap(arr, 0, i);
    }

}

/**
 * 调整堆
 * @param arr 待排序列
 * @param parent 父节点
 * @param length 待排序列尾元素索引
 */
private static void adjustHeap(int[] arr, int parent, int length) {
    //将temp作为父节点
    int temp = arr[parent];
    //左孩子
    int lChild = 2 * parent + 1;

    while (lChild < length) {
        //右孩子
        int rChild = lChild + 1;
        // 如果有右孩子结点，并且右孩子结点的值大于左孩子结点，则选取右孩子结点
        if (rChild < length && arr[lChild] < arr[rChild]) {
            lChild++;
        }

        // 如果父结点的值已经大于孩子结点的值，则直接结束
        if (temp >= arr[lChild]) {
            break;
        }

        // 把孩子结点的值赋给父结点
        arr[parent] = arr[lChild];

        //选取孩子结点的左孩子结点,继续向下筛选
        parent = lChild;
        lChild = 2 * lChild + 1;
    }
    arr[parent] = temp;
}
```

5：topk



## 2、链表

1：链表反转

2：链表公共节点

3：链表环入口

4：链表反转2

5：有序链表合并

6：链表倒数第k个节点

```java
public static listNode daoshukNode(listNode head,int k){
    if (k<=0){
        return null;
    }
    listNode fast=head;
    listNode slow=head;

    for (int i = 1; i < k; i++) {
        fast=fast.next;

    }
    while (fast.next!=null){
        fast=fast.next;
        slow=slow.next;
    }
    return slow;
}
```

6：二叉树遍历

7：二叉树层序遍历

8：二叉树之字遍历

9：二叉树左视图

10：二叉树路径和

11：前序和中序重建二叉树

12：二叉树镜像

13：二叉树最低公共父节点

14：BST最低公共父节点

15：数组转BST

## 3、数组

1：有序数组中位数

2：两数之和

3：三数之和

4：矩阵顺时针打印

5：股票买卖1

```java
public class GuPiao1 {
    public static void main(String[] args) {

    }
    public static int maxProfit(int[] prices) {

        int minPrice=prices[0];
        int maxProfit=0;
        for(int i:prices){
            if(i<minPrice){
                minPrice=i;
            }
            if(i-minPrice>maxProfit){
                maxProfit=i-minPrice;
            }
        }

        return maxProfit;

    }
}
```

## 4、动态规划

1：爬楼梯

2：打家劫舍

```java
/**
 * LeetCode 198 获取数组中不相邻元素的最大和，打家劫舍
 */
public class Q1 {
    public static void main(String[] args) {
        int[] test={5,2,6,3,1,7}; //567
        System.out.println(getMax(test));

    }

    public static int getMax(int[] nums){
        if (nums.length==0){
            return 0;
        }

        if (nums.length==1){
            return nums[0];
        }
        int[] dp=new int[nums.length];
        dp[0]=nums[0];
        dp[1]= Math.max(nums[0],nums[1]);
        for (int i=2;i<nums.length;i++){
            dp[i]=Math.max(dp[i-2]+nums[i],dp[i-1]);
        }

        return dp[nums.length-1];
    }
}
```

3：最大字段和

```java
/**
 * LeetCode 53
 * 给定一个数组，求这个数组的连续子数组中，最大那一段的和
 */
public class Q2 {
    public static void main(String[] args) {
        int[] res={2,-3,1,6,5,-4};//1 6 5
        System.out.println(getMaxSon(res));

    }

    public static int getMaxSon(int[] nums){
        if (nums.length==0){
            return 0;
        }

        int[] dp=new int[nums.length];
        dp[0]=nums[0];
        int max_res=nums[0];
        for (int i = 1; i < nums.length; i++) {
            dp[i]=Math.max(dp[i-1]+nums[i],nums[i]);

            if (dp[i]>max_res){
                max_res=dp[i];
            }
        }
        return max_res;

    }

}
```

4：最长上升子序列

```java
public class LongestUp {
    public static void main(String[] args) {

        int[] test={1,3,2,3,1,4};

        System.out.println(getLongest(test));


    }

    public static int getLongest(int[] nums){
       if (nums==null||nums.length==0){
           return 0;
       }
       int[] dp=new int[nums.length];
       int MAX=1;
       dp[0]=1;
       for (int i=1;i<nums.length;i++){
           dp[i]=1;
           for (int j=0;j<i;j++){
               if (nums[j]<nums[i]&&dp[i]<dp[j]+1){
                   dp[i]=dp[j]+1;
               }
           }
           if (dp[i]>MAX){
               MAX=dp[i];
           }
       }

       return MAX;
    }
}
```

5：找零钱



## 5、字符串

1：最长回文串

```java
/**
 * 最长回文子串 动态规划
 */
public class HuiWenMax {
    public static void main(String[] args) {

        String s="cabbaeeaf";

        String maxSon = getMaxSon(s);
        System.out.println(maxSon);

    }

    public static String getMaxSon(String s){
        char[] chars = s.toCharArray();

        int length=chars.length;

        //dp[j][i]表示j到i的子串是否是回文串
        boolean[][] dp=new boolean[length][length];

        //记录最长回文子串
        int maxlen=1;

        int start=0;

        for (int i=0;i<length;i++){
            for (int j=0;j<=i;j++){
                if (i-j<2){
                    dp[j][i]=chars[i]==chars[j];
                }else {
                    dp[j][i]=dp[j+1][i-1]&&chars[j]==chars[i];
                }

                if (dp[j][i]&&(i-j+1)>maxlen){
                    maxlen=i-j+1;
                    start=j;
                }
            }

        }

        return s.substring(start,start+maxlen);

    }




}
```

2：最长无重复连续子串

```java
/**
 * 给定一个字符串，请你找出其中不含有重复字符的 **最长子串** 的长度。
 * 滑动窗口
 */
public class ANS_3 {
    public static void main(String[] args) {
        String test="abcabcbb";
        System.out.println(lengthOfLongestSubstring(test));

    }

    public static int lengthOfLongestSubstring(String s){
        int[] freq=new int[256];
        Arrays.fill(freq,0);
        int left=0,right=-1;
        int res=0;
        while(left<s.length()){
            if((right+1)<s.length()&&freq[s.charAt(right+1)]==0){
                right++;
                freq[s.charAt(right)]++;

            }else{
                freq[s.charAt(left)]--;
                left++;
            }
//            res=max(res,r-l+1);
            res= Math.max(res, right - left + 1);
        }
        return res;
    }
}
```

3：最长相同子串

4：字符串相加

```java
/**
 * 字符串相加
 */
public class StringAdd {
    public static void main(String[] args) {

        String s1="242352";
        String s2="392344";
        System.out.println(stringAdd(s1,s2));


    }

    public static String stringAdd(String s1,String s2){
        char[] chars1 = s1.toCharArray();
        char[] chars2 = s2.toCharArray();
        int carry=0;
        int length1=chars1.length;
        int length2=chars2.length;

        StringBuilder sb=new StringBuilder();

        while (length1>0||length2>0||carry>0){
            int temp=carry;
            if (length1>0){
                length1--;
                temp=temp+(chars1[length1]-'0');
            }

            if (length2>0){
                length2--;
                temp=temp+(chars2[length2]-'0');
            }

            carry=temp/10;

            sb.append(temp%10);

        }

        return sb.reverse().toString();
    }
}
```



5：字符串转整数

```java
public class StringToInt {
    public static void main(String[] args) {

    }

    public static int String2Int(String s){
        if (s==null){
            return 0;
        }

        String str=s.trim();
        if (str.isEmpty()){
            return 0;
        }
        int index=0;
        int sign=1;
        char first=str.charAt(index);
        if (first=='+'){

            index++;
        }else if (first=='-'){
            sign=-1;
            index++;
        }else if (!Character.isDigit(first)){
            return 0;
        }

        long num=0;
        long res=0;
        while (index<str.length()&&Character.isDigit(str.charAt(index))){
            num=num*10+Integer.parseInt(String.valueOf(str.charAt(index)));
            res=sign*num;
            if (res>Integer.MAX_VALUE){
                return Integer.MAX_VALUE;
            }

            if (res<Integer.MIN_VALUE){
                return Integer.MIN_VALUE;
            }
            index++;
        }



        return (int)res;
    }

}
```





## 6、递归回溯

1：全排列

```java
public class AllPailie {
    public static void main(String[] args) {

        int[] nums={1,2,3,4};
        List<List<Integer>> lists = allPai(nums);
        System.out.println(lists);

    }


    public  static List<List<Integer>> allPai(int[] nums){

        if (nums==null||nums.length==0){
            return null;
        }

        List<List<Integer>> res=new ArrayList<>();
        List<Integer> cur=new ArrayList<>();
        dfs(nums,cur,res);

        return res;

    }

    private static void dfs(int[] nums, List<Integer> cur,List<List<Integer>> res) {
        if (nums.length==cur.size()){
            res.add(new ArrayList<>(cur));
            return;
        }
        for (int i=0;i<nums.length;i++){
            if (cur.contains(nums[i])){
                continue;
            }
            cur.add(nums[i]);
            dfs(nums,cur,res);
            cur.remove(cur.size()-1);
        }
    }


}
```



## 7、dfs bfs

1：岛屿数量

```java
/**
 * 岛屿数量
 */
public class IslandNum {
    public static void main(String[] args) {

    }
    int n;
    int m;
    public int islandNum(char[][] grid){
         n=grid.length;
         m=grid[0].length;
         int res=0;
         for (int i=0;i<n;i++){
             for (int j=0;j<m;j++){
                 if (grid[i][j]=='1'){
                     res++;
                     dfs(grid,i,j);
                 }
             }
         }
         return res;
    }

    private void dfs(char[][] grid, int i, int j) {
        if (i<0||j<0||i>n||j>m||grid[i][j]=='0'){
            return;
        }
        grid[i][j]='0';
        dfs(grid,i-1,j);
        dfs(grid,i+1,j);
        dfs(grid,i,j-1);
        dfs(grid,i,j+1);
    }
}
```







## 8、位运算

1：二进制中1出现次数

```java
/**
 * 二进制数1出现次数
 */
public class OneTime {
    public static void main(String[] args) {
        System.out.println(getOne(5));

        System.out.println(getOne(10));

    }
    public static int getOne(int n){
        if (n==0){
            return 0;
        }
        int count=0;
        while (n!=0){
            count++;
            n=n&(n-1);
        }

        return count;
    }
}
```









## 9、队列和栈

1：有效括号leetcode20

```java
public class ValidKuoHao {
    public static void main(String[] args) {

    }

    public boolean valid(String s){
        if (s==null||s.length()==0||s.length()==1){
            return false;
        }

        Stack<Character> stack=new Stack<>();

        for (char c:s.toCharArray()){
            if (c=='{'){
                stack.push('}');
            }else if (c=='('){
                stack.push(')');
            }else if (c=='['){
                stack.push(']');
            }else {
                if (stack.isEmpty()){
                    return false;
                }

                if (stack.pop()!=c){
                    return false;
                }
            }
        }
        return stack.isEmpty();
    }

}
```



# 计算机系统



## 1：局部性原理

局部性通常有两种不同的形式，时间局部性和空间局部性。在一个具有良好时间局部性的程序中，被引用过一次的内存位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置

# java基础：

## 1：equals方法和"=="的区别

浮点型：float(4 byte), double(8 byte)

整型：byte(1 byte), short(2 byte), int(4 byte) , long(8 byte)

字符型: char(2 byte)

布尔型: boolean(JVM规范没有明确规定其所占的空间大小，仅规定其只能够取字面值"true"和"false")

https://www.cnblogs.com/dolphin0520/p/3592500.html

== 是比较内存地址是否相同，equals 是比较内存地址上面的值是否相同



## 2：常见集合框架

![](https://pic.imgdb.cn/item/622b31f05baa1a80abfb8820.png)

## 3：ArrayList，LinkedList，Vector

ArrayList：

ArrayList 底层基于数组实现容量大小动态可变。 默认容量为10，扩容机制为首先扩容为原始容量的 1.5 倍。如果1.5倍太小的话，则将我们所需的容量大小赋值给 newCapacity，如果1.5倍太大或者我们需要的容量太大，那就直接拿 `newCapacity = (minCapacity > MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE` 来扩容。 扩容之后是通过数组的拷贝来确保元素的准确性的，所以尽可能减少扩容操作。 ArrayList 的最大存储能力：Integer.MAX_VALUE。 size 为集合中存储的元素的个数。elementData.length 为数组长度，表示最多可以存储多少个元素。 如果需要边遍历边 remove ，必须使用 iterator。且 remove 之前必须先 next，next 之后只能用一次 remove。



扩容：

![](https://pic.imgdb.cn/item/622b32385baa1a80abfbb302.png)



获取newCapacity后再对newCapacity的大小进行判断，如果仍然小于minCapacity，则直接让newCapacity 等于minCapacity，而不再计算1.5倍的扩容。然后还要再进行一步判断，即判断当前新容量是否超过最大的容量 if (newCapacity - MAX_ARRAY_SIZE > 0)，如果超过，则调用hugeCapacity方法，传进去的是minCapacity，即新增元素后需要的最小容量：



遍历删除：

![](https://pic.imgdb.cn/item/622b326f5baa1a80abfbe1db.png)



ArrayList线程不安全，解决方案

1 vector   也是基于数组，方法都加上了synchronized，降低了效率

2、使用Collections.synchronziedList(new ArrayLIst<>());

3、使用CopyOnWriteArrayList



 因为Array是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的，可以直接返回数组中index位置的元素，因此在随机访问集合元素上有较好的性能。Array获取数据的时间复杂度是O(1),但是要插入、删除数据却是开销很大的，因为这需要移动数组中插入位置之后的的所有元素。相对于ArrayList，LinkedList的随机访问集合元素时性能较差，因为需要在双向列表中找到要index的位置，再返回






## 4：HashMap，TreeMap

https://tech.meituan.com/2016/06/24/java-hashmap.html

简介：

Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示：

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/f7fe16a2.png)

下面针对各个实现类的特点做一些说明：

(1) **HashMap**：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的**键为null**，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。

(2) **Hashtable**：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且**是线程安全的**，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。

(3) **LinkedHashMap**：LinkedHashMap是HashMap的一个子类，**保存了记录的插入顺序**，在用Iterator遍历LinkedHashMap时，**先得到的记录肯定是先插入的**，也可以在构造时带参数，按照访问次序排序。

(4) **TreeMap**：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。

对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。

通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。

内部实现

搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。

存储结构-字段

从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。



![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/e4a19398.png)



这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么优点呢？

(1) 从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。



![](https://pic.imgdb.cn/item/622b33585baa1a80abfc9241.png)



Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。

(2) HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用**开放地址法和链地址法**等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码：

![](https://pic.imgdb.cn/item/622b33b15baa1a80abfccbb1.png)

系统将调用”美团”这个key的hashCode()方法得到其hashCode 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。

如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是**好的Hash算法和扩容机制。**

在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：

![](https://pic.imgdb.cn/item/622b33f45baa1a80abfcf8ed.png)



首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。

结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。

size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。

在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考[这篇文章](http://blog.csdn.net/liuqiyao_01/article/details/14475159)，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。

这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考[这篇文章](http://blog.csdn.net/v_july_v/article/details/6105630)。



功能实现-方法

HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。

1. 确定哈希桶数组索引位置

不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):

![](https://pic.imgdb.cn/item/622b348f5baa1a80abfd5c0b.png)



这里的Hash算法本质上就是三步：**取key的hashCode值、高位运算、取模运算**。

对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。

这个方法非常巧妙，它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。

在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。

下面举例说明下，n为table的长度。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/45205ec2.png)

2. 分析HashMap的put方法

HashMap的put方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/d669d29c.png)



①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； ②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； ③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； ④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； ⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； ⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

JDK1.8HashMap的put方法源码如下:

![](https://pic.imgdb.cn/item/622b35a65baa1a80abfe17df.png)

3. 扩容机制

扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。

我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。

![](https://pic.imgdb.cn/item/622b35dc5baa1a80abfe4327.png)



这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。

![](https://pic.imgdb.cn/item/622b360e5baa1a80abfe64da.png)



newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。

下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/b2330062.png)



下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/4d8022db.png)



元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/d773f86e.png)



因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图：

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/3cc9813a.png)

这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下:

线程安全性

在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。那么为什么说HashMap是线程不安全的，下面举例子说明在并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)：

![](https://pic.imgdb.cn/item/622b36915baa1a80abfebdd0.png)



其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。

通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/7df99266.png)





注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。

线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/6c8d086a.png)





e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/6eed9aaf.png)



于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。



小结

1. 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。
2. 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。
3. HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。
4. JDK1.8引入红黑树大程度优化了HashMap的性能。
5. 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。



TreeMap：底层基于红黑树



## 5：hashcode

String 获取hashcode

![](https://pic.imgdb.cn/item/622b38345baa1a80abffc352.png)



Integer获取hashcode

![](https://pic.imgdb.cn/item/622b38545baa1a80abffd8a1.png)



Object获取hashcode





## 6：set

hashset：基于hashmap，不允许有重复元素

treeset：排好序



## 7：反射





## 8：序列化和反序列化

**把对象转换为字节序列的过程称为对象的序列化**。

**把字节序列恢复为对象的过程称为对象的反序列化**。

对象的序列化主要有两种用途：

1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中；

2） 在网络上传送对象的字节序列。



## 9：一维数组和二维数组

多维数组按“行优先”规则在内存中存放，即从行下标为0的那一行开始，存放完一行紧接着存放下一行，直到整个数组存放完毕。所以从内存结构看，所有的数组都是一维数组！



## 10：基本数据类型和包装类

1、包装类是对象，拥有方法和字段，对象的调用都是通过引用对象的地址；基本类型不是 
2、包装类型是引用的传递；基本类型是值的传递 
3、声明方式不同：
                基本数据类型不需要new关键字；
                包装类型需要new在堆内存中进行new来分配内存空间 
4、存储位置不同：
                基本数据类型直接将值保存在值栈中；
                包装类型是把对象放在堆中，然后通过对象的引用来调用他们 
5、初始值不同：
                int的初始值为 0 、 boolean的初始值为false 
                包装类型的初始值为null 
6、使用方式不同：
                基本数据类型直接赋值使用就好；
                包装类型是在集合如 coolectionMap时使用

## 11：值传递和引用传递

- 一个方法不能修改一个基本数据类型的参数（数值型和布尔型）。
- 一个方法可以修改一个引用所指向的对象状态，但这仍然是按值调用而非引用调用。



## 12：泛型

泛型” 意味着编写的代码可以被不同类型的对象所重用。泛型的提出是为了编写重用性更好的代码。泛型的本质是***\*参数化类型\****，也就是说所操作的***\*数据类型\****被指定为一个***\*参数\****。



> 在性能上不如数组快。
>





## 13：抽象类和接口





## 14：Java的随机数

```java
Random random=new Random();
int j=random.nextInt(i);
j是i以内(小于i)的随机数
```





## 15：类型转换

char 转 int

```java
char c='a';
int a=c-'0';
```

int 转 char

```java
int a=50;
char c=(char)(a+'0');
```



## 16：位运算相关

```java
Integer.bitCount(n) 返回n的二进制有几位
```



## 17：final和static



# 计算机网络：

## 1：TCP 3次握手4次挥手

序号：表示发送的数据字节流，确保TCP传输有序，对每个字节编号

确认序号：发送方期待接收的下一序列号，接收成功后的数据字节序列号加 1。只有ACK=1时才有效。

ACK：确认序号的标志，ACK=1表示确认号有效，ACK=0表示报文不含确认序号信息

SYN：连接请求序号标志，用于建立连接，SYN=1表示请求连接

FIN：结束标志，用于释放连接，为1表示关闭本方数据流



1）3次握手

建立TCP连接时，需要客户端和服务器共发送3个包。

- 第一次：客户端发送初始序号x和syn=1请求标志
- 第二次：服务器发送请求标志syn，发送确认标志ACK，发送自己的序号seq=y，发送客户端的确认序号ack=x+1
- 第三次：客户端发送ACK确认号，发送自己的序号seq=x+1，发送对方的确认号ack=y+1

![img](https://img2018.cnblogs.com/blog/1344250/201904/1344250-20190402114137828-2119548758.png)





- 第一次：客户端发送请求到服务器，服务器知道客户端发送，自己接收正常。SYN=1,seq=x
- 第二次：服务器发给客户端，客户端知道自己发送、接收正常，服务器接收、发送正常。ACK=1,ack=x+1,SYN=1,seq=y
- 第三次：客户端发给服务器：服务器知道客户端发送，接收正常，自己接收，发送也正常.seq=x+1,ACK=1,ack=y+1

### SYN泛洪攻击

服务器为了响应一个收到的SYN,分配并初始化连接变量和缓存。然后服务器发送一个SYNACK进行响应，并等待来自客户的ACK报文段。如果某客户不发送ACK来完成该三次握手的第三步，最终（通常在一分多钟之后）服务器将终止该半开连接并回收资源。这种TCP连接管理协议为经典的DoS攻击即SYN洪泛攻击

解决方法：SYN Cookie







2）4次挥手

![](https://pic.imgdb.cn/item/6229aac75baa1a80ab04c2a6.png)

- 第一次挥手：客户端发出释放FIN=1，自己序列号seq=u，进入FIN-WAIT-1状态
- 第二次挥手：服务器收到客户端的后，发出ACK=1确认标志和客户端的确认号ack=u+1，自己的序列号seq=v，进入CLOSE-WAIT状态
- 第三次挥手：客户端收到服务器确认结果后，进入FIN-WAIT-2状态。此时服务器发送释放FIN=1信号，确认标志ACK=1，确认序号ack=u+1，自己序号seq=w，服务器进入LAST-ACK（最后确认态）
- 第四次挥手：客户端收到回复后，发送确认ACK=1，ack=w+1，自己的seq=u+1，客户端进入TIME-WAIT（时间等待）。客户端经过2个最长报文段寿命后，客户端CLOSE；服务器收到确认后，立刻进入CLOSE状态。



客户TCP开始时处于CLOSED （关闭）状态。 客户的应用程序发起一个新的TCP连接。这引起客户中的TCP向服务器中的TCP发送一个SYN报文段。在发送过SYN报文段后，客户TCP进入了 SYN_SENT状态。当客户TCP处在SYN_SENT状态时，它等待来自服务器TCP的对客户所发报文段进行确认且SYN比特被置为1的一个报文段。收到这样一个报文段之后，客户TCP进入ESTABLISHED （已建立）状态。当处在ESTABLISHED状态时，TCP客户就能发送和接收包含有效载荷数据（即应用层产生的数据）的TCP报文段了。

![](https://pic.imgdb.cn/item/6229ab825baa1a80ab0552be.png)

假设客户应用程序决定要关闭该连接。（注意到服务器也能选择关闭该连接。）这引起客户TCP发送一个带有FIN比特被置为1的TCP报文段，并进入FIN_WAIT_1状态。当处在FIN_WAIT_1状态时，客户TCP等待一个来自服务器的带有确认的TCP报文段。当它收到该报文段时，客户TCP进入FIN_WAIT_2状态。当处在FIN_WAIT_2状态时，客户等待来自服务器的FIN比特被置为1的另一个报文段；当收到该报文段后，客户TCP对服务器的报文段进行确认，并进入TIME_WAIT状态。假定ACK丢失，TIME_WAIT状态使TCP客户重传最后的确认报文。在TIME.WAIT状态中所消耗的时间是与具体实现有关的，而典型的值是30秒、1分钟或2分钟。 经过等待后，连接就正式关闭，客户端所有资源（包括端口号）将被释放。

- 第一次：客户端请求断开FIN,seq=u
- 第二次：服务器确认客户端的断开请求ACK,ack=u+1,seq=v
- 第三次：服务器请求断开FIN,seq=w,ACK,ack=u+1
- 第四次：客户端确认服务器的断开ACK,ack=w+1,seq=u+1

![](https://pic.imgdb.cn/item/6229ad6c5baa1a80ab069067.png)

3）补充

 1）为什么三次握手和四次挥手？

- 三次握手时，服务器同时把ACK和SYN放在一起发送到了客户端那里
- 四次挥手时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方 ACK 和 FIN 一般都会分开发送。

2）为什么客户端最后还要等待2MSL？

- 客户端需要保证最后一次发送的ACK报文到服务器，如果服务器未收到，可以请求客户端重发，这样客户端还有时间再发，重启2MSL计时。

**MSL** : Max segment lifetime ，报文最大生存时间，是指任何报文在网络上存在的最长时间，超过这个时间报文将会被丢弃。在 Linux 系统中，MSL 被定义成 30 秒， 2MSL 就是 60 秒。

### CLOSE-WAIT 状态问题：

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送FIN 连接释放报文。

### TIME-WAIT 状态问题：

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。

等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一 个新的连接不会出现旧的连接请求报文。

通信双方建立TCP连接后，主动关闭连接的一方就会进入TIME_WAIT状态。



#### 大量的time-wait是什么原因

time-wait是正常的状态。http短连接请求非常多，可能造成time-wait状态的累积



## 2：TCP拥塞控制

在某段时间，若**对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏**，这种情况就叫做**网络拥塞**。

在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。

若**出现拥塞而不进行控制**，整个网络的**吞吐量将随输入负荷的增大而下降**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731190238241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。
TCP的四种拥塞控制算法
1.慢开始（指数增长）
2.拥塞控制（线性增长）
3.快重传
4.快恢复
假定：
1.数据是单方向传送，而另一个方向只传送确认
2.接收方总是有足够大的缓存空间，因而发送发发送窗口的大小由网络的拥塞程度来决定
3.以TCP报文段的个数为讨论问题的单位，而不是以字节为单位
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731155254165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)



示例如下：
传输轮次：发送方给接收方发送数据报文段后，接收方给发送方发回相应的确认报文段，一个传输轮次所经历的时间就是往返时间RTT(RTT并非是恒定的数值），使用传输轮次是为了强调，把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个报文段的确认，拥塞窗口cwnd会随着网络拥塞程度以及所使用的拥塞控制算法动态变化。

在tcp双方建立逻辑链接关系时， 拥塞窗口cwnd的值被设置为1，还需设置慢开始门限ssthresh,在执行慢开始算法时，发送方每收到一个对新报文段的确认时，就把拥塞窗口cwnd的值加一，然后开始下一轮的传输，当拥塞窗口cwnd增长到慢开始门限值时，就使用拥塞避免算法。

慢开始：
假设当前发送方拥塞窗口cwnd的值为1，而发送窗口swnd等于拥塞窗口cwnd，因此发送方当前只能发送一个数据报文段（拥塞窗口cwnd的值是几，就能发送几个数据报文段），接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为2，

发送方此时可以连续发送两个数据报文段，接收方收到该数据报文段后，给发送方一次发回2个确认报文段，发送方收到这两个确认报文后，将拥塞窗口的值加2变为4，发送方此时可连续发送4个报文段，接收方收到4个报文段后，给发送方依次回复4个确认报文，发送方收到确认报文后，将拥塞窗口加4，置为8，发送方此时可以连续发送8个数据报文段，接收方收到该8个数据报文段后，给发送方一次发回8个确认报文段，发送方收到这8个确认报文后，将拥塞窗口的值加8变为16，

当前的拥塞窗口cwnd的值已经等于慢开始门限值，之后改用拥塞避免算法。

拥塞避免：
也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长。同理，16+1……直至到达24，假设24个报文段在传输过程中丢失4个，接收方只收到20个报文段，给发送方依次回复20个确认报文段，一段时间后，丢失的4个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改cwnd和ssthresh.并重新开始慢开始算法，如图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731165743903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)



![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731165605396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)



快速重传：
发送方发送1号数据报文段，接收方收到1号报文段后给发送方发回对1号报文段的确认，在1号报文段到达发送方之前，发送方还可以将发送窗口内的2号数据报文段发送出去，接收方收到2号报文段后给发送方发回对2号报文段的确认，在2号报文段到达发送方之前，发送方还可以将发送窗口内的3号数据报文段发送出去，

假设该报文丢失，发送方便不会发送针对该报文的确认报文给发送方，发送方还可以将发送窗口内的4号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，发送方还可以将发送窗口中的5号报文段发送出去,接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段,，发送方还可以将发送窗口内的最后一个数据段即6号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，

此时，发送方收到了累计3个连续的针对2号报文段的重复确认，立即重传3号报文段，接收方收到后，给发送方发回针对6号报文的确认，表明，序号到6为至的报文都收到了，这样就不会造成发送方对3号报文的超时重传，而是提早收到了重传。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184314574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)



![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184640178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)







![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)





## 3：HTTPS

在 HTTP 协议中有可能存在信息窃听或身份伪装等安全问题。使用HTTPS 通信机制可以有效地防止这些问题。本章我们就了解一下
HTTPS。

### HTTP 的缺点

1.  HTTP 主要有这些不足，例举如下。**通信使用明文**（不加密），内容可能会被窃听
2.  不验证通信方的身份，因此有可能遭遇伪装
3.  无法证明报文的完整性，所以有可能已遭篡改

#### 通信使用明文可能会被窃听

由于 HTTP 本身不具备加密的功能，所以也无法做到对通信整体（使用 HTTP 协议通信的请求和响应的内容）进行加密。即，HTTP 报文
使用明文（指未经过加密的报文）方式发送

![](https://pic.imgdb.cn/item/621632752ab3f51d911dbbdc.png)

![](https://pic.imgdb.cn/item/621632902ab3f51d911dfce0.png)



##### 加密处理防止被窃听

在目前大家正在研究的如何防止窃听保护信息的几种对策中，最为普及的就是加密技术。加密的对象可以有这么几个

==通信的加密==

一种方式就是将通信加密。HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或TLS（Transport Layer Security，安全层传输协议）的组合使用，加密 HTTP 的通信内容。
用 SSL建立安全通信线路之后，就可以在这条线路上进行 HTTP通信了。与 SSL组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。

![](https://pic.imgdb.cn/item/621636cf2ab3f51d9128dab8.png)

==内容的加密==

还有一种将参与通信的内容本身加密的方式。由于 HTTP 协议中没有加密机制，那么就对 HTTP 协议传输的内容本身加密。即把
HTTP 报文里所含的内容进行加密处理。
在这种情况下，客户端需要对 HTTP 报文进行加密处理后再发送请求。

![](https://pic.imgdb.cn/item/621637662ab3f51d912a7152.png)

诚然，为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制。主要应用在 Web 服务中。有一点必须
引起注意，由于该方式不同于 SSL或 TLS 将整个通信线路加密处理，所以内容仍有被篡改的风险。

#### 不验证通信方的身份就可能遭遇伪装

HTTP 协议中的请求和响应不会对通信方进行确认。也就是说存在“服务器是否就是发送请求中 URI 真正指定的主机，返回的响应是否真的返回到实际提出请求的客户端”等类似问题。

##### 任何人都可发起请求

在 HTTP 协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。另外，服务器只要接收到请求，不管对方是
谁都会返回一个响应（但也仅限于发送端的 IP 地址和端口号没有被 Web 服务器设定限制访问的前提下）。

![](https://pic.imgdb.cn/item/62163b0c2ab3f51d9134a201.png)

1.  HTTP 协议的实现本身非常简单，不论是谁发送过来的请求都会返回响应，因此不确认通信方，会存在以下各种隐患
2.  无法确定请求发送至目标的 Web 服务器是否是按真实意图返回响应的那台服务器。有可能是已伪装的 Web 服务器。
3.  无法确定响应返回到的客户端是否是按真实意图接收响应的那个客户端。有可能是已伪装的客户端。
4.  无法确定正在通信的对方是否具备访问权限。因为某些Web 服务器上保存着重要的信息，只想发给特定用户通信的权限。
5.  无法判定请求是来自何方、出自谁手。即使是无意义的请求也会照单全收。
6.  无法阻止海量请求下的 DoS 攻击（Denial of Service，拒绝服务攻击）。

##### 查明对手的证书

虽然使用 HTTP 协议无法确定通信方，但如果使用 SSL则可以。**SSL不仅提供加密处理，而且还使用了一种被称为证书的手段**，可用于确定对方

证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件
事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图

![](https://pic.imgdb.cn/item/62171ac32ab3f51d91b5e5d8.png)

通过使用证书，以证明通信方就是意料中的服务器。这对使用者个人来讲，也减少了个人信息泄露的危险性。另外，客户端持有证书即可完成个人身份的确认，也可用于对Web 网站的认证环节。

#### 无法证明报文完整性，可能已遭篡改

所谓完整性是指信息的准确度。若无法证明其完整性，通常也就意味着无法判断信息是否准确

##### 接收到的内容可能有误

由于 HTTP 协议无法证明通信的报文完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的
内容遭到篡改，也没有办法获悉。
换句话说，没有任何办法确认，发出的请求 / 响应和接收到的请求 / 响应是前后相同的

![](https://pic.imgdb.cn/item/62171ba52ab3f51d91b7cc32.png)

比如，从某个 Web 网站上下载内容，是无法确定客户端下载的文件和服务器上存放的文件是否前后一致的。文件内容在传输途中可能已经被篡改为其他的内容。即使内容真的已改变，作为接收方的客户端也是觉察不到的。

像这样，**请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击称为中间人攻击（Man-in-the-Middle attack，MITM）。**



![](https://pic.imgdb.cn/item/62171bfa2ab3f51d91b87cb0.png)



##### 如何防止篡改

虽然有使用 HTTP 协议确定报文完整性的方法，但事实上并不便捷、可靠。其中常用的是 MD5 和 SHA-1 等散列值校验的方法，以及用来确认文件的数字签名方法

提供文件下载服务的 Web 网站也会提供相应的以 PGP（Pretty Good Privacy，完美隐私）创建的数字签名及 MD5 算法生成的散列值。PGP 是用来证明创建文件的数字签名，MD5 是由单向函数生成的散列值。不论使用哪一种方法，都需要操纵客户端的用户本人亲自检查验证下载的文件是否就是原来服务器上的文件。浏览器无法自动帮用户检查。
可惜的是，用这些方法也依然无法百分百保证确认结果正确。因为 PGP 和 MD5 本身被改写的话，用户是没有办法意识到的。为了有效防止这些弊端，有必要使用 HTTPS。SSL提供认证和加密处理及摘要功能。仅靠 HTTP 确保完整性是非常困难的，因此通过和其他协议组合使用来实现这个目标。下节我们介绍HTTPS 的相关内容



### HTTP+ 加密 + 认证 + 完整性保护 =HTTPS

#### HTTP 加上加密处理和认证以及完整性保护后即是HTTPS

如果在 HTTP 协议通信过程中使用未经加密的明文，比如在 Web 页面中输入信用卡号，如果这条通信线路遭到窃听，那么信用卡号就暴
露了。另外，对于 HTTP 来说，服务器也好，客户端也好，都是没有办法确认通信方的。因为很有可能并不是和原本预想的通信方在实际通信。并且还需要考虑到接收到的报文在通信途中已经遭到篡改这一可能性

为了统一解决上述这些问题，需要在 HTTP 上再加入加密处理和认证等机制。我们把添加了加密及认证机制的 HTTP 称为 HTTPS（HTTP
Secure）

![](https://pic.imgdb.cn/item/62171d432ab3f51d91bb4076.png)



#### HTTPS 是身披 SSL 外壳的 HTTP

HTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替而已。

通常，HTTP 直接和 TCP 通信。当使用 SSL时，则演变成先和 SSL通信，再由 SSL和 TCP 通信了。简言之，所谓 HTTPS，其实就是身披SSL协议这层外壳的 HTTP。

![](https://pic.imgdb.cn/item/62171e452ab3f51d91bd7912.png)

在采用 SSL后，HTTP 就拥有了 HTTPS 的加密、证书和完整性保护这些功能

SSL是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL协议使用。可以说 SSL是
当今世界上应用最为广泛的网络安全技术

#### 相互交换密钥的公开密钥加密技术

![](https://pic.imgdb.cn/item/62171eff2ab3f51d91bf1296.png)

==共享密钥加密的困境==

加密和解密同用一个密钥的方式称为共享密钥加密（Common keycrypto system），也被叫做对称密钥加密。

![](https://pic.imgdb.cn/item/62171f3d2ab3f51d91bfa1e3.png)

以共享密钥方式加密时必须将密钥也发给对方。可究竟怎样才能安全地转交？在互联网上转发密钥时，如果通信被监听那么密钥就可会落入攻击者之手，同时也就失去了加密的意义。另外还得设法安全地保管接收到的密钥。

![](https://pic.imgdb.cn/item/62171f782ab3f51d91c02106.png)



==使用两把密钥的公开密钥加密==

公开密钥加密方式很好地解决了共享密钥加密的困难。公开密钥加密使用一对非对称的密钥。一把叫做==私有密钥==（private key），另一把叫做==公开密钥==（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。使用公开密钥加密方式，==发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密==。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。退一步讲，如果能对一个非常大的整数做到快速地因式分解，那么密码破解还是存在希望的。但就目前的技术来看是不太现实的。

![](https://pic.imgdb.cn/item/621720132ab3f51d91c16059.png)



#### HTTPS 采用混合加密机制

HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。若密钥能够实现安全交换，那么有可能会考虑仅使用公开
密钥加密来通信。但是公开密钥加密与共享密钥加密相比，其处理速度要慢。
所以应充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交
换报文阶段则使用共享密钥加密方式。
![](https://pic.imgdb.cn/item/621720b22ab3f51d91c2afe7.png)

#### 证明公开密钥正确性的证书

遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器
建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真
正的公开密钥已经被攻击者替换掉了。

为了解决上述问题，可以使用由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书

服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称
为证书

![](https://pic.imgdb.cn/item/621721e02ab3f51d91c54ddb.png)



#### HTTPS 的安全通信机制

![](https://pic.imgdb.cn/item/621722bf2ab3f51d91c745e9.png)



步骤 1： 客户端通过发送 Client Hello 报文开始 SSL通信。报文中包含客户端支持的 SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）

步骤 2： 服务器可进行 SSL通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL版本以及加密组件。服务器的
加密组件内容是从接收到的客户端加密组件内筛选出来的。

步骤 3： 之后服务器发送 Certificate 报文。报文中包含公开密钥证书。

步骤 4： 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL握手协商部分结束。

步骤 5： SSL第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master
secret 的随机密码串。该报文已用步骤 3 中的公开密钥进行加密。

步骤 6： 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。

步骤 7： 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。

步骤 8： 服务器同样发送 Change Cipher Spec 报文。

步骤 9： 服务器同样发送 Finished 报文。

步骤 10： 服务器和客户端的 Finished 报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到 SSL的保护。从此处开始进行应用
层协议的通信，即发送 HTTP 请求。

步骤 11： 应用层协议通信，即发送 HTTP 响应。

步骤 12： 最后由客户端断开连接。断开连接时，发送 close_notify 报文。上图做了一些省略，这步之后再发送 TCP FIN 报文来关闭与 TCP的通信。

在以上流程中，**应用层发送数据时会附加一种叫做 MAC（MessageAuthentication Code）的报文摘要。MAC 能够查知报文是否遭到篡**
**改，从而保护报文的完整性**。下面是对整个流程的图解。图中说明了从仅使用服务器端的公开密钥证书（服务器证书）建立 HTTPS 通信的整个过程。

![](https://pic.imgdb.cn/item/621723672ab3f51d91c8b00e.png)



![](https://pic.imgdb.cn/item/621723e22ab3f51d91c9d1d6.png)

![](https://pic.imgdb.cn/item/621723fa2ab3f51d91ca0486.png)

SSL的慢分两种。一种是指通信慢。另一种是指由于大量消耗CPU 及内存等资源，导致处理速度变慢。
和使用 HTTP 相比，网络负载可能会变慢 2 到 100 倍。除去和TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL通信，
因此整体上处理通信量不可避免会增加。另一点是 SSL必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。针对速度变慢这一问题，并没有根本性的解决方案，我们会使用SSL加速器这种（专用服务器）硬件来改善该问题。该硬件为SSL通信专用硬件，相对软件来讲，能够提高数倍 SSL的计算速度。仅在 SSL处理时发挥 SSL加速器的功效，以分担负载。





## 4：HTTP状态码

常见状态代码、状态描述、说明：

[![b9Tscd.png](https://s4.ax1x.com/2022/02/23/b9Tscd.png)

1.  200 OK   //客户端请求成功
2.  301 永久移动
3.  302 暂时移动
4.  400 Bad Request //客户端请求有语法错误，不能被服务器所理解
5.  401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 
6.  403 Forbidden //服务器收到请求，但是拒绝提供服务
7.  404 Not Found //请求资源不存在，eg：输入了错误的URL
8.  500 Internal Server Error //服务器发生不可预期的错误
9.  503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常



## 5：输入URL后的过程

![img](https://pic2.zhimg.com/80/v2-a069ac8daaf04686fb59bc3cbb175cf9_1440w.jpg?source=1940ef5c)



![img](https://pic4.zhimg.com/80/v2-056561275ab9c040f22d98f52dfa2216_1440w.jpg?source=1940ef5c)



 ![](https://static.vue-js.com/11bf1f20-bdf4-11eb-85f6-6fac77c0c9b3.png)


### 一、简单分析

简单的分析，从输入 `URL`到回车后发生的行为如下：

- URL解析
- DNS 查询
- TCP 连接
- HTTP 请求
- 响应请求
- 页面渲染


### 二、详细分析

### URL解析

首先判断你输入的是一个合法的` URL` 还是一个待搜索的关键词，并且根据你输入的内容进行对应操作

`URL`的解析第过程中的第一步，一个`url`的结构解析如下：

 ![](https://static.vue-js.com/27a0c690-bdf4-11eb-ab90-d9ae814b240d.png)



### DNS查询

在之前文章中讲过`DNS`的查询，这里就不再讲述了

整个查询过程如下图所示：

 ![](https://static.vue-js.com/330fb770-bdf4-11eb-85f6-6fac77c0c9b3.png)

最终，获取到了域名对应的目标服务器`IP`地址



### TCP连接

在之前文章中，了解到`tcp`是一种面向有连接的传输层协议

在确定目标服务器服务器的`IP`地址后，则经历三次握手建立`TCP`连接，流程如下：

 ![](https://static.vue-js.com/ad750790-bdf4-11eb-85f6-6fac77c0c9b3.png)





### 发送 http 请求

当建立`tcp`连接之后，就可以在这基础上进行通信，浏览器发送 `http` 请求到目标服务器

请求的内容包括：

- 请求行
- 请求头
- 请求主体

 ![](https://static.vue-js.com/bbcb60f0-bdf4-11eb-ab90-d9ae814b240d.png)



### 响应请求

当服务器接收到浏览器的请求之后，就会进行逻辑操作，处理完成之后返回一个`HTTP`响应消息，包括：

- 状态行
- 响应头
- 响应正文

 ![](https://static.vue-js.com/c5fe0140-bdf4-11eb-ab90-d9ae814b240d.png)

在服务器响应之后，由于现在`http`默认开始长连接`keep-alive`，当页面关闭之后，`tcp`链接则会经过四次挥手完成断开



### 页面渲染

当浏览器接收到服务器响应的资源后，首先会对资源进行解析：

- 查看响应头的信息，根据不同的指示做对应处理，比如重定向，存储cookie，解压gzip，缓存资源等等
- 查看响应头的 Content-Type的值，根据不同的资源类型采用不同的解析方式

关于页面的渲染过程如下：

- 解析HTML，构建 DOM 树
- 解析 CSS ，生成 CSS 规则树
- 合并 DOM 树和 CSS 规则，生成 render 树
- 布局 render 树（ Layout / reflow ），负责各元素尺寸、位置的计算
- 绘制 render 树（ paint ），绘制页面像素信息
- 浏览器会将各层的信息发送给 GPU，GPU 会将各层合成（ composite ），显示在屏幕上

 ![](https://static.vue-js.com/db7bddd0-bdf4-11eb-85f6-6fac77c0c9b3.png)





使用的协议:

DNS: 获取域名对应的IP 

HTTP：客户端浏览器与Web服务器之间的应用层通信协议，在TCP建立完成后，使用HTTP协议访问网页

TCP: 与服务器建立TCP连接

IP: 建立TCP协议时，需要发送数据，发送数据在网络层上使用IP协议

RIP, OSPF：域内路由，IP数据包在路由器之间，路由选择使用OSPF协议

BGP：域间路由

ICMP：搭配ip协议

ARP：路由器在与服务器进行通信的过程中，将IP地址装换成MAC地址



## 6：get和post

### 一、是什么

`GET`和`POST`，两者是`HTTP`协议中发送请求的方法

#### GET

`GET`方法请求一个指定资源的表示形式，使用GET的请求应该只被用于获取数据

#### POST

`POST`方法用于将实体提交到指定的资源，通常导致在服务器上的状态变化或**副作用**

**本质上都是`TCP`链接，并无差别**

但是由于`HTTP`的规定和浏览器/服务器的限制，导致他们在应用过程中会体现出一些区别

### 二、区别

从`w3schools`得到的标准答案的区别如下：

- GET在浏览器回退时是无害的，而POST会再次提交请求。
- GET产生的URL地址可以被Bookmark，而POST不可以。
- GET请求会被浏览器主动cache，而POST不会，除非手动设置。
- GET请求只能进行url编码，而POST支持多种编码方式。
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
- GET请求在URL中传送的参数是有长度限制的，而POST没有。
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
- GET参数通过URL传递，POST放在Request body中


#### 参数位置

貌似从上面看到`GET`与`POST`请求区别非常大，但两者实质并没有区别

无论 `GET `还是 `POST`，用的都是同一个传输层协议，所以在传输上没有区别

当不携带参数的时候，两者最大的区别为第一行方法名不同

> POST /uri HTTP/1.1 \r\n
>
> GET /uri HTTP/1.1 \r\n

**当携带参数的时候，我们都知道`GET`请求是放在`url`中，`POST`则放在`body`中**

`GET` 方法简约版报文是这样的

```
GET /index.html?name=qiming.c&age=22 HTTP/1.1
Host: localhost
```

`POST `方法简约版报文是这样的

```
POST /index.html HTTP/1.1
Host: localhost
Content-Type: application/x-www-form-urlencoded

name=qiming.c&age=22
```

注意：这里只是约定，并不属于`HTTP`规范，相反的，我们可以在`POST`请求中`url`中写入参数，或者`GET`请求中的`body`携带参数


#### 参数长度

`HTTP `协议没有` Body `和 `URL` 的长度限制，对 `URL `限制的大多是浏览器和服务器的原因

`IE`对`URL`长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持

这里限制的是整个`URL`长度，而不仅仅是参数值的长度

服务器处理长` URL` 要消耗比较多的资源，为了性能和安全考虑，会给 `URL` 长度加限制

#### 安全

`POST `比` GET` 安全，因为数据在地址栏上不可见

然而，从传输的角度来说，他们都是不安全的，因为` HTTP` 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文

只有使用`HTTPS`才能加密安全


#### 数据包

对于`GET`方式的请求，浏览器会把`http header`和`data`一并发送出去，服务器响应200（返回数据）

对于`POST`，浏览器先发送`header`，服务器响应100 `continue`，浏览器再发送`data`，服务器响应200 ok

并不是所有浏览器都会在`POST`中发送两次包，`Firefox`就只发送一次







## 7：cookie和session

一、客户端与服务端请求响应的关系
USER（客户端） 请求 tomcat（服务器）, 属于HTTP请求。http请求是无状态的,即每次服务端接收到客户端的请求时，都是一个全新的请求，服务器并不知道客户端的历史请求记录；所以当用户从客户端请求一次登录后，登录成功，再次进行请求时，因为tomcat不能识别这两次会话都是来自同一个浏览器，即服务端不知道客户端的历史请求记录；就会再次弹出登录对话框。

![这里写图片描述](https://img-blog.csdn.net/20180705090014248?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4Mjk2OTI1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



为了解决客户端与服务端会话同步问题。这便引出了下面几个概念：cookie、session。

于是，我们便把**服务器中产生的会话sessionID**存储到**客户端浏览器cookie**中去。在客户端存在周期为浏览器关闭时，消失。这样便解决了客户端请求服务端会话不同步问题。

二、cookie是什么
一个HTTP cookie的（网络Cookie，浏览器cookie）是一小片数据的一个服务器发送到用户的网络浏览器。浏览器可以存储它并将其与下一个请求一起发送回同一服务器。通常，它用于判断两个请求是否来自同一个浏览器 - 例如，保持用户登录。它记住无状态 HTTP协议的有状态信息。

三、session是什么
客户端请求服务端，**服务端（Tomcat）会为这次请求开辟一块内存空间，这个对象便是Session对象**， 存储结构为**ConcurrentHashMap**。

session的目的：弥补HTTP无状态特性，服务器可以利用session存储客户端在同一个会话期间的一些操作记录。

四、HTTP是无状态的
在同一连接上连续执行的两个请求之间没有链接。对于试图与某些页面连贯地相互作用的用户而言，这立即存在问题，例如，使用电子商务购物篮。但是，虽然HTTP本身的核心是无状态，但HTTP cookie允许使用有状态会话。使用标头可扩展性，HTTP Cookie被添加到工作流中，允许在每个HTTP请求上创建会话以共享相同的上下文或相同的状态。

五、session的实现机制
1、服务器如何判断客户端发送过来的请求属于同一个会话？
用session id区分；session id 相同即认为是同一个会话；  
1
 在tomcat中session id中用JSESSIONID来表示；

2、服务器、客户端如何获取sessionID?SessionID在期间是如何传输的？
 服务器第一次接收到请求时，开辟了一块Session空间（创建了Session对象），同时生成一个Session id，并通过响应头的Set-Cookie：“JSESSIONID=XXXXXXX”命令，向客户端发送要求设置cookie的响应； 客户端收到响应后，在本机客户端设置了一个JSESSIONID=XXXXXXX的cookie信息，该cookie的过期时间为浏览器会话结束；

接下来客户端每次向同一个网站发送请求时，请求头都会带上该cookie信息（包含Session id）； 然后，服务器通过读取请求头中的Cookie信息，获取名称为JSESSIONID的值，得到此次请求的Session id；

 注意：服务器只会在客户端第一次请求响应的时候，在响应头上添加Set-Cookie：“JSESSIONID=XXXXXXX”信息，接下来在同一个会话的第二第三次响应头里，是不会添加Set- Cookie：“JSESSIONID=XXXXXXX”信息的； 而客户端是会在每次请求头的cookie中带上JSESSIONID信息；

![这里写图片描述](https://img-blog.csdn.net/20180705090753401?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4Mjk2OTI1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



![这里写图片描述](https://img-blog.csdn.net/20180705090758830?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4Mjk2OTI1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



![这里写图片描述](https://img-blog.csdn.net/2018070509080586?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI4Mjk2OTI1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



#### 关于过期

-   Cookie保存在客户端浏览器，Session保存在服务器。
-   Cookie可以设置过期时间。
    -   **如果Cookie不包含到期日期，则可视为会话Cookie（Session Cookie）**。会话Cookie存储在客户端的内存（浏览器占用的内存）中，决不会写入磁盘。当浏览器关闭时，Cookie将从此永久丢失。
    -   **如果Cookie包含到期日期，则可视为持久性Cookie，存储在客户端的磁盘中**。在指定的到期日期，Cookie将从磁盘中删除。
-   **客户端请求服务端时，如果客户端的Cookie中没有当前会话的SessionId，则服务端会新分配一个Session，同时通过算法生成一个唯一的（不重复的）sessionId，并将与该Session对应的SessionId存到Cookie中发回给客户端浏览器。**
-   由于大部分的网站在发回SessionId时使用了会话Cookie（即没有设置过期时间），导致该Cookie存在客户端内存中，所以关闭浏览器即丢失了SessionId信息，再次访问服务端时才找不到对应的Session，于是才有了“关闭浏览器则Session过期”的说法！
-   服务端在保存Session时也可以设置该Session的过期时间，服务端的Web服务容器通常也有一个默认的过期时间。若访问服务器后，保持不关闭浏览器一段时间，超过Session过期时间后再次访问，会发现依然Session过期找不到了（比如表现为跳转到登录页面），则是“没有关浏览器但Session过期了”！
-   **当（存放着SessionId的）Cookie和Session中两者有任一过期，即宣告会话过期。**



#### HTTP首部字段中关于cookie

管理服务器与客户端之间状态的 Cookie，虽然没有被编入标准化HTTP/1.1 的 RFC2616 中，但在 Web 网站方面得到了广泛的应用。Cookie 的工作机制是用户识别及状态管理。Web 网站为了管理用户状态会通过 Web 浏览器，把一些数据临时写入用户的计算机内。接着当用户访问该Web网站时，可通过通信方式取回之前发放的Cookie。

![](https://pic.imgdb.cn/item/621630e32ab3f51d9119b55c.png)

## 8：UDP实现可靠数据传输



在应用层实现，确认机制，重传机制



## 9：HTTP 和 HTTPS 什么区别？

端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL之上的HTTP协议，SSL运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。



## 10：讲一下对称加密算法和非对称加密算法？

对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称 加密算法有DES、AES等；

非对称密钥加密，加密和解密使用不同的密钥。通信发送方获得接收方的公开密钥之后，就 可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。可以更安全地将公 开密钥传输给通信发送方；运算速度慢。典型的非对称加密算法有RSA、DSA等

HTTPS 采用的加密方式: HTTPS 采用混合的加密机制。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。



## 11：HTTP报文详解？

### HTTP 报文

用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的HTTP 报文叫做请求报文，响应端（服务器端）的叫做响应报文。
HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。
HTTP 报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR+LF）来划分。通常，并不一定要有报文主体

[![b9uzh6.png](https://s4.ax1x.com/2022/02/23/b9uzh6.png)](https://imgtu.com/i/b9uzh6)



### 请求报文及响应报文的结构

[![b9Ku38.png](https://s4.ax1x.com/2022/02/23/b9Ku38.png)](https://imgtu.com/i/b9Ku38)



[![b9KJNq.png](https://s4.ax1x.com/2022/02/23/b9KJNq.png)](https://imgtu.com/i/b9KJNq)



请求报文和响应报文的首部内容由以下数据组成。现在出现的各种首部字段及状态码稍后会进行阐述。
==请求行==
包含用于请求的方法，请求 URI 和 HTTP 版本。
==状态行==
包含表明响应结果的状态码，原因短语和 HTTP 版本。
==首部字段==
包含表示请求和响应的各种条件和属性的各类首部。一般有 4 种首部，分别是：通用首部、请求首部、响应首部和实体首部。
==其他==
可能包含 HTTP 的 RFC 里未定义的首部（Cookie 等）





## 12：Mac 地址和 ip 地址的区别？

MAC地址是烧录在网卡或者接口上的**物理地址**，具有**全球唯一性**，一般不能被改变。IP地址是网络中的主机或接口在网络中的**逻辑地址**，在**同一个网络内具有唯一性**。

因为存在网络层地址 例如 因特网的IP地址 和链路层地址 即MAC地址 所以需要在它们之间进行转换。对于因特网而言，这是地址解析协 （Address ResolutionProtocol, **ARP** [RFC 826] 的任务

## 13：HTTP是不保存状态的协议,如何保存用户状态?

HTTP 是一种无状态协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。主要通过session机制来进行解决，Session 的主要作用就是通过服务端记录用户的状态。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下， 我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

Cookie 被禁用怎么办**?** 最常用的就是利用 URL 把 Session ID 直接附加在URL路径的后面。



## **14：DNS**



### 一、是什么

DNS（Domain Names System），域名系统，是互联网一项服务，是进行域名和与之相对应的 IP 地址进行转换的服务器

简单来讲，`DNS`相当于一个翻译官，负责将域名翻译成`ip`地址

- IP 地址：一长串能够唯一地标记网络上的计算机的数字
- 域名：是由一串用点分隔的名字组成的 Internet 上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识

 ![](https://static.vue-js.com/965a03a0-b78f-11eb-ab90-d9ae814b240d.png)





### 二、域名

域名是一个具有层次的结构，从上到下一次为根域名、顶级域名、二级域名、三级域名...

 ![](https://static.vue-js.com/9f112780-b78f-11eb-85f6-6fac77c0c9b3.png)

例如`www.xxx.com`，`www`为三级域名、`xxx`为二级域名、`com`为顶级域名，系统为用户做了兼容，域名末尾的根域名`.`一般不需要输入

在域名的每一层都会有一个域名服务器，如下图：

 ![](https://static.vue-js.com/f40e0090-b7a4-11eb-85f6-6fac77c0c9b3.png)

除此之外，还有电脑默认的本地域名服务器



### 三、查询方式

DNS 查询的方式有两种：

- 递归查询：如果 A 请求 B，那么 B 作为请求的接收者一定要给 A 想要的答案

 ![](https://static.vue-js.com/a73be9e0-b78f-11eb-85f6-6fac77c0c9b3.png)

- 迭代查询：如果接收者 B 没有请求者 A 所需要的准确内容，接收者 B 将告诉请求者 A，如何去获得这个内容，但是自己并不去发出请求

 ![](https://static.vue-js.com/b023e1c0-b78f-11eb-85f6-6fac77c0c9b3.png)



### 四、域名缓存

在域名服务器解析的时候，使用缓存保存域名和`IP`地址的映射

计算机中`DNS`的记录也分成了两种缓存方式：

- 浏览器缓存：浏览器在获取网站域名的实际 IP 地址后会对其进行缓存，减少网络请求的损耗
- 操作系统缓存：操作系统的缓存其实是用户自己配置的 `hosts` 文件



### 五、查询过程

解析域名的过程如下：

- 首先搜索浏览器的 DNS 缓存，缓存中维护一张域名与 IP 地址的对应表
- 若没有命中，则继续搜索操作系统的 DNS 缓存
- 若仍然没有命中，则操作系统将域名发送至本地域名服务器，本地域名服务器采用递归查询自己的 DNS 缓存，查找成功则返回结果
- 若本地域名服务器的 DNS 缓存没有命中，则本地域名服务器向上级域名服务器进行迭代查询
    - 首先本地域名服务器向根域名服务器发起请求，根域名服务器返回顶级域名服务器的地址给本地服务器
    - 本地域名服务器拿到这个顶级域名服务器的地址后，就向其发起请求，获取权限域名服务器的地址
    - 本地域名服务器根据权限域名服务器的地址向其发起请求，最终得到该域名对应的 IP 地址

- 本地域名服务器将得到的 IP 地址返回给操作系统，同时自己将 IP 地址缓存起来

- 操作系统将 IP 地址返回给浏览器，同时自己也将 IP 地址缓存起

- 至此，浏览器就得到了域名对应的 IP 地址，并将 IP 地址缓存起

流程如下图所示：

 ![](https://static.vue-js.com/bec3c740-b78f-11eb-ab90-d9ae814b240d.png)





## 15：CDN

### 一、是什么

CDN (全称 Content Delivery Network)，即内容分发网络

构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。`CDN` 的关键技术主要有内容存储和分发技术

简单来讲，`CDN`就是根据用户位置分配最近的资源

于是，用户在上网的时候不用直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫**边缘节点**，其实就是缓存了源站内容的代理服务器。如下图：

 ![](https://static.vue-js.com/4f0289f0-b86b-11eb-85f6-6fac77c0c9b3.png)



### 二、原理分析

在没有应用`CDN`时，我们使用域名访问某一个站点时的路径为

> 用户提交域名→浏览器对域名进行解释→`DNS` 解析得到目的主机的IP地址→根据IP地址访问发出请求→得到请求数据并回复

应用`CDN`后，`DNS` 返回的不再是 `IP` 地址，而是一个`CNAME`(Canonical Name ) 别名记录，指向`CDN`的全局负载均衡

`CNAME`实际上在域名解析的过程中承担了中间人（或者说代理）的角色，这是`CDN`实现的关键

#### 负载均衡系统

由于没有返回`IP`地址，于是本地`DNS`会向负载均衡系统再发送请求  ，则进入到`CDN`的全局负载均衡系统进行智能调度：

- 看用户的 IP 地址，查表得知地理位置，找相对最近的边缘节点
- 看用户所在的运营商网络，找相同网络的边缘节点

- 检查边缘节点的负载情况，找负载较轻的节点
- 其他，比如节点的“健康状况”、服务能力、带宽、响应时间等

结合上面的因素，得到最合适的边缘节点，然后把这个节点返回给用户，用户就能够就近访问`CDN`的缓存代理

整体流程如下图：

 ![](https://static.vue-js.com/588d7890-b86b-11eb-85f6-6fac77c0c9b3.png)



#### 缓存代理

缓存系统是 `CDN `的另一个关键组成部分，缓存系统会有选择地缓存那些最常用的那些资源

其中有两个衡量`CDN`服务质量的指标：

- 命中率：用户访问的资源恰好在缓存系统里，可以直接返回给用户，命中次数与所有访问次数之比
- 回源率：缓存里没有，必须用代理的方式回源站取，回源次数与所有访问次数之比

缓存系统也可以划分出层次，分成一级缓存节点和二级缓存节点。一级缓存配置高一些，直连源站，二级缓存配置低一些，直连用户

回源的时候二级缓存只找一级缓存，一级缓存没有才回源站，可以有效地减少真正的回源

现在的商业 `CDN`命中率都在 90% 以上，相当于把源站的服务能力放大了 10 倍以上



### 三、总结

`CDN` 目的是为了改善互联网的服务质量，通俗一点说其实就是提高访问速度

`CDN` 构建了全国、全球级别的专网，让用户就近访问专网里的边缘节点，降低了传输延迟，实现了网站加速

通过`CDN`的负载均衡系统，智能调度边缘节点提供服务，相当于`CDN`服务的大脑，而缓存系统相当于`CDN`的心脏，缓存命中直接返回给用户，否则回源





## 16：常见的网络攻击

### SYN泛洪攻击

服务器为了响应一个收到的SYN,分配并初始化连接变量和缓存。然后服务器发送一个SYNACK进行响应，并等待来自客户的ACK报文段。如果某客户不发送ACK来完成该三次握手的第三步，最终（通常在一分多钟之后）服务器将终止该半开连接并回收资源。这种TCP连接管理协议为经典的DoS攻击即SYN洪泛攻击

解决方法：SYN Cookie

### Dos(DDos攻击)

DoS 攻击（Denial of Service attack）是一种让运行中的服务呈停止状态的攻击。有时也叫做服务停止攻击或拒绝服务攻击。DoS 攻击的对象不仅限于 Web 网站，还包括网络设备及服务器等。
主要有以下两种 DoS 攻击方式。

1.  集中利用访问请求造成资源过载，资源用尽的同时，实际上服务也就呈停止状态。
2.  通过攻击安全漏洞使服务停止。

多台计算机发起的 DoS 攻击称为 DDoS 攻击（Distributed Denial of Service attack）。DDoS 攻击通常利用那些感染病毒的计算机作为攻击者的攻击跳板

### XSS攻击

跨站脚本攻击（Cross-Site Scripting，XSS）是指通过存在安全漏洞的Web 网站注册用户的浏览器内运行非法的 HTML标签或 JavaScript 进行的一种攻击。动态创建的 HTML部分有可能隐藏着安全漏洞。就这样，攻击者编写脚本设下陷阱，用户在自己的浏览器上运行时，一不小心就会受到被动攻击

![](https://pic.imgdb.cn/item/62178b812ab3f51d91d0a639.png)

此时的确认界面上，浏览器会把用户输入的 <s> 解析成 HTML标签，然后显示删除线。
删除线显示出来并不会造成太大的不利后果，但如果换成使用script 标签将会如何呢。
XSS 是攻击者利用预先设置的陷阱触发的被动攻击

跨站脚本攻击属于被动攻击模式，因此攻击者会事先布置好用于攻击的陷阱。

**XSS 攻击有两大要素： 1. 攻击者提交恶意代码。 2. 浏览器执行恶意代码。**

预防：

#### 1.预防 DOM 型 XSS 攻击

DOM 型 XSS 攻击，实际上就是网站前端 JavaScript 代码本身不够严谨，把不可信的数据当作代码执行了。

在使用 `.innerHTML、.outerHTML、document.write() `时要特别小心，不要把不可信的数据作为 HTML 插到页面上，而应尽量使用` .textContent、.setAttribute()` 等。

DOM 中的内联事件监听器，如 `location、onclick、onerror、onload、onmouseover `等， 标签的`href`属性，JavaScript 的`eval()、setTimeout()、setInterval()`等，都能把字符串作为代码运行。如果不可信的数据拼接到字符串中传递给这些 API，很容易 产生安全隐患，请务必避免。

#### 2.输入过滤

如果由前端过滤输入，然后提交到后端的话。一旦攻击者绕过前端过滤，直接构造请求，就可以提交恶意代码了。

那么，换一个过滤时机：后端在写入数据库前，对输入进行过滤，然后把“安全的”内容，返回给前端。这样是否可行呢？ 我们举一个例子，一个正常的用户输入了 5 < 7 这个内容，在写入数据库前，被转义，变成了 5 `$lt;` 7。 问题是：在提交阶段，我们并不确定内容要输出到哪里。

这里的“并不确定内容要输出到哪里”有两层含义：

1.  用户的输入内容可能同时提供给前端和客户端，而一旦经过了 escapeHTML()，客户端显示的内容就变成了乱码( 5 `$lt;`7 )。
2.  在前端中，不同的位置所需的编码也不同。 当 5 `$lt;`7  作为 HTML 拼接页面时，可以正常显示：`5 < 7`

所以输入过滤非完全可靠，我们就要通过“防止浏览器执行恶意代码”来防范 XSS，可采用下面的两种方法

#### 3.前端渲染把代码和数据分隔开

在前端渲染中，我们会明确的告诉浏览器：下面要设置的内容是文本（.innerText），还是属性（.setAttribute），还是样式 （.style）等等。浏览器不会被轻易的被欺骗，执行预期外的代码了。

-   Javascript：可以使用textContent或者innerText的地方，尽量不使用innerHTML；
-   query：可以使用text()得地方，尽量不使用html()；

#### 4.拼接HTML时对其进行转义

如果拼接 HTML 是必要的，就需要采用合适的转义库，对 HTML 模板各处插入点进行充分的转义。

常用的模板引擎，如 doT.js、ejs、FreeMarker 等，对于 HTML 转义通常只有一个规则，就是把 & < > " ' / 这几个字符转义掉，确 实能起到一定的 XSS 防护作用，但并不完善：




### SQL注入攻击

SQL注入（SQLInjection）是指针对 Web 应用使用的数据库，通过运行非法的 SQL而产生的攻击。该安全隐患有可能引发极大
的威胁，有时会直接导致个人信息及机密信息的泄露。

**如何预防SQL注入？**

这是开发人员应该思考的问题，作为测试人员，了解如何预防SQL注入，可以在发现注入攻击bug时，对bug产生原因进行定位。

1）严格检查输入变量的类型和格式

对于整数参数，加判断条件：不能为空、参数类型必须为数字

对于字符串参数，可以使用正则表达式进行过滤：如：必须为[0-9a-zA-Z]范围内的字符串

2）过滤和转义特殊字符

在username这个变量前进行转义，对'、"、\等特殊字符进行转义，如：php中的addslashes()函数对username参数进行转义

3）利用mysql的预编译机制

把sql语句的模板（变量采用占位符进行占位）发送给mysql服务器，mysql服务器对sql语句的模板进行编译，编译之后根据语句的优化分析对相应的索引进行优化，在最终绑定参数时把相应的参数传送给mysql服务器，直接进行执行，节省了sql查询时间，以及mysql服务器的资源，达到一次编译、多次执行的目的，除此之外，还可以防止SQL注入。具体是怎样防止SQL注入的呢？实际上当将绑定的参数传到mysql服务器，mysql服务器对参数进行编译，即填充到相应的占位符的过程中，做了转义操作。


## 17：HTTP的版本

#### 一、HTTP1.0

`HTTP`协议的第二个版本，第一个在通讯中指定版本号的HTTP协议版本

`HTTP 1.0` 浏览器与服务器只保持短暂的连接，每次请求都需要与服务器建立一个`TCP`连接

服务器完成请求处理后立即断开`TCP`连接，服务器不跟踪每个客户也不记录过去的请求

简单来讲，每次与服务器交互，都需要新开一个连接

 ![](https://static.vue-js.com/efff4da0-b93a-11eb-85f6-6fac77c0c9b3.png)

例如，解析`html`文件，当发现文件中存在资源文件的时候，这时候又创建单独的链接

最终导致，一个`html`文件的访问包含了多次的请求和响应，每次请求都需要创建连接、关系连接

这种形式明显造成了性能上的缺陷

如果需要建立长连接，需要设置一个非标准的Connection字段 `Connection: keep-alive`


#### 二、HTTP1.1

在`HTTP1.1`中，默认支持长连接（`Connection: keep-alive`），即在一个TCP连接上可以传送多个`HTTP`请求和响应，减少了建立和关闭连接的消耗和延迟

建立一次连接，多次请求均由这个连接完成

 ![](https://static.vue-js.com/22db2b90-b93b-11eb-ab90-d9ae814b240d.png)

这样，在加载`html`文件的时候，文件中多个请求和响应就可以在一个连接中传输

同时，`HTTP 1.1`还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间

同时，`HTTP1.1`在`HTTP1.0`的基础上，增加更多的请求头和响应头来完善的功能，如下：

- 引入了更多的缓存控制策略，如If-Unmodified-Since, If-Match, If-None-Match等缓存头来控制缓存策略
- 引入range，允许值请求资源某个部分
- 引入host，实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点

并且还添加了其他的请求方法：`put`、`delete`、`options`...





#### 三、HTTP2.0

而`HTTP2.0`在相比之前版本，性能上有很大的提升，如添加了一个特性：

- 多路复用
- 二进制分帧
- 首部压缩
- 服务器推送



### 多路复用

`HTTP/2` 复用`TCP`连接，在一个连接里，客户端和浏览器都可以**同时**发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了”队头堵塞”

 ![](https://static.vue-js.com/313f1980-b93b-11eb-85f6-6fac77c0c9b3.png)

上图中，可以看到第四步中`css`、`js`资源是同时发送到服务端



### 二进制分帧

帧是`HTTP2`通信中最小单位信息

`HTTP/2` 采用二进制格式传输数据，而非 `HTTP 1.x `的文本格式，解析起来更高效

将请求和响应数据分割为更小的帧，并且它们采用二进制编码

`HTTP2 `中，同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流

每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装，这也是多路复用同时发送数据的实现条件



### 首部压缩

`HTTP/2`在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送

首部表在`HTTP/2`的连接存续期内始终存在，由客户端和服务器共同渐进地更新

例如：下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销

 ![](https://static.vue-js.com/3c536740-b93b-11eb-ab90-d9ae814b240d.png)

### 服务器推送

`HTTP2`引入服务器推送，允许服务端推送资源给客户端

服务器会顺便把一些客户端需要的资源一起推送到客户端，如在响应一个页面请求中，就可以随同页面的其它资源

免得客户端再次创建连接发送请求到服务器端获取

这种方式非常合适加载静态资源

 ![](https://static.vue-js.com/47130550-b93b-11eb-85f6-6fac77c0c9b3.png)



#### 四、总结

HTTP1.0：

- 浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接

HTTP1.1：

- 引入了持久连接，即TCP连接默认不关闭，可以被多个请求复用
- 在同一个TCP连接里面，客户端可以同时发送多个请求
- 虽然允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的，服务器只有处理完一个请求，才会接着处理下一个请求。如果前面的处理特别慢，后面就会有许多请求排队等着
- 新增了一些请求方法
- 新增了一些请求头和响应头

HTTP2.0：

- 采用二进制格式而非文本格式
- 完全多路复用，而非有序并阻塞的、只需一个连接即可实现并行
- 使用报头压缩，降低开销
- 服务器推送



## 18：TCP和UDP

#### 一、UDP

UDP（User Datagram Protocol），用户数据包协议，是一个简单的**面向数据报的通信协议**，即对应用层交下来的报文，不合并，不拆分，只是在其上面加上首部后就交给了下面的网络层

也就是说无论应用层交给`UDP`多长的报文，它统统发送，一次发送一个报文

而对接收方，接到后直接去除首部，交给上面的应用层就完成任务

`UDP`报头包括4个字段，每个字段占用2个字节（即16个二进制位），标题短，开销小

 ![](https://static.vue-js.com/928e5d20-b393-11eb-ab90-d9ae814b240d.png)



特点如下：

- UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务
- 传输途中出现丢包，UDP 也不负责重发
- 当包的到达顺序出现乱序时，UDP没有纠正的功能。
- 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为



#### 二、TCP

TCP（Transmission Control Protocol），传输控制协议，是一种可靠、**面向字节流的通信协议**，把上面应用层交下来的数据看成无结构的字节流来发送

可以想象成流水形式的，发送方TCP会将数据放入“蓄水池”（缓存区），等到可以发送的时候就发送，不能发送就等着，TCP会根据当前网络的拥塞状态来确定每个报文段的大小

`TCP`报文首部有20个字节，额外开销大

 ![](https://static.vue-js.com/a0010d40-b393-11eb-ab90-d9ae814b240d.png)



特点如下：

- TCP充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。
- 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。
- 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）



#### 三、区别

`UDP`与`TCP`两者的都位于传输层，如下图所示：

 ![](https://static.vue-js.com/a92bda80-b393-11eb-ab90-d9ae814b240d.png)

两者区别如下表所示：

|          | TCP                              | UDP                            |
| -------- | -------------------------------- | ------------------------------ |
| 可靠性   | 可靠                             | 不可靠                         |
| 连接性   | 面向连接                         | 无连接                         |
| 报文     | 面向字节流                       | 面向报文                       |
| 效率     | 传输效率低                       | 传输效率高                     |
| 双共性   | 全双工                           | 一对一、一对多、多对一、多对多 |
| 流量控制 | 滑动窗口                         | 无                             |
| 拥塞控制 | 慢开始、拥塞避免、快重传、快恢复 | 无                             |
| 传输效率 | 慢                               | 快                             |

- TCP 是面向连接的协议，建立连接3次握手、断开连接四次挥手，UDP是面向无连接，数据传输前后不连接连接，发送端只负责将数据发送到网络，接收端从消息队列读取
- TCP 提供可靠的服务，传输过程采用流量控制、编号与确认、计时器等手段确保数据无差错，不丢失。UDP 则尽可能传递数据，但不保证传递交付给对方
- TCP 面向字节流，将应用层报文看成一串无结构的字节流，分解为多个TCP报文段传输后，在目的站重新装配。UDP协议面向报文，不拆分应用层报文，只保留报文边界，一次发送一个报文，接收方去除报文首部后，原封不动将报文交给上层应用

- TCP 只能点对点全双工通信。UDP 支持一对一、一对多、多对一和多对多的交互通信

两者应用场景如下图：

 ![](https://static.vue-js.com/b6cdd800-b393-11eb-ab90-d9ae814b240d.png)

可以看到，TCP 应用场景适用于对效率要求低，对准确性要求高或者要求有链接的场景，而UDP 适用场景为对效率要求高，对准确性要求低的场景

## 19：OSI和TCP/IP模型

 ![](https://static.vue-js.com/a92bda80-b393-11eb-ab90-d9ae814b240d.png)



## 20：WebSocket

### 一、是什么

WebSocket，是一种网络传输协议，位于`OSI`模型的应用层。可在单个`TCP`连接上进行全双工通信，能更好的节省服务器资源和带宽并达到实时通迅

客户端和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输

 ![](https://static.vue-js.com/ad386e20-c0f1-11eb-85f6-6fac77c0c9b3.png)

从上图可见，`websocket`服务器与客户端通过握手连接，连接成功后，两者都能主动的向对方发送或接受数据

而在`websocket`出现之前，开发实时`web`应用的方式为轮询

不停地向服务器发送 HTTP 请求，问有没有数据，有数据的话服务器就用响应报文回应。如果轮询的频率比较高，那么就可以近似地实现“实时通信”的效果

轮询的缺点也很明显，反复发送无效查询请求耗费了大量的带宽和 `CPU `资源



### 二、特点



#### 全双工

通信允许数据在两个方向上同时传输，它在能力上相当于两个单工通信方式的结合

例如指 A→B 的同时 B→A ，是瞬时同步的



#### 二进制帧

采用了二进制帧结构，语法、语义与 HTTP 完全不兼容，相比`http/2`，`WebSocket `更侧重于“实时通信”，而`HTTP/2` 更侧重于提高传输效率，所以两者的帧结构也有很大的区别

不像 `HTTP/2` 那样定义流，也就不存在多路复用、优先级等特性

自身就是全双工，也不需要服务器推送





#### 协议名

引入`ws`和`wss`分别代表明文和密文的`websocket`协议，且默认端口使用80或443，几乎与`http`一致

```http
ws://www.chrono.com
ws://www.chrono.com:8080/srv
wss://www.chrono.com:445/im?user_id=xxx
```



#### 握手

`WebSocket `也要有一个握手过程，然后才能正式收发数据

客户端发送数据格式如下：

```http
GET /chat HTTP/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Origin: http://example.com
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13
```

- Connection：必须设置Upgrade，表示客户端希望连接升级
- Upgrade：必须设置Websocket，表示希望升级到Websocket协议
- Sec-WebSocket-Key：客户端发送的一个 base64 编码的密文，用于简单的认证秘钥。要求服务端必须返回一个对应加密的“Sec-WebSocket-Accept应答，否则客户端会抛出错误，并关闭连接
- Sec-WebSocket-Version ：表示支持的Websocket版本

服务端返回的数据格式：

```http
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=Sec-WebSocket-Protocol: chat
```

- HTTP/1.1 101 Switching Protocols：表示服务端接受 WebSocket 协议的客户端连接
- Sec-WebSocket-Accep：验证客户端请求报文，同样也是为了防止误连接。具体做法是把请求头里“Sec-WebSocket-Key”的值，加上一个专用的 UUID，再计算摘要



#### 优点

- 较少的控制开销：数据包头部协议较小，不同于http每次请求需要携带完整的头部
- 更强的实时性：相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少
- 保持创连接状态：创建通信后，可省略状态信息，不同于HTTP每次请求需要携带身份验证
- 更好的二进制支持：定义了二进制帧，更好处理二进制内容
- 支持扩展：用户可以扩展websocket协议、实现部分自定义的子协议
- 更好的压缩效果：Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率



### 三、应用场景

基于`websocket`的事实通信的特点，其存在的应用场景大概有：

- 弹幕
- 媒体聊天
- 协同编辑
- 基于位置的应用
- 体育实况更新
- 股票基金报价实时更新



## 



# JVM ：

## 1：JVM运行时数据区

**Java虚拟机管理的内存各区域：**

![JVM](https://s4.ax1x.com/2022/01/14/7GVmY6.png)



### 程序计数器

程序计数器是一块较小的内存区域，它可以看作是当前线程所执行字节码的行号指示器。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值为空（Undefined）

此区域是**唯一没有OutOfMemoryError的区域**



### Java虚拟机栈

它的生命周期与线程相同。**虚拟机栈描述的是Java方法执行的线程内存模型**：每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程



两类异常：

1  如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverFlowError异常

2  如果Java虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常



### 本地方法栈

虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的本地(Native)方法服务。与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失败时分别抛出StackOverFlowError和OutOfMemoryError



### Java堆

对于Java应用程序来说，Java堆是**虚拟机所管理的内存中最大的一块**。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java世界里**几乎所有的对象实例都在这里分配内存。**

Java堆可以处于物理上不连续的内存空间中，但在逻辑上他应该被视为连续的。Java堆既可以被实现成固定大小的，也可以是可扩展的，当前主流的Java虚拟机都是按照可扩展来实现的(通过参数-Xmx和-Xms设定)。



### 方法区

方法区和Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。



#### 运行时常量池

运行时常量池是方法区的一部分。Class文件中除了有类的版本，字段、方法、接口等描述信息外，还有一项信息是常量池表，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。



#### 直接内存

直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁的使用，而且也可能导致OOM的出现

元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：**元空间并不在虚拟机中，而是使用本地内存。**





## 2：HotSpot虚拟机对象揭秘

#### 对象的内存布局

![2022 02 16 16 34 34](https://s4.ax1x.com/2022/02/16/Hh9IG8.png)

在HotSpot虚拟机中，对象在堆内存中的存储布局可以划分为三个部分：对象头(Header)，实例数据(Instance Data) 和对齐填充(padding)。

HotSpot虚拟机对象的对象头部分包括两类信息。**第一类**用于存储对象自身的运行时数据，如哈希码(HashCode)，GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称它为==Mark Word==。Mark Word被设计成一个有着动态定义的数据结构。在32位的HotSpot虚拟机中，在对象未被同步锁锁定的状态下，Mark Word的32位存储空间中，25个比特用于存储对象哈希码，4个比特用于存储对象分代年龄，2个比特用于存储锁标志位，1个比特固定为0，在其他状态下(轻量级锁定，重量级锁定，GC标记，可偏向)下对象的存储内容如下图所示：

![160128](https://s4.ax1x.com/2022/01/18/70wI9e.png)



对象头的**另外一部分**是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。



#### 对象的访问定位

Java程序会通过栈上的reference数据来操作堆上的具体对象，对象访问方式是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种：

- [ ] 如果使用句柄访问的话，Java堆中将可能会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例信息和类型数据各自的具体地址信息
- [ ] 如果使用直接指针访问的话，Java堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销

![161426](https://s4.ax1x.com/2022/01/18/70Dpmn.png)

![161453](https://s4.ax1x.com/2022/01/18/70DikV.png)

使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference本身不需要被修改。 

使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访 问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本，就本书讨论的主要虚拟 机HotSpot而言，它主要使用第二种方式进行对象访问











## 1：类加载过程

加载 

验证 准备 解析

初始化

使用

卸载

## 2：类加载器

![img](https://img-blog.csdn.net/20180813145521896?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM4MDc1NDI1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



## 3：双亲委派



 双亲委派机制，其工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都很懒，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己才想办法去完成。



双亲委派机制的优势：采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。



findClass（）用于写类加载逻辑、loadClass（）方法的逻辑里如果父类加载器加载失败则会调用自己的findClass（）方法完成加载，保证了双亲委派规则。

1、如果不想打破双亲委派模型，那么只需要重写findClass方法即可

2、如果想打破双亲委派模型，那么就重写整个loadClass方法



打破双亲委派场景：

JDBC Driver类



## 4：JVM内存模型

![image-20210223231249075](C:\Users\16068\AppData\Roaming\Typora\typora-user-images\image-20210223231249075.png)



**程序计数器(线程私有)：**
是当前线程锁执行字节码的行号治时期，每条线程都有一个独立的程序计数器，这类内存也称为“线程私有”的内存。正在执行java方法的话，计数器记录的是虚拟机字节码指令的地址(当前指令的地址)。如果是Natice方法，则为空。



**java 虚拟机栈是线程私有的（线程私有）**
每个方法在执行的时候也会创建一个栈帧，存储了局部变量，操作数，动态链接，方法返回地址。
每个方法从调用到执行完毕，对应一个栈帧在虚拟机栈中的入栈和出栈。
通常所说的栈，一般是指在虚拟机栈中的局部变量部分。
局部变量所需内存在编译期间完成分配，
如果线程请求的栈深度大于虚拟机所允许的深度，则StackOverflowError。
如果虚拟机栈可以动态扩展，扩展到无法申请足够的内存，则OutOfMemoryError。



**本地方法栈（线程私有）**
和虚拟机栈类似，主要为虚拟机使用到的Native方法服务。也会抛出StackOverflowError 和OutOfMemoryError。

**Java堆（线程共享）**
被所有线程共享的一块内存区域，在虚拟机启动的时候创建，用于存放对象实例。
对可以按照可扩展来实现（通过-Xmx 和-Xms 来控制）
当队中没有内存可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。

**方法区（线程共享）**
被所有方法线程共享的一块内存区域。
用于存储已经被虚拟机加载的类信息，常量，静态变量等。
这个区域的内存回收目标主要针对常量池的回收和堆类型的卸载。







## 5：判断垃圾是否可以回收

引用计数法

可达性分析

  GCROOTS：

虚拟机栈中引用的对象

本地方法栈中引用的对象

方法区中常量引用的对象

方法区中静态属性引用的对象

## 6：垃圾回收算法

①标记-清理算法

  分为两个步骤：第一就是标记，也就是标记所有的需要回收的对象；第二就是清理，标记完成后进行统一的回收带有标记的对象占据的内存空间。缺点是效率问题，还有一个致命的缺点就是空间问题，标记清除之后会产生大量不连续的内存碎片，当程序在运行过程中需要分配较大对象时，无法找到足够的连续内存而造成内存空间浪费。

![img](https://img-blog.csdnimg.cn/20190226115046820.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5neGluZzUyMDc3,size_16,color_FFFFFF,t_70)

②复制算法

   复制算法是将内存容量划分为大小相等的两块，每次只使用其中的一块。当一块内存用完之后，就将还存活的对象复制到另一块上面，然后再把已使用的内存空间一次性清理。这样使得每次都对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只是这种算法的代价就是将内存缩小为原来的一半了。

![img](https://img-blog.csdnimg.cn/20190226110054168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5neGluZzUyMDc3,size_16,color_FFFFFF,t_70)

③标记-整理算法

标记整理算法与标记清除算法很相似，但显著的区别是：标记清除算法仅对不存活的对象进行处理，剩余存活对象不做任何处理，这就造成了内存碎片的问题；而标记整理算法不仅对不存活的对象进行清除，还对存活的对象进行重新整理，因此不会产生内存不连续的现象。

![img](https://img-blog.csdnimg.cn/20190226110527984.png)



**①新生代**

  新生代的目标就是尽可能快速的收集掉那些生命周期较短的对象，一般情况下新生成的或者朝生夕亡的对象一般都是首先存放在新生代里面。

![img](https://img-blog.csdnimg.cn/2019022611401291.png)

新生代将内存按照8:1:1分为一个Eden和so，s1三个区域；大部分对象都在Eden区域生成，在垃圾回收时，先将Eden存活的对象复制到s0区，然后清除Eden区，当这个s0区满了，则将Eden区和s0区的存活对象复制到s1，然后将Eden和s0区清空，此时s0是空的，然后交换s0和s1的角色（即下次回收会扫描eden和s1区），即保持s0为空，如此往复；特别地，当s1不足以存放Eden和s0存放的对象时，则将对象直接放到老年代）

适用回收算法：复制算法

在新生代中，每次垃圾回收都有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成垃圾收集



**②老年代**

老年代一般存放的是一些生命周期较长的对象，比如在新生代中经历来了n次垃圾回收后仍然存活的对象都进入了老年代。

适用回收算法：标记整理或标记清除

在老年代中因为对象存活率较高，没有额外的空间对它分配担保，就必须使用标记清除或标记整理





## 7：垃圾回收器





1) 分代收集器

- **ParNew：** 一款多线程的收集器，采用复制算法，主要工作在 Young 区，可以通过 `-XX:ParallelGCThreads` 参数来控制收集的线程数，整个过程都是 STW 的，常与 CMS 组合使用。
- **CMS：** 以获取最短回收停顿时间为目标，采用“标记-清除”算法，分 4 大步进行垃圾收集，其中初始标记和重新标记会 STW ，多数应用于互联网站或者 B/S 系统的服务器端上，JDK9 被标记弃用，JDK14 被删除，详情可见 [JEP 363](https://openjdk.java.net/jeps/363)。

2) 分区收集器

- **G1：** 一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能地满足垃圾收集暂停时间的要求。
- **ZGC：** JDK11 中推出的一款低延迟垃圾回收器，适用于大内存低延迟服务的内存管理和回收，SPECjbb 2015 基准测试，在 128G 的大堆下，最大停顿时间才 1.68 ms，停顿时间远胜于 G1 和 CMS。
- **Shenandoah：** 由 Red Hat 的一个团队负责开发，与 G1 类似，基于 Region 设计的垃圾收集器，但不需要 Remember Set 或者 Card Table 来记录跨 Region 引用，停顿时间和堆的大小没有任何关系。停顿时间与 ZGC 接近，下图为与 CMS 和 G1 等收集器的 benchmark。



目前使用最多的是 CMS 和 G1 收集器，二者都有分代的概念，主要内存结构如下：

![img](https://p1.meituan.net/travelcube/3a6dacdd87bfbec847d33d09dbe6226d199915.png)





1.Serial垃圾回收器

​    中文名是串行回收器，细分有两个回收器，分别提供给新生代和老年代。

    在新生代：使用复制算法进行垃圾回收；在老年代：使用标记-整理算法进行垃圾回收。
    
    其余的，两回收器便没有什么差异了，都是为单线程环境而打造的回收器，在垃圾回收时，开启单个线程进行垃圾回收，并且暂停所有的用户线程（Stop The World），这是JVMClient模式下的默认GC回收器。
    
    通过-UseSerialGC参数，可以使用两个新老代串行回收器的组合。
    
    在单CPU的环境下，由于没有线程交互的开销，效率会比较高，回收模型如下：

![img](https://img-blog.csdn.net/20180629180840515?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoYXRfaXNfY29vbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

2.ParNew垃圾回收器

​    ParNew垃圾回收器，几乎是Serial回收器的多线程版，其余特性无差别。（注：ParNew垃圾回收器只有新生代回收器，不像Serial回收器，还有一个SerialOld回收器）

    在JVMServer模式下，ParNew垃圾回收器是新生代回收器的首选，很大部分原因，是因为在选择CMS垃圾回收器时，会默认使用ParNew垃圾回收器作为新生代回收器，即，使用参数-XX:+UseConcMarkSweepGC，便会默认使用ParNew垃圾回收器。
    
    同样的，也可以使用-XX:+UseParNewGC参数强制使用ParNew回收器，而通过-XX:ParallelGCThreads参数可以限制ParNew回收器的线程数量，ParNew回收器的模型如下图：

![img](https://img-blog.csdn.net/20180629181938417?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoYXRfaXNfY29vbA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



3.Parallel Scavenge垃圾回收器

​    英文翻译为并行清理，听上去和ParNew垃圾回收器没有任何区别，但是此回收器相对于ParNew来说，他关注吞吐量。
   所谓的吞吐量，就是用户线程执行的时间占比，当使用Parallel Scavenge垃圾回收器的时候，可以通过设置参数，-XX:MaxGCPauseMillis控制最大垃圾收集停顿时间和-XX:GCTimeRatio设置吞吐量大小。

    控制垃圾收集停顿时间，相应的就会牺牲吞吐量，因为垃圾回收的停顿时间减少，相应的垃圾回收频率就会变高，随之吞吐量自然下降。
    
    在JDK1.6以前，Parallel Scavenge只能配合使用SerialOld垃圾回收器，所以老年代无法控制吞吐量，在JDK1.6以后，Parallel Old实现了老年代版本的并行垃圾回收器，使用标记-整理算法对垃圾进行回收，其他与Parallel无区别，可以搭配Parallel使用。

4.CMS垃圾回收器（Concurrent Mark Sweep）

​    这是垃圾回收器中唯一一个使用标记-清理算法的垃圾回收器。
​    由于并发的原因，他的垃圾回收停顿时间会比较小，但是相应的牺牲了吞吐量，停顿时间短的好处是能提高用户体验，所以，他被广泛地用于B/S架构中。

    CMS垃圾回收器回收垃圾分为四步：

初始标记：快速标记GCROOT能够关联到的对象，这个步骤会STW；
并发标记；
重新标记：此过程会STW，为了修正并发标记时，用户线程对标记的变化；
并发清理：清理过程是并发的；
    虽然说CMS垃圾回收器能够减少回收垃圾停顿时间，但是他的缺点也比较明显：

 由于频繁的进行垃圾回收，所以，吞吐量会下降；
标记-清理带来的缺点：存在内存碎片；



5.G1垃圾回收器（Garbage First）

​    G1垃圾回收器在CMS垃圾回收器的基础上有所改进，比较明显的有两点：

    一是使用了标记-整理算法，解决了垃圾碎片问题；
    
    第二，G1垃圾回收器将回收内存分为了多个区域，会观察多个区域中垃圾的情况，并优先收集垃圾较多的区域，这也是他名字Garbage First的由来。
    
    第三，G1垃圾回收器不需要其他垃圾回收器的配合就可以管理两个分代。

总结:

  

      垃圾回收器，其实粗分有四种垃圾回收器，串行，并行，并发，G1。但是细分可以有七种，其中，串行回收器有两个垃圾回收器，分别在新老年代，是单线程的实现，而ParNew则是串行回收器新生代的多线程版，这前三者又有一个共同点，都是简单的实现垃圾回收，STW，并没有多余的参数关注吞吐量。
      于是关注吞吐量的并行垃圾回收器就出现了，它可以通过设置参数来改变吞吐量，和最大停顿时间，同样也有新老年代两种实现。
      CMS则是唯一的一个使用标记-清除算法的垃圾回收器，由于并发执行，CMS能够做到垃圾回收停顿时间的优化，但是相对牺牲了吞吐量，同时也造成了回收碎片，只有老年代的实现。最后就是G1回收器，G1回收器在CMS的基础上又做了优化，将内存分区域，挑选垃圾最多的区域进行回收，同时的，它使用标记-整理算法，也就解决了内存碎片的问题，此回收器无需其他回收器的配合就能完成新老代的回收。





## 8：堆详解

JDK1.8之前：
![在这里插入图片描述](https://img-blog.csdn.net/20180925154516230?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDE2MDA1Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



JDK1.8之后：

![在这里插入图片描述](https://img-blog.csdn.net/20180925154742948?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDE2MDA1Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)





## 9：四种引用

![image-20210319160042893](C:\Users\16068\AppData\Roaming\Typora\typora-user-images\image-20210319160042893.png)

## 10：内存泄漏与内存溢出

内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。

内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。



## 11：OOM可能原因

1、堆空间 -> 堆空间已经装不下新创建的对象；
2、方法区 -> 方法区（落地实现）空间不足；
3、虚拟机栈 -> 创建的线程太多，每一个线程私有的栈空间又很大，就会申请不到内存空间；
4、本地方法栈 -> 本地方法栈也是私有的，当线程很多时也会出现OOM。

也就是说，运行时数据区中，只有程序计数器（占用空间极小）才不会导致程序报 OOM



## 12：new的对象一定在堆中吗

不一定，也有可能在栈中



## 13：栈溢出和堆溢出



## 14：young GC 和 full GC







## 15：JVM调优





## 16：Class类文件结构

Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在Class文件中，中间没有添加任何的分隔符，这使得整个Class文件中存储的内容几乎全部是程序运行的必要数据。当遇到需要占用8个字节以上空间的数据项时，则会按照高位在前的方式分隔成多个8位字节进行存储。

　　Class文件采用一种类似于C语言结构体的伪结构来存储数据，这种结构中只存在两种数据类型：无符号数和表。

-   **无符号数：**属于基本数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值
-   **表：**由多个无符号数或其他表作为数据项构成的符合数据类型，所以表都习惯以_info结尾。表用于描述有层次关系的复合结构的数据。整个Class文件本质上就是一张表，它由下表所示的数据项构成：

![](https://pic.imgdb.cn/item/623302b05baa1a80ab058324.png)





## 17：类加载过程

一个类型从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历加载(Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）七个阶段，其中验证、准备、解析三个部分统称为连接（Linking）。这七个阶段的发生顺序如图7-1所示。

![](https://pic.imgdb.cn/item/623303e35baa1a80ab07c0c4.png)



# MySQL：

## 1：索引

B树:

图中所示，B树事实上是一种平衡的多叉查找树，也就是说最多可以开m个叉（m>=2），我们称之为m阶b树

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180126165126756-1850778539.png)





总的来说，m阶B树满足以下条件：

- 每个节点至多可以拥有m棵子树。
- 根节点，只有至少有2个节点（要么极端情况，就是一棵树就一个根节点，单细胞生物，即是根，也是叶，也是树)。
- 非根非叶的节点至少有的Ceil(m/2)个子树(Ceil表示向上取整，图中5阶B树，每个节点至少有3个子树，也就是至少有3个叉)。
- 非叶节点中的信息包括[n,A0,K1,A1,K2,A2,…,Kn,An]，，其中n表示该节点中保存的关键字个数，K为关键字且Ki<Ki+1，A为指向子树根节点的指针。
- 从根到叶子的每一条路径都有相同的长度，也就是说，叶子节在相同的层，并且这些节点不带信息，实际上这些节点就表示找不到指定的值，也就是指向这些节点的指针为空。

B树的查询过程和二叉排序树比较类似，从根节点依次比较每个结点，**因为每个节点中的关键字和左右子树都是有序的**，所以只要比较节点中的关键字，或者沿着指针就能很快地找到指定的关键字，如果查找失败，则会返回叶子节点，即空指针。

例如查询图中字母表中的K：

1. 从根节点P开始，K的位置在P之前，进入左侧指针。
2. 左子树中，依次比较C、F、J、M，发现K在J和M之间。
3. 沿着J和M之间的指针，继续访问子树，并依次进行比较，发现第一个关键字K即为指定查找的值



B树的特点可以总结为如下：

1. 关键字集合分布在整颗树中。
2. 任何一个关键字出现且只出现在一个节点中。
3. 搜索有可能在非叶子节点结束。
4. 其搜索性能等价于在关键字集合内做一次二分查找。
5. B树在插入删除新的数据记录会破坏B-Tree的性质，因为在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。



B+树：

作为B树的加强版，B+树与B树的差异在于

- 有n棵子树的节点含有n个关键字（也有认为是n-1个关键字）。
- 所有的关键字全部存储在叶子节点上，且叶子节点本身根据关键字自小而大顺序连接。
- 非叶子节点可以看成索引部分，节点中仅含有其子树（根节点）中的最大（或最小）关键字。



![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180126171338850-1455023219.png)





B+树的查找过程，与B树类似，只不过查找时，如果在非叶子节点上的关键字等于给定值，并不终止，而是继续沿着指针直到叶子节点位置。因此在B+树，不管查找成功与否，每次查找都是走了一条从根到叶子节点的路径。

B+树的特性如下：

- 所有关键字都存储在叶子节上，且链表中的关键字恰好是有序的。
- 不可能非叶子节点命中返回。
- 非叶子节点相当于叶子节点的索引，叶子节点相当于是存储（关键字）数据的数据层。
- 更适合文件索引系统



带有顺序访问指针的B+Tree：

一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180126172151522-1626747450.png)



如上图所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。





MySQL为什么使用B树（B+树)：

红黑树等数据结构也可以用来实现索引，但是文件系统以及数据库系统普遍采用B树或者B+树，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。

**主存存取原理**

目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。



![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127132031069-608242954.png)





从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。上图展示了一个4 x 4的主存模型。



**主存的存取过程如下：**

当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。

写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。

这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。







上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。

下图是磁盘的整体结构示意图：

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127132317537-980020687.png)



一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。



下图是磁盘结构的示意图:

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127132643334-820894642.png)



盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。

当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。



![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127133337209-1019295107.png)



局部性原理与磁盘预读

由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

**当一个数据被用到时，其附近的数据也通常会马上被使用。**

所以，程序运行期间所需要的数据通常应当比较集中。

由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

B-/+Tree索引的性能分析

到这里终于可以分析B-/+Tree索引的性能了。

上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：

每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。（h表示树的高度 & 出度d表示的是树的度，即树中各个节点的度的最大值）

综上所述，用B-Tree作为索引结构效率是非常高的。

而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。

上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：





dmax=floor(pagesize/(keysize+datasize+pointsize))dmax=floor(pagesize/(keysize+datasize+pointsize))



floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。



MySQL索引实现

在MySQL中，索引属于**存储引擎**级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。

MyISAM索引实现

MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127161009725-1788644003.png)



这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，**主索引和辅助索引（Secondary key）在结构上没有任何区别**，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127161153647-1802334548.png)





同样也是一棵B+树，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。

MyISAM的索引方式也叫做“**非聚集**”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

InnoDB索引实现

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127161454428-323630182.png)







上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以**InnoDB要求表必须有主键**（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。

第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，上图为定义在Col3上的一个辅助索引：

![img](https://images2017.cnblogs.com/blog/758447/201801/758447-20180127161707334-628982052.png)



这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一棵B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

## 2：事务

ACID

原子性：要么都成功，要么都失败

一致性：最终目的

隔离性：事物之间隔离

持久性：一旦提交不能更改



脏读：读到事务未提交数据

不可重复读：多次读，读到数据不同

幻读：读到新增数据



事务隔离级别：





MVCC：

多版本并发控制（MVCC）是一种用来解决`读-写冲突`的**无锁并发控制**，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。



当前读
像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

快照读
像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现



**当前读，快照读和MVCC的关系**
准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念
而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现
要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 **3个隐式字段，undo日志 ，Read View** 等去完成的，具体可以看下面的MVCC实现原理



每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段

DB_TRX_ID
6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID
DB_ROLL_PTR
7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
DB_ROW_ID
6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190313213705258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NuYWlsTWFubg==,size_16,color_FFFFFF,t_70)



![img](https://img-blog.csdnimg.cn/20190313220528630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NuYWlsTWFubg==,size_16,color_FFFFFF,t_70)



## 3：Mysql解决幻读

1.1 快照读是什么？

因为MySQL默认的隔离级别是**可重复读**，这种隔离级别下，我们普通的SELECT语句都是快照读，也就是在一个事务内，多次执行SELECT语句，查询到的数据都是事务开始时那个状态的数据（这样就不会受其他事务修改数据的影响），这样就解决了幻读的问题。

1.2 那么innodb是怎么解决快照读的幻读问题的？

快照读就是每一行数据中额外保存两个隐藏的列，插入这个数据行时的版本号，删除这个数据行时的版本号（可能为空），滚动指针(指向undo log中用于事务回滚的日志记录)。

事务在对数据修改后，进行保存时，如果数据行的当前版本号与事务开始取得数据的版本号一致就保存成功，否则保存失败。

当我们不显式使用BEGIN来开启事务时，我们执行的每一条语句就是一个事务，每次开始事务时，会对系统版本号+1作为当前事务的ID。



## 4：数据库三大范式



1NF：确保每列保证原子性，即列不可分

2NF：属性完全依赖于主键，属性都是对象拥有的

3NF：属性和主键不可间接相关，（减少数据冗余，这样就可以通过主外键进行表之间的连接）



## 5：explain字段

![img](https://img-blog.csdn.net/20131107215222265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemh1eGluZWxp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**select_type**

查询中每个select的查询类型，如下：

1. SIMPLE：简单select，不使用union和子查询
2. PRIMARY：查询中包含任何复杂的子部分，最外层的select被标记为PRIMARY
3. UNION：union中第二个后面的select语句
4. DEPENDENT UNION
5. UNION RESULT

**type**

性能由好到差依次为：**system>const>eq_ref>ref>range>index>all**

**ref**

表示哪一列被使用了，常数表示这一列等于某个常数。

## 6：SQL慢查询

1：先对SQL语句进行explain，查看语句存在的问题

2：使用showprofile查看执行耗时，分析具体耗时原因



## 7：MySQL中的锁





## 8：mysql执行的底层（update select）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620162442577.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p3eDkwMDEwMg==,size_16,color_FFFFFF,t_70)



## 9：binlog undolog redolog





## 10：数据库设计的三大范式

第一范式（1NF）用来确保每列的原子性，要求每列（或者每个属性值）都是不可再分的最小数据单元（也称为最小的原子单元）。

第二范式（2NF）在第一范式的基础上更进一层，要求表中的每列都和主键相关，即要求实体的唯一性。如果一个表满足第一范式，并且除了主键以外的其他列全部都依赖于该主键，那么该表满足第二范式

第三范式（3NF）在第二范式的基础上更进一层，第三范式是确保每列都和主键列直接相关，而不是间接相关，即限制列的冗余性。如果一个关系满足第二范式，并且除了主键以外的其他列都依赖于主键列，列和列之间不存在相互依赖关系，则满足第三范式





# JUC：



## 一：并发编程的挑战

并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。在进行并发编程时，如果希望通过多线程执行任务让程序运行得更快，会面临非常多的挑战，比如上下文切换的问题、死锁的问题，以及受限于硬件和软件的资源限制问题



### 上下文切换

即使是单核处理器也支持多线程执行代码，CPU 通过给每个线程分配 CPU 时间片来实现这个机制。时间片是 CPU 分配给各个线程的时间，因为时间片非常短，所以 CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。CPU 通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换



#### 多线程一定快吗？

```java
public class Demo4 {
    public static final long count=100000L;

    public static void main(String[] args) throws InterruptedException {

        concurrency();
        serial();

    }
    private static void concurrency() throws InterruptedException{
        long start=System.currentTimeMillis();
        Thread thread=new Thread(new Runnable() {
            @Override
            public void run() {
                int a=0;
                for(long i=0;i<count;i++){
                    a+=5;
                }
            }
        });
        thread.start();

        int b=0;
        for(long i=0;i<count;i++){
            b--;
        }
        long time=System.currentTimeMillis()-start;
        thread.join();

        System.out.println("concurrency: "+time+"ms,b="+b);
    }

    private static void serial(){
        long start=System.currentTimeMillis();
        int a=0;
        for(long i=0;i<count;i++){
            a+=5;
        }
        int b=0;
        for(long i=0;i<count;i++){
            b--;
        }
        long time =System.currentTimeMillis()-start;
        System.out.println("serial: "+time+"ms,b="+b+",a="+a);
    }
}
```

![2022 02 15 14 11 28](https://s4.ax1x.com/2022/02/15/Hg4jH0.png)



为什么并发执行的速度会比串行慢呢？这是因为线程有创建和上下文切换的开销



#### 测试上下文切换次数和时长

下面我们来看看有什么工具可以度量上下文切换带来的消耗。
      使用 Lmbench3可以测量上下文切换的时长。
      使用 vmstat 可以测量上下文切换的次数。



#### 如何减少上下文切换

减少上下文切换的方法有无锁并发编程、CAS 算法、使用最少线程和使用协程。

1.  无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的 ID 按照 Hash 算法取模分段，不同的线程处理不同段的数据。
2.  CAS 算法。Java 的 Atomic 包使用 CAS 算法来更新数据，而不需要加锁。
3.  使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。
4.  协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。



#### 减少上下文切换实战



### 死锁

一旦产生死锁，就会造成系统功能不可用。下面这段代码会引起死锁

```java
public class DeadLock {
    private static String A="A";
    private static String B="B";

    public static void main(String[] args) throws Exception{

        deadLock();

    }

    private static void deadLock() throws InterruptedException {

        Thread t1=new Thread(new Runnable() {
            @Override
            public void run() {
                //得到A的锁
                synchronized (A){
                    try {
                        //因为暂停,导致t2先得到B的锁
                        Thread.currentThread().sleep(2000);

                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                    //得到B的锁
                    synchronized (B){
                        System.out.println("1");
                    }
                }
            }
        });

        Thread t2=new Thread(new Runnable() {
            @Override
            public void run() {
                //得到B的锁
                synchronized (B){
                    //得到A的锁
                    synchronized (A){
                        System.out.println("2");
                    }
                }
            }
        });
        t1.start();
        t2.start();

    }
}
```



现在我们介绍避免死锁的几个常见方法。

1.  避免一个线程同时获取多个锁。
2.  避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3.  尝试使用定时锁，使用 lock.tryLock（timeout）来替代使用内部锁机制。
4.  对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。



### 资源限制的挑战

资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。例如，服务器的带宽只有 2Mb/s，某个资源的下载速度是 1Mb/s 每秒，系统启动 10个线程下载资源，下载速度不会变成 10Mb/s，所以在进行并发编程时，要考虑这些资源的限制。硬件资源限制有带宽的上传/下载速度、硬盘读写速度和 CPU 的处理速度。软件资源限制有数据库的连接数和 socket 连接数等



## 二：Java 并发机制的底层实现原理

Java 代码在编译后会变成 Java 字节码，字节码被类加载器加载到 JVM 里，JVM 执行字节码，最终需要转化为汇编指令在 CPU 上执行，Java 中所使用的并发机制依赖于JVM 的实现和 CPU 的指令。



### volatile 的应用

在多线程并发编程中 synchronized 和 volatile 都扮演着重要的角色，volatile 是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果 volatile 变量修饰
符使用恰当的话，它比 synchronized 的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。



#### volatile 的定义与实现原理

Java 编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java 语言提供了 volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java 线程内存模型确保所有线程看到这个变量的值是一致的。



CPU 术语的定义：

![2022 02 15 15 34 07](https://s4.ax1x.com/2022/02/15/H2Vr9K.png)



![2022 02 15 15 37 32](https://s4.ax1x.com/2022/02/15/H2ZG5t.png)



#### volatile 的使用优化



### synchronized 的实现原理与应用

在多线程并发编程中 synchronized 一直是元老级角色，很多人都会称呼它为重量级锁。但是，随着 Java SE 1.6 对 synchronized 进行了各种优化之后，有些情况下它就并不那么重了。本文详细介绍 Java SE 1.6 中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程



先来看下利用 synchronized 实现同步的基础：Java 中的每一个对象都可以作为锁。具体表现为以下 3 种形式。

1.  对于普通同步方法，锁是当前实例对象。
2.  对于静态同步方法，锁是当前类的 Class 对象。
3.  对于同步方法块，锁是 Synchonized 括号里配置的对象



当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁到底存在哪里呢？锁里面会存储什么信息呢？



从 JVM 规范中可以看到 Synchonized 在 JVM 里的实现原理，JVM 基于进入和退出Monitor 对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用 monitorenter 和 monitorexit 指令实现的，而方法同步是使用另外一种方式实现的，细
节在 JVM 规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。

monitorenter 指令是在编译后插入到同步代码块的开始位置，而 monitorexit 是插入到方法结束处和异常处，JVM 要保证每个 monitorenter 必须有对应的 monitorexit 与之配对。任何对象都有一个 monitor 与之关联，当且一个 monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁



#### Java 对象头

在HotSpot虚拟机中，对象在堆内存中的存储布局可以划分为三个部分：对象头(Header)，实例数据(Instance Data) 和对齐填充(padding)。

![2022 02 16 16 34 34](https://s4.ax1x.com/2022/02/16/Hh9IG8.png)



![2022 02 16 16 38 28](https://s4.ax1x.com/2022/02/16/HhC6YV.png)



![2022 02 16 16 37 03](https://s4.ax1x.com/2022/02/16/HhC4m9.png)



![2022 02 16 16 37 41](https://s4.ax1x.com/2022/02/16/HhPCff.png)



#### 锁的升级与对比

Java SE 1.6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在 Java SE 1.6 中，锁一共有 4 种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。



##### 偏向锁

当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，以后该线程在进入和退出同步块时不需要进行 CAS 操作来加锁和解锁，只需简单地测试一下对象头的 Mark Word 里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下 Mark Word 中偏向锁的标识是否设置成 1（表示当前是偏向锁）：如果没有设置，则使用 CAS 竞争锁；如果设置了，则尝试使用CAS 将对象头的偏向锁指向当前线程。



###### 偏向锁的撤销

偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word 要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。

![2022 02 16 16 53 49](https://s4.ax1x.com/2022/02/16/HhAUqe.png)



###### 关闭偏向锁

偏向锁在 Java 6 和 Java 7 里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用 JVM 参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。



##### 轻量级锁

争夺锁导致的锁膨胀流程图：

![2022 02 16 19 25 19](https://s4.ax1x.com/2022/02/16/HhBxDf.png)



###### 轻量级锁加锁

线程在执行同步块之前，JVM 会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的 Mark Word 复制到锁记录中，官方称为 Displaced Mark Word。然后线程尝试使用 CAS 将对象头中的 Mark Word 替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

###### 轻量级锁解锁

轻量级解锁时，会使用原子的 CAS 操作将 Displaced Mark Word 替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。
因为自旋会消耗 CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争

![2022 02 16 19 32 27](https://s4.ax1x.com/2022/02/16/HhrGWj.png)



### 原子操作的实现原理

原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。



#### 术语定义

![2022 02 16 19 35 06](https://s4.ax1x.com/2022/02/16/HhrIte.png)



#### 处理器如何实现原子操作

使用总线锁保证原子性

使用缓存锁保证原子性



#### Java 如何实现原子操作

在 Java 中可以通过锁和循环 CAS 的方式来实现原子操作

##### 使用循环 CAS 实现原子操作

JVM 中的 CAS 操作正是利用了处理器提供的 CMPXCHG 指令实现的。自旋 CAS 实现的基本思路就是循环进行 CAS 操作直到成功为止，以下代码实现了一个基于 CAS 线程安全的计数器方法 safeCount 和一个非线程安全的计数器 count。

```java
public class CASDemo {
    private AtomicInteger atomicI=new AtomicInteger(0);
    private int i=0;

    public static void main(String[] args) {

        final CASDemo cas=new CASDemo();
        List<Thread> ts=new ArrayList<Thread>(600);
        long start=System.currentTimeMillis();
        for(int i=0;i<100;i++){
            Thread t=new Thread(new Runnable() {
                @Override
                public void run() {
                    for(int j=0;j<10000;j++){
                        cas.count();
                        cas.safeCount();
                    }
                }

            });
            ts.add(t);
        }

        for (Thread t:ts){
            t.start();
        }

        for(Thread t:ts){
            try {
                t.join();
            }catch (Exception e){
                e.printStackTrace();
            }
        }

        System.out.println(cas.i);
        System.out.println(cas.atomicI.get());
        System.out.println(System.currentTimeMillis()-start);

    }

    /**
     *  使用CAS实现线程安全计数器
     */
    private void safeCount(){
        for(;;){
            int i=atomicI.get();
            boolean suc=atomicI.compareAndSet(i,++i);
            if(suc){
                break;
            }
        }
    }

    /**
     * 非线程安全计数器
     */
    private void count(){
        i++;
    }
}

```



###### CAS 实现原子操作的三大问题：

###### **ABA 问题**

因为 CAS 需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA 问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加 1，那么A→B→A 就会变成 1A→2B→3A。从 Java 1.5 开始，JDK 的 Atomic 包里提供了一个类
AtomicStampedReference 来解决 ABA 问题。



###### 循环时间长开销大

自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。



###### 只能保证一个共享变量的原子操作

why？

Java中的CAS操作只是对CPU的cmpxchgq指令的一层封装。它的功能就是一次只原子地修改一个变量。

当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证
操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。



##### 使用锁机制实现原子操作

锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM 内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM 实现锁的方式都用了循环 CAS，即当一个线程想进入同步块的时候使用循环 CAS 的方式来获取锁，当它退出同步块的时候使用循环 CAS 释放锁



### 本章小结

本章我们一起研究了 volatile、synchronized 和原子操作的实现原理。Java 中的大部分容器和框架都依赖于本章介绍的 volatile 和原子操作的实现原理，了解这些原理对我们进行并发编程会更有帮助



## 三：Java内存模型

Java 线程之间的通信对程序员完全透明，内存可见性问题很容易困扰 Java 程序员，本章将揭开 Java 内存模型神秘的面纱。本章大致分 4 部分：

**Java 内存模型的基础**，主要介绍内存模型相关的基本概念；

**Java 内存模型中的顺序一致性**，主要介绍重排序与顺序一致性内存模型；

**同步原语**，主要介绍 3 个同步原语（synchronized、volatile 和 final）的内存语义及重排序规则在处理器中的实现；

**Java 内存模型的设计**，主要介绍 Java 内存模型的设计原理，及其与处理器内存模型和顺序一致性内存模型的关系



### Java 内存模型的基础

#### 并发编程模型的两个关键问题

在并发编程中，需要处理两个关键问题：**线程之间如何通信**及**线程之间如何同步**（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：==共享内存==和==消息传递==

Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明



#### Java 内存模型的抽象结构

在 Java 中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享（本章用“共享变量”这个术语代指实例域，静态域和数组元素）。



Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

![2022 02 16 20 21 58](https://s4.ax1x.com/2022/02/16/HhRH56.png)



如果线程 A 与线程 B 之间要通信的话，必须要经历下面 2 个步骤。

1.  线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。
2.  线程 B 到主内存中去读取线程 A 之前已更新过的共享变量



![2022 02 16 20 24 16](https://s4.ax1x.com/2022/02/16/HhWiPf.png)



JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 Java程序员提供内存可见性保证



#### 从源代码到指令序列的重排序

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3 种类型。

1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序。现代处理器采用了指令级并行技术（InstructionLevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行



![2022 02 16 20 29 21](https://s4.ax1x.com/2022/02/16/HhWhJf.png)



#### 并发编程模型的分类

虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！



![2022 02 16 20 35 22](https://s4.ax1x.com/2022/02/16/Hhfc1U.png)

![2022 02 16 20 35 35](https://s4.ax1x.com/2022/02/16/HhffB9.png)

为了保证内存可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。



#### happens-before 简介

从 JDK 5 开始，Java 使用新的 JSR-133 内存模型（除非特别说明，本文针对的都是JSR-133 内存模型）。JSR-133 使用 happens-before 的概念来阐述操作之间的内存可见性。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在 happens-before 关系。



### 重排序

#### 数据依赖性

![2022 02 16 20 39 35](https://s4.ax1x.com/2022/02/16/HhhPgS.png)

编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。这
里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑



#### as-if-serial 语义



#### 程序顺序规则



#### 重排序对多线程的影响

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as-ifserial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果



### 顺序一致性

顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照



#### 数据竞争与顺序一致性

#### 顺序一致性内存模型

#### 同步程序的顺序一致性效果

#### 未同步程序的执行特性



### volatile 的内存语义

当声明共享变量为 volatile 后，对这个变量的读/写将会很特别。为了揭开 volatile 的神秘面纱，下面将介绍 volatile 的内存语义及 volatile 内存语义的实现

#### volatile 的特性

![2022 02 16 21 25 46](https://s4.ax1x.com/2022/02/16/Hh78bD.png)



![2022 02 16 21 26 01](https://s4.ax1x.com/2022/02/16/Hh7t5d.png)



对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。锁的语义决定了临界区代码的执行具有原子性。这意味着，即使是 64 位的 long 型和 double 型变量，只要它是 volatile 变量，对该变量的读/写就具有原子性。如果是多个volatile 操作或类似于 volatile++这种复合操作，这些操作整体上不具有原子性



简而言之，volatile 变量自身具有下列特性。

1.   可见性。对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。
2.   原子性：**对任意单个 volatile 变量的读/写具有原子性**，**但类似于 volatile++这种复合操作不具有原子性**。



#### volatile 写-读建立的 happens-before 关系

#### volatile 写-读的内存语义

![2022 02 16 21 35 56](https://s4.ax1x.com/2022/02/16/HhHT6P.png)

#### volatile 内存语义的实现

X86 处理器仅会对写-读操作做重排序。

![2022 02 16 21 34 53](https://s4.ax1x.com/2022/02/16/HhHsQx.png)



#### JSR-133 为什么要增强 volatile 的内存语义



### 锁的内存语义

众所周知，锁可以让临界区互斥执行。这里将介绍锁的另一个同样重要，但常常被忽视的功能：锁的内存语义



#### 锁的释放-获取建立的 happens-before 关系

锁是 Java 并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。



#### 锁的释放和获取的内存语义

当线程释放锁时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存中

![2022 02 16 23 04 58](https://s4.ax1x.com/2022/02/16/H4eYCj.png)





当线程获取锁时，JMM 会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。

![2022 02 16 23 08 28](https://s4.ax1x.com/2022/02/16/H4e5VO.png)



![2022 02 16 23 08 51](https://s4.ax1x.com/2022/02/16/H4ebRA.png)



#### 锁 内存语义的实现

本文将借助 ReentrantLock 的源代码，来分析锁内存语义的具体实现机制

```java
public class ReentrantLockExample {
    int a=0;
    ReentrantLock lock=new ReentrantLock();
    
    public void writer(){
        lock.lock();//获取锁
        try {
            a++;
        }finally {
            lock.unlock();//释放锁
        }
    }
    
    public void reader(){
        lock.lock();
        try {
            int i=a;
            System.out.println(i);
            
        }finally {
            lock.unlock();
        }
    }
}
```

在 ReentrantLock 中，调用 lock()方法获取锁；调用 unlock()方法释放锁

ReentrantLock 的实现依赖于 Java 同步器框架 AbstractQueuedSynchronizer（本文简称之为 AQS）。AQS 使用一个整型的 volatile 变量（命名为 state）来维护同步状态，马上我们会看到，这个 volatile 变量是 ReentrantLock 内存语义实现的关键



ReentrantLock类图

![](https://ftp.bmp.ovh/imgs/2022/02/854b3e8ddd453a45.png)



ReentrantLock 分为公平锁和非公平锁，我们首先分析公平锁。使用公平锁时，加锁
方法 lock()调用轨迹如下。

1. ReentrantLock:lock()。

2. FairSync:lock()。

3. AbstractQueuedSynchronizer:acquire(int arg)。

4. ReentrantLock:tryAcquire(int acquires)。

  

  在第 4 步真正开始加锁，下面是该方法的源代码

```java
protected final boolean tryAcquire(int acquires) {
     final Thread current = Thread.currentThread();
     int c = getState(); // 获取锁的开始，首先读 volatile 变量 state
     if (c == 0) {
         if (isFirst(current) && compareAndSetState(0, acquires)) {
             setExclusiveOwnerThread(current);
             return true;
         }
     } else if (current == getExclusiveOwnerThread()) {
         int nextc = c + acquires;
         if (nextc < 0) throw new Error("Maximum lock count exceeded");
         setState(nextc);
         return true;
     }
     return false;
}
```



![](https://s3.bmp.ovh/imgs/2022/02/3ce7206a64864918.png)



```java
protected final boolean tryRelease(int releases) {
     int c = getState() - releases;
     if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException();
     boolean free = false;
     if (c == 0) {
         free = true;
         setExclusiveOwnerThread(null);
     }
     setState(c); // 释放锁的最后，写 volatile 变量 state
     return free;
}
```



![](https://s3.bmp.ovh/imgs/2022/02/be9419d972c98f33.png)

![](https://s3.bmp.ovh/imgs/2022/02/8b07e93bd2bc234e.png)





#### concurrent 包的实现

![](https://s3.bmp.ovh/imgs/2022/02/d12d28c838a21dbc.png)



Java 的 CAS 会使用现代处理器上提供的高效机器级别的原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键

volatile 变量的读/写和 CAS 可以实现线程之间的通信。把这些特性整合在一起，就形成了整个 concurrent 包得以实现的基石。如果我们仔细分析 concurrent 包的源代码实现，会发现一个通用化的实现模式

```java
首先，声明共享变量为 volatile。
然后，使用 CAS 的原子条件更新来实现线程之间的同步。
同时，配合以 volatile 的读/写和 CAS 所具有的 volatile 读和写的内存语义来实现线程之间的通信
```

==concurrent 包的实现示意图==

![](https://s3.bmp.ovh/imgs/2022/02/177eeca9d55b1d3c.png)



### final 域的内存语义

与前面介绍的锁和 volatile 相比，对 final 域的读和写更像是普通的变量访问。下面将介绍 final 域的内存语义

#### final 域的重排序规则

#### 写 final 域的重排序规则

#### 读 final 域的重排序规则

#### final 域为引用类型

#### 为什么 final 引用不能从构造函数内“溢出”

#### final 语义在处理器中的实现

#### JSR-133 为什么要增强 final 的语义





### happens-before





### 双重检查锁定与延迟初始化

在 Java 多线程程序中，有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双重检查锁定是常见的延迟初始化技术，但它是一个错误的用法。本文将分析双重检查锁定的错误根源，以及两种线程安全的延迟初始化方案。

#### 双重检查锁定的由来

在 Java 程序中，有时候可能需要推迟一些高开销的对象初始化操作，并且只有在使用这些对象时才进行初始化。此时，程序员可能会采用延迟初始化。但要正确实现线程安全的延迟初始化需要一些技巧，否则很容易出现问题。比如，下面是非线程安全的延迟初始化对象的示例代码。

```java
public class UnsafeLazyInitialization {
     private static Instance instance;
     public static Instance getInstance() {
         if (instance == null) // 1：A 线程执行
             instance = new Instance(); // 2：B 线程执行
     			return instance;
     }
}
```

在 UnsafeLazyInitialization 类中，假设 A 线程执行代码 1 的同时，B 线程执行代码2。此时，线程 A 可能会看到 instance 引用的对象还没有完成初始化

我们可以对 getInstance()方法做同步处理来实现线程安全的延迟初始化。示例代码如下

```java
public class SafeLazyInitialization {
     private static Instance instance;
     public synchronized static Instance getInstance() {
         if (instance == null) instance = new Instance();
         return instance;
     }
}
```

由于对 getInstance()方法做了同步处理，synchronized 将导致性能开销。如果getInstance()方法被多个线程频繁的调用，将会导致程序执行性能的下降。在早期的 JVM 中，synchronized（甚至是无竞争的 synchronized）存在巨大的性能开销。因此，人们想出了一个“聪明”的技巧：双重检查锁定（Double-Checked Locking）。

```java
public class DoubleCheckedLocking { // 1
     private static Instance instance; // 2
     public static Instance getInstance() { // 3
         if (instance == null) { // 4:第一次检查
             synchronized (DoubleCheckedLocking.class) { // 5:加锁
                 if (instance == null) // 6:第二次检查
                     instance = new Instance(); // 7:问题的根源出在这里
              } // 8
          } // 9 
          return instance; // 10
     } // 11
}
```

双重检查锁定看起来似乎很完美，==但这是一个错误的优化！==  在线程执行到第 4 行，代码读取到 instance 不为 null 时，instance 引用的对象有可能还没有完成初始化!!!



#### 问题的根源

![](https://s3.bmp.ovh/imgs/2022/02/ef32ea977374f2c4.png)

![](https://s3.bmp.ovh/imgs/2022/02/43c0b5208d49bff4.png)



#### 基于 volatile 的解决方案

对于前面的基于双重检查锁定来实现延迟初始化的方案（指 DoubleCheckedLocking示例代码），只需要做一点小的修改（把 instance 声明为 volatile 型），就可以实现线程安全的延迟初始化。请看下面的示例代码。

```java
public class SafeDoubleCheckedLocking {
     private volatile static Instance instance;
     public static Instance getInstance() {
         if (instance == null) {
             synchronized (SafeDoubleCheckedLocking.class) {
                 if (instance == null)
                     instance = new Instance(); // instance 为 volatile，现在没问题了
             }
         }
         return instance;
     }
}
```

当声明对象的引用为 volatile 后，3.8.2 节中的 3 行伪代码中的 2 和 3 之间的重排序，在多线程环境中将会被禁止。



#### 基于类初始化的解决方案

JVM 在类的初始化阶段（即在 Class 被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM 会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。基于这个特性，可以实现另一种线程安全的延迟初始化方案

```java
public class InstanceFactory {
     private static class InstanceHolder {
         public static Instance instance = new Instance();
     }
     public static Instance getInstance() {
         return InstanceHolder.instance; // 这里将导致 InstanceHolder 类被初始化
     }
}
```



### Java 内存模型综述

### 本章小结





## 四：Java 并发编程基础

Java 从诞生开始就明智地选择了内置对多线程的支持，这使得 Java 语言相比同一时期的其他语言具有明显的优势。==线程作为操作系统调度的最小单元==，多个线程能够同时执行，这将显著提升程序性能，在多核环境中表现得更加明显。但是，过多地创建线程和对线程的不当管理也容易造成问题。本章将着重介绍 Java 并发编程的基础知识，从启动一个线程到线程间不同的通信方式，最后通过简单的线程池示例以及应用（简单的Web 服务器）来串联本章所介绍的内容。

### 线程简介

#### 什么是线程

现代操作系统在运行一个程序时，会为其创建一个进程。例如，启动一个 Java 程序，操作系统就会创建一个 Java 进程。现代操作系统调度的最小单元是线程，也叫轻量级进程（Light Weight Process），在一个进程里可以创建多个线程，这些线程都拥有各自的**计数器、堆栈和局部变量**等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行

一个 Java 程序从 main()方法开始执行，然后按照既定的代码逻辑执行，看似没有其他线程参与，但实际上 Java 程序天生就是多线程程序，因为执行 main()方法的是一个名称为 main 的线程

![](https://s3.bmp.ovh/imgs/2022/02/8bd17a8d19f7dc36.png)



#### 为什么要使用多线程

正确使用多线程，总是能够给开发人员带来显著的好处，而使用多线程的原因主要有以下几点。

1.  更多的处理器核心

随着处理器上的核心数量越来越多，以及超线程技术的广泛运用，现在大多数计算机都比以往更加擅长并行计算，而处理器性能的提升方式，也从更高的主频向更多的核心发展。如何利用好处理器上的多个核心也成了现在的主要问题。线程是大多数操作系统调度的基本单元，一个程序作为一个进程来运行，程序运行过程中能够创建多个线程，而一个线程在一个时刻只能运行在一个处理器核心上。试想
一下，一个单线程程序在运行时只能使用一个处理器核心，那么再多的处理器核心加入也无法显著提升该程序的执行效率。相反，如果该程序使用多线程技术，将计算逻辑分配到多个处理器核心上，就会显著减少程序的处理时间，并且随着更多处理器核心的加入而变得更有效率

2.  更快的响应时间
3.  更好的编程模型



#### 线程优先级

在 Java 线程中，通过一个整型成员变量 priority 来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过 setPriority(int)方法来修改优先级，默认优先级是 5



####  线程的状态

Java 线程在运行的生命周期中可能处于表 4-1 所示的 6 种不同的状态，在给定的一个时刻，线程只能处于其中的一个状态

![](https://s3.bmp.ovh/imgs/2022/02/92b8263cc6db10ab.png)

**Java 线程状态变迁**

![](https://s3.bmp.ovh/imgs/2022/02/dfc28954b2973991.png)



![](https://s3.bmp.ovh/imgs/2022/02/e4edcc35b60cf540.png)



#### Daemon 线程

Daemon 线程是一种支持型线程(常被叫做守护线程)，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个 Java 虚拟机中不存在非 Daemon 线程的时候，Java 虚拟机将会退出。可以通过调用 Thread.setDaemon(true)将线程设置为 Daemon 线程。



### 启动和终止线程

在前面章节的示例中通过调用线程的 start()方法进行启动，随着 run()方法的执行完毕，线程也随之终止，大家对此一定不会陌生，下面将详细介绍线程的启动和终止

#### 构造线程

在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，如线程所属的线程组、线程优先级、是否是 Daemon 线程等信息。

#### 启动线程

线程对象在初始化完成之后，调用 start()方法就可以启动这个线程。线程 start()方法的含义是：当前线程（即 parent 线程）同步告知 Java 虚拟机，只要线程规划器空闲，应立即启动调用 start()方法的线程。
注意：启动一个线程前，最好为这个线程设置线程名称，因为这样在使用 jstack分析程序或者进行问题排查时，就会给开发人员提供一些提示，自定义的线程最好能够起个名字。



#### 理解中断

中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作。

从 Java 的 API 中可以看到，许多声明抛出 InterruptedException 的方法（例如Thread.sleep(longmillis)方法）这些方法在抛出 InterruptedException 之前，Java 虚拟机会先将该线程的中断标识位清除，然后抛出 InterruptedException，此时调用 isInterrupted()
方法将会返回 false。



#### 过期的 suspend()、resume()和 stop()



#### 安全地终止线程

在 4.2.3 节中提到的中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。除了中断以外，还可以利用一个 boolean 变量来控制是否需要停止任务并终止该线程

```java
public class CountThread {
    public static void main(String[] args) throws Exception{
        Runner one =new Runner();
        Thread countT=new Thread(one,"countThread");
        countT.start();

        TimeUnit.SECONDS.sleep(1);
        countT.interrupt();

        Runner two=new Runner();

        countT=new Thread(two,"countThread");
        countT.start();

        TimeUnit.SECONDS.sleep(1);
        two.cancel();

    }

    private static class Runner implements Runnable{
        private long i;
        private volatile boolean on=true;

        @Override
        public void run() {
            while (on&&!Thread.currentThread().isInterrupted()){
                i++;
            }
            System.out.println("count i= "+i);
        }

        public void cancel(){
            on=false;
        }
    }
}

```

示例在执行过程中，main 线程通过中断操作和 cancel()方法均可使 CountThread 得以终止。这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅

### 线程间通信

线程开始运行，拥有自己的栈空间，就如同一个脚本一样，按照既定的代码一步一步地执行，直到终止。但是，每个运行中的线程，如果仅仅是孤立地运行，那么没有一点儿价值，或者说价值很少，如果多个线程能够相互配合完成工作，这将会带来巨大的价值

#### volatile 和 synchronized 关键字

Java 支持多个线程同时访问一个对象或者对象的成员变量，由于每个线程可以拥有这个变量的拷贝（虽然对象以及成员变量分配的内存是在共享内存中的，但是每个执行的线程还是可以拥有一份拷贝，这样做的目的是加速程序的执行，这是现代多核处理器的一个显著特性），所以程序在执行过程中，一个线程看到的变量并不一定是最新的。

关键字 volatile 可以用来修饰字段（成员变量），就是告知程序任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新回共享内存，它能保证所有线程对变量访问的可见性



关键字 synchronized 可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性。



在代码清单 4-10 所示的例子中，使用了同步块和同步方法，通过使用 javap 工具查看生成的 class 文件信息来分析 synchronized 关键字的实现细节，示例如下

[![H7Npn0.png](https://s4.ax1x.com/2022/02/18/H7Npn0.png)](https://imgtu.com/i/H7Npn0)



![](https://s3.bmp.ovh/imgs/2022/02/d176c42885edc488.png)



![](https://s3.bmp.ovh/imgs/2022/02/ddfda7166617301d.png)



#### 等待/通知机制

一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个过程开始于一个线程，而最终执行又是另一个线程。前者是生产者，后者就是消费者，这种模式隔离了“做什么”（what）和“怎么做”（How），在功能层面上实现了解耦，体系结构上具备了良好的伸缩性，但是在 Java 语言中如何实现类似的功能呢？

![](https://s3.bmp.ovh/imgs/2022/02/edc046b04a53d30d.png)



等待/通知机制，是指一个线程 A 调用了对象 O 的 wait()方法进入等待状态，而另一个线程 B 调用了对象 O 的 notify()或者 notifyAll()方法，线程 A 收到通知后从对象 O 的wait()方法返回，进而执行后续操作。上述两个线程通过对象 O 来完成交互，而对象上的wait()和 notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作

调用 wait()、notify()以及 notifyAll()时需要注意的细节

![](https://s3.bmp.ovh/imgs/2022/02/79c857fb0ebc0841.png)

从上述细节中可以看到，等待/通知机制依托于同步机制，其目的就是确保等待线程从 wait()方法返回时能够感知到通知线程对变量做出的修改。

#### 等待/通知的经典范式

从 4.3.2 节中的 Concurrency 示例中可以提炼出等待/通知的经典范式，该范式分为两
部分，分别针对等待方（消费者）和通知方（生产者）

![](https://s3.bmp.ovh/imgs/2022/02/f13e3699aa58bbf8.png)

![](https://s3.bmp.ovh/imgs/2022/02/057c73a4da577543.png)



#### 管道输入/输出流



#### Thread.join()的使用

如果一个线程 A 执行了 thread.join()语句，其含义是：当前线程 A 等待 thread 线程终止之后才从 thread.join()返回。线程 Thread 除了提供 join()方法之外，还提供了 join(long millis)和 join(longmillis,int nanos)两个具备超时特性的方法。这两个超时方法表示，如果
线程 thread 在给定的超时时间里没有终止，那么将会从该超时方法中返回

```java
public class JoinDemo {
      public static void main(String[] args) throws Exception{

          Thread pre=Thread.currentThread();
          for(int i=0;i<10;i++){
              Thread thread=new Thread(new Dimino(pre),String.valueOf(i));
              thread.start();
              pre=thread;
          }

      }

      static class Dimino implements Runnable{

          private Thread thread;
          public Dimino(Thread thread){
              this.thread=thread;
          }
          @Override
          public void run() {
              try {
                  thread.join();
              }catch (InterruptedException e){
                  e.printStackTrace();
              }
              System.out.println(thread.getName()+"terminate");

          }
      }
  

}

Thread 2等待Thread 1结束后再执行
```



#### ThreadLocal 的使用

ThreadLocal，即线程变量，是一个以 ThreadLocal 对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个 ThreadLocal 对象查询到绑定在这个线程上的一个值。可以通过 set(T)方法来设置一个值，在当前线程下再通过 get()方法获取到原先设置的值

在代码清单 4-15 所示的例子中，构建了一个常用的 Profiler 类，它具有 begin()和end()两个方法，而 end()方法返回从 begin()方法调用开始到 end()方法被调用时的时间差，单位是毫秒

```java
public class Profiler {
    
    // 第一次 get()方法调用时会进行初始化（如果 set 方法没有调用），每个线程会调用一次
    private static final ThreadLocal<Long> TIME_THREADLOCAL = new ThreadLocal<Long>();
    
    protected Long initialValue() {
        return System.currentTimeMillis();
    }
    public static final void begin() {
        TIME_THREADLOCAL.set(System.currentTimeMillis());
    }


    public static final long end() {
        return System.currentTimeMillis() - TIME_THREADLOCAL.get();
    }


    public static void main(String[] args) throws Exception {
        Profiler.begin();
        TimeUnit.SECONDS.sleep(1);
        System.out.println("Cost: " + Profiler.end() + " mills");
    }
}
```



### 线程应用实例

#### 等待超时模式

[![URyk1.png](https://i.w3tt.com/2022/02/20/URyk1.png)](https://imgtg.com/image/URyk1)



![](https://s3.bmp.ovh/imgs/2022/02/307215e11eca9391.png)



#### 一个简单的数据库连接池示例



#### 线程池技术及其示例

对于服务端的程序，经常面对的是客户端传入的短小（执行时间短、工作内容较为单一）任务，需要服务端快速处理并返回结果。如果服务端每次接受到一个任务，创建一个线程，然后进行执行，这在原型阶段是个不错的选择，但是面对成千上万的任务递交进服务器时，如果还是采用一个任务一个线程的方式，那么将会创建数以万记的线程，这不是一个好的选择。因为这会使操作系统频繁的进行线程上下文切换，无故增加系统的负载，而线程的创建和消亡都是需要耗费系统资源的，也无疑浪费了系统资源。

线程池技术能够很好地解决这个问题，它预先创建了若干数量的线程，并且不能由用户直接对线程的创建进行控制，在这个前提下重复使用固定或较为固定数目的线程来完成任务的执行。这样做的好处是，一方面，消除了频繁创建和消亡线程的系统资源开销，另一方面，面对过量任务的提交能够平缓的劣化。

客户端可以通过 execute(Job)方法将 Job 提交入线程池执行，而客户端自身不用等Job 的执行完成。除了 execute(Job)方法以外，线程池接口提供了增大/减少工作者线程以及关闭线程池的方法。这里工作者线程代表着一个重复执行 Job 的线程，而每个由客户端提交的 Job 都将进入到一个工作队列中等待工作者线程的处理

从线程池的实现可以看到，当客户端调用 execute(Job)方法时，会不断地向任务列表jobs 中添加 Job，而每个工作者线程会不断地从 jobs 上取出一个 Job 进行执行，当 jobs为空时，工作者线程进入等待状态。添加一个 Job 后，对工作队列 jobs 调用了其 notify()方法，而不是 notifyAll()方法，因为能够确定有工作者线程被唤醒，这时使用 notify()方法将会比 notifyAll()方法获得更小的开销（避免将等待队列中的线程全部移动到阻塞队列中）。

可以看到，线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端线程，客户端线程将任务放入工作队列后便返回，而工作者线程则不断地从工作队列上取出工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上，当有客户端提交了一个任务之后会通知任意一个工作者线程，随着大量的任务被提交，更多的工作者线程会被唤醒。



#### 一个基于线程池技术的简单 Web 服务器



### 本章小节

本章从介绍多线程技术带来的好处开始，讲述了如何启动和终止线程以及线程的状态，详细阐述了多线程之间进行通信的基本方式和等待/通知经典范式。在线程应用示例中，使用了等待超时、数据库连接池以及简单线程池 3 个不同的示例巩固本章前面章节所介绍的 Java 多线程基础知识。最后通过一个简单的 Web 服务器将上述知识点串联起来，加深我们对这些知识点的理解。



## 五：Java 中的锁

本章将介绍 Java 并发包中与锁相关的 API 和组件，以及这些 API 和组件的使用方式和实现细节。内容主要围绕两个方面：

1.  使用，通过示例演示这些组件的使用方法以及详细介绍与锁相关的 API；

2.  实现，通过分析源码来剖析实现细节，因为理解实现的细节方能更加得心应手且正确地使用这些组件。

### Lock 接口

![](https://s3.bmp.ovh/imgs/2022/02/ffe872ffcf60abdf.png)

![](https://s3.bmp.ovh/imgs/2022/02/72987eda7f928609.png)

![](https://s3.bmp.ovh/imgs/2022/02/0f9e9c8f82e1c903.png)

Lock 接口的实现基本都是通过聚合了一个同步器的子类来完成线程访问控制的



### 队列同步器

队列同步器 AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个 int 成员变量表示同步状态，通过内置的 FIFO 队列来完成资源获取线程的排队工作



同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的 3 个方法（getState()、setState(int newState)和 compareAndSetState(int expect,int 
update)）来进行操作，因为它们能够保证状态的改变是安全的。子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock 和 CountDownLatch 等）。



#### 队列同步器的接口与示例

同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。重写同步器指定的方法时，需要使用同步器提供的如下 3 个方法来访问或修改同步状态。

1.  getState()：获取当前同步状态。
2.  setState(int newState)：设置当前同步状态。
3.  compareAndSetState(int expect,int update)：使用 CAS 设置当前状态，该方法能够保证状态设置的原子性 

![](https://s3.bmp.ovh/imgs/2022/02/ac060d15492265ff.png)

同步器提供的模板方法基本上分为 3 类：独占式获取与释放同步状态、共享式获取与释放同步状态和查询同步队列中的等待线程情况。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义



#### 队列同步器的实现分析

接下来将从实现角度分析同步器是如何完成线程同步的，主要包括：

1.  同步队列
2.  独占式同步状态获取与释放
3.  共享式同步状态获取与释放
4.  超时获取同步状态等同步器的核心数据结构与模板方法

## 1：synchronized及底层实现（优化）

Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：

普通同步方法（实例方法），锁是当前实例对象 ，进入同步代码前要获得当前实例的锁
静态同步方法，锁是当前类的class对象 ，进入同步代码前要获得当前类对象的锁
同步方法块，锁是括号里面的对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。



synchronized关键字解决的是多个线程之间访问资源的同步性，调用操作系统内核态做同 步，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，**Java 的线程是映射到操作系统的原生线程**之上的。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

synchronized关键字最主要的三种使用方式：

修饰实例方法**:** 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

修饰静态方法**:** 也就是给当前类加锁，会作用于类的所有对象实例。因为访问静态synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。

修饰代码块**:** 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

synchronized 关键字底层原理属于 JVM 层面。

① synchronized 同步语句块的情况：synchronized 同步语句块的实现使用的是monitorenter和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。

② synchronized 修饰方法的的情况：JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。



## 2：lock

lock是一个接口

实现类：





1、Synchronized 内置的Java关键字， Lock 是一个Java接口
2、Synchronized 无法判断获取锁的状态，Lock 可以判断是否获取到了锁
3、Synchronized 会自动释放锁，lock 必须要手动释放锁！如果不释放锁，死锁
4、Synchronized 线程 1（获得锁，阻塞）、线程2（等待，傻傻的等）；Lock锁就不一定会等待下去；
5、Synchronized 可重入锁，不可以中断的，非公平；Lock ，可重入锁，可以判断锁，非公平（可以自己设置）；
6、Synchronized 适合锁少量的代码同步问题，Lock 适合锁大量的同步代码！





## 3：ReentrantLock

可重入就是说某个线程已经获得某个锁，可以再次获取这个锁而不会出现死锁

独占锁，可以中断

手动lock ，unlock

可以实现公平锁，默认非公平



ReentrantLock底层使用了CAS+AQS队列

0.每一个ReentrantLock自身维护一个AQS队列记录申请锁的线程信息；

1.通过大量CAS保证多个线程竞争锁的时候的并发安全；

2.可重入的功能是通过维护state变量来记录重入次数实现的。

3.公平锁需要维护队列，通过AQS队列的先后顺序获取锁，缺点是会造成大量线程上下文切换；

4.非公平锁可以直接抢占，所以效率更高；



ReentrantLock的基本实现可以概括为：先通过CAS尝试获取锁。如果此时已经有线程占据了锁，那就加入AQS队列并且被挂起。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。

## 4：volatile

轻量级同步机制

1. volatile保证可见性



2. volatile不保证原子性

​     如何解决：
​           1 使用synchronized

​           2 使用juc下的atomicInteger



3. volatile禁止指令重排

**使用内存屏障**

内存屏障其实就是一个CPU指令，在硬件层面上来说可以扥为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。主要有两个作用：

（1）阻止屏障两侧的指令重排序；

（2）强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。

JMM（java memory model）

1 可见性 2 原子性 3 有序性 

## 5：CAS

compare and set





CAS ： 比较当前工作内存中的值和主内存中的值，如果这个值是期望的，那么则执行操作！如果不是就
一直循环！
缺点：
1、 循环会耗时
2、一次性只能保证一个共享变量的原子性
3、ABA问题





解决ABA 问题，引入原子引用！ 对应的思想：乐观锁！
带版本号 的原子操作！















## 6：AQS

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181128142923147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L211bGluc2VuNzc=,size_16,color_FFFFFF,t_70)

## 7：线程池





![img](https://upload-images.jianshu.io/upload_images/5363507-52a4fdee539b6472.png?imageMogr2/auto-orient/strip|imageView2/2/w/589/format/webp)







```java

public class Demo1 {
    public static void main(String[] args) {


   /**
     * 三大方法
     */
     ExecutorService threadPool1 = Executors.newSingleThreadExecutor();// 单个线程
//   ExecutorService threadPool2= Executors.newFixedThreadPool(5);// 创建一个固定大小的线程池
  ExecutorService threadPool3= Executors.newCachedThreadPool();// 可伸缩的，遇强则强，遇弱则弱
   try {
        for (int i = 0; i < 5; i++) {

            threadPool3.execute(()->{
                System.out.println(Thread.currentThread().getName()+" ok ");
            });
        }
    } catch (Exception e) {
        e.printStackTrace();
    } finally {
        threadPool3.shutdown();
    }

    System.out.println("---------------");

    /**
     * 7大参数：
     * int corePoolSize, // 核心线程池大小
     * int maximumPoolSize, // 最大核心线程池大小
     * long keepAliveTime, // 超时了没有人调用就会释放
     * TimeUnit unit, // 超时单位
     * BlockingQueue<Runnable> workQueue, // 阻塞队列
     * ThreadFactory threadFactory, // 线程工厂：创建线程的，一般不用动
     * RejectedExecutionHandler handle // 拒绝策略
     */

    /**
     * 4大拒绝策略：
     * new ThreadPoolExecutor.AbortPolicy() // 银行满了，还有人进来，不处理这个人的，抛出异常
     * new ThreadPoolExecutor.CallerRunsPolicy() // 哪来的去哪里！
     * new ThreadPoolExecutor.DiscardPolicy() //队列满了，丢掉任务，不会抛出异常！
     * new ThreadPoolExecutor.DiscardOldestPolicy() //队列满了，尝试去和最早的竞争，也不会抛出异常！
     */

    System.out.println(Runtime.getRuntime().availableProcessors());

    System.out.println("--------------");
    //自定义线程池
    ExecutorService threadPool2 = new ThreadPoolExecutor(
            2,
            5,
            3,
            TimeUnit.SECONDS,
            new LinkedBlockingDeque<>(3),
            Executors.defaultThreadFactory(),
            new ThreadPoolExecutor.AbortPolicy()

    );

    try {
        for (int i = 0; i < 9; i++) {

            threadPool2.execute(()->{
                System.out.println(Thread.currentThread().getName()+" ok ");
            });
        }
    } catch (Exception e) {
        e.printStackTrace();
    } finally {
        threadPool2.shutdown();
    }
    
   }
}
```



核心线程池ThreadPoolExecutor内部参数：

1. corePoolSize：指定了线程池中的线程数量
2. maximumPoolSize：指定了线程池中的最大线程数量
3. keepAliveTime：线程池维护线程所允许的空闲时间
4. unit: keepAliveTime 的单位。
5. workQueue：任务队列，被提交但尚未被执行的任务。
6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
7. handler：拒绝策略。当任务太多来不及处理，如何拒绝任务。



**线程池的执行流程**

1. 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务
2. 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列
3. 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务
4. 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException

线程池的拒绝策略

1. ThreadPoolExecutor.**Abort**Policy:丢弃任务并抛出RejectedExecutionException异常。
2. ThreadPoolExecutor.**Discard**Policy：丢弃任务，但是不抛出异常。
3. ThreadPoolExecutor.**DiscardOldest**Policy：丢弃队列最前面的任务，然后重新提交被拒绝的任务
4. ThreadPoolExecutor.**CallerRuns**Policy：由调用线程（提交任务的线程）处理该任务

## 8：countdownlatch，cyclicbarrier，semaphore

1) CountDownLatch



```java
//计数器,减法计数器
public class CountDownLatchDemo {
    public static void main(String[] args) throws InterruptedException {

        CountDownLatch countDownLatch = new CountDownLatch(6);
        for (int i = 1; i <=6; i++) {
            new Thread(()->{
                System.out.println(Thread.currentThread().getName()+" go out");
                countDownLatch.countDown();

            },String.valueOf(i)).start();



        }
        countDownLatch.await();//等待计数器归零，再向下执行
        System.out.println("close door");
    }


}
```



2) CyclicBarrier

```java
public class CyclicBarrierDemo {
    public static void main(String[] args) {
        CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -> {
            System.out.println("7个龙珠集齐");
        });

        for (int i = 1; i <= 7; i++) {
            final int temp=i;
            new Thread(()->{
                System.out.println(Thread.currentThread().getName()+"收集了"+temp+"个龙珠");
                try {
                    cyclicBarrier.await();
                }catch (Exception e){
                    e.printStackTrace();
                }

            },String.valueOf(i)).start();

        }

    }

}
```



3) Semaphore

```java
public class SemaphoreDemo {
    public static void main(String[] args) {

        Semaphore semaphore = new Semaphore(3);

        for (int i = 1; i <= 6 ; i++) {
            new Thread(()->{
                //acquire() 得到
                try {
                    semaphore.acquire();
                    System.out.println(Thread.currentThread().getName()+"抢到车位");
                    TimeUnit.SECONDS.sleep(2);
                    System.out.println(Thread.currentThread().getName()+"离开车位");

                } catch (InterruptedException e) {
                    e.printStackTrace();
                }finally {
                    semaphore.release();
                }
            },String.valueOf(i)).start();

        }

    }

}
```



1,CountdownLatch适用于所有线程通过某一点后通知方法,而CyclicBarrier则适合让所有线程在同一点同时执行 2,CountdownLatch利用继承AQS的共享锁来进行线程的通知,利用CAS来进行--,而CyclicBarrier则利用 ReentrantLock的Condition来阻塞和通知线程



countdownlatch的计数器只能使用一次，而cyclicBarrier的计数器可以使用reset方法重置

cyclicBarrier能处理更为复杂的业务场景

## 9：锁升级

锁的4中状态：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态（级别从低到高）

（1）偏向锁->轻量级锁：

为什么要引入偏向锁？

因为经过HotSpot的作者大量的研究发现，大多数时候是不存在锁竞争的，常常是一个线程多次获得同一个锁，因此如果每次都要竞争锁会增大很多没有必要付出的代价，为了降低获取锁的代价，才引入的偏向锁。

偏向锁的升级

当线程1访问代码块并获取锁对象时，会在java对象头和栈帧中记录偏向的锁的threadID，因为偏向锁不会主动释放锁，因此以后线程1再次获取锁的时候，需要比较当前线程的threadID和Java对象头中的threadID是否一致，如果一致（还是线程1获取锁对象），则无需使用CAS来加锁、解锁；如果不一致（其他线程，如线程2要竞争锁对象，而偏向锁不会主动释放因此还是存储的线程1的threadID），那么需要查看Java对象头中记录的线程1是否存活，如果没有存活，那么锁对象被重置为无锁状态，其它线程（线程2）可以竞争将其设置为偏向锁；如果存活，那么立刻查找该线程（线程1）的栈帧信息，如果还是需要继续持有这个锁对象，那么暂停当前线程1，撤销偏向锁，升级为轻量级锁，如果线程1 不再使用该锁对象，那么将锁对象状态设为无锁状态，重新偏向新的线程。

2)   轻量级锁到重量级锁

线程1获取轻量级锁时会先把锁对象的对象头MarkWord复制一份到线程1的栈帧中创建的用于存储锁记录的空间（称为DisplacedMarkWord），然后使用CAS把对象头中的内容替换为线程1存储的锁记录（DisplacedMarkWord）的地址；

如果在线程1复制对象头的同时（在线程1CAS之前），线程2也准备获取锁，复制了对象头到线程2的锁记录空间中，但是在线程2CAS的时候，发现线程1已经把对象头换了，线程2的CAS失败，那么线程2就尝试使用自旋锁来等待线程1释放锁。

但是如果自旋的时间太长也不行，因为自旋是要消耗CPU的，因此自旋的次数是有限制的，比如10次或者100次，如果自旋次数到了线程1还没有释放锁，或者线程1还在执行，线程2还在自旋等待，这时又有一个线程3过来竞争这个锁对象，那么这个时候轻量级锁就会膨胀为重量级锁。重量级锁把除了拥有锁的线程都阻塞，防止CPU空转。

**注意：**为了避免无用的自旋，轻量级锁一旦膨胀为重量级锁就不会再降级为轻量级锁了；偏向锁升级为轻量级锁也不能再降级为偏向锁。一句话就是锁可以升级不可以降级，但是偏向锁状态可以被重置为无锁状态。

![img](https://img-blog.csdn.net/2018032217003676)

## 10：生产者和消费者问题







## 11：线程按序打印





## 12：ThreadLocal

ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来， ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set() 、 get() 、 remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal 方法后 最好手动调用remove() 方法。



## 13：丢包问题发生在哪一层，为什么？

网络层 

ping命令

ICMP协议



## 14：如何获取异步线程的返回结果



## 15：socket网络编程

!

# 操作系统：

## 1：文件的I/O方式

### 阻塞式文件I/O

阻塞式文件I/O模式是最普遍使用的文件I/O模式。大部分应用程序在对文件进行访问的时候使用的都是阻塞模式的I/O。 缺省情况下，标准输入输出读写，管道的读写、连接建立完成后的套接字都采用阻塞I/O 模式。如图14-1 所示，一旦进程期望读取数据，就调用
read/write函数，进程从调用这些函数开始，一直到返回这段时间内都处理阻塞状态。当recv正常返回时，进程继续其他操作。

![](https://pic.imgdb.cn/item/622b26c75baa1a80abf452ab.png)

这种模式的优点在于操作简单，但整个进程在等待过程中处于阻塞状态，不能申请到CPU执行其他操作。



### 非阻塞式文件I/O

如果设置某个文件IO操作为非阻塞I/O,即相当于告诉内核:如果当前没有数据可操作, 将不阻塞当前进程，而是立即返回一个错误信息。如图14-2所示为非阻塞I/O操作模型。使用非阻塞I/O方式虽然不阻塞当前进程，但需要反复尝试。例如，为了从文件中获取数据，当前进程需要反复调用read/recv函数直至读取到数据。

![](https://pic.imgdb.cn/item/622b27925baa1a80abf4c8c3.png)



### 多路复用I/O

多路复用方式仍然是以阻塞方式等待文件 IO 准备好，但其可以同时等待多个文件描述符，如果当前有一个或多个 socket 有状态发生变化 则从阻塞状态返回，转而处理该文件描述符 IO 操作，如图 14-3 所示。

多路复用技术一方面受限于阻塞的文件描述符数量的限制，另一方面，从系统角度来说，仍然只有一个进程与系统其他进程竞争资源 如果过量的文件 IO 操作必然影响当前服务性能。

![](https://pic.imgdb.cn/item/622b283b5baa1a80abf53136.png)





### 信号驱动I/O

前面3种模式都是以同步方式去获取数据，因此，内核提供了另一种异步数据处理方式，其让内核在文件描述符就绪后产生SIGIO 信号，通知用户进程数据或者空间准备好，如图 14-4所示，这种模式称为信号驱动异步 I/O模式。这种处理方式使得用户进程不需要重复询问内
核该文件描述符对象是否准备好，从而大大提高了当前进程效率。

![](https://pic.imgdb.cn/item/622b28bc5baa1a80abf57f74.png)







### 阻塞与非阻塞对比

在处理数据的传送与接收时，有阻塞和非阻塞两种操作方法。

1.  阻塞方式

    默认情况下 read/write 函数为阻塞方式，如果将 flag设置为0, recv/send函数也采用阻塞方式，即如果没有数据可操作，则该进程将被阻塞，当有数据时才继续执行并返回。

2.  非阻塞方式 

    如果没有数据可接收就立即返回 -1, 表示接收失败，并修改系统全局变量errno 的值为 EAGAIN 表示数据未准备好。









## 2：(socket 多路复用)select , poll ,epoll

### select( )

系统调用 select( )提供**轮循等待**的方式从多个文件描述符中获取状态变化后的情况 该函数声明如下

![](https://pic.imgdb.cn/item/622b2ae15baa1a80abf6c876.png)



![](https://pic.imgdb.cn/item/622b2b745baa1a80abf72672.png)



![](https://pic.imgdb.cn/item/622b2c505baa1a80abf7f08a.png)





**select机制的问题**

1. 每次调用select，都需要把`fd_set`集合从用户态拷贝到内核态，如果`fd_set`集合很大时，那这个开销也很大
2. 同时每次调用select都需要在内核遍历传递进来的所有`fd_set`，如果`fd_set`集合很大时，那这个开销也很大
3. 为了减少数据拷贝带来的性能损坏，内核对被监控的`fd_set`集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)

### poll( )

poll ppoll 函数可以实现比 select/pselect 函数更强大的功能，更细粒的等待时间。两函数声明如下：

![](https://pic.imgdb.cn/item/622b2d3b5baa1a80abf89c4b.png)

![](https://pic.imgdb.cn/item/622b2de85baa1a80abf91f4d.png)



poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。也就是说，poll只解决了上面的问题3，并没有解决问题1，2的性能开销问题。

### epoll( )

相对于select来说，epoll没有描述符个数限制，使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

epoll是Linux内核为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。

epoll除了提供select/poll那种IO事件的水平触发（Level Triggered）外，还提供了边缘触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。

**水平触发（LT）：**默认工作模式，即当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次通知此事件

**边缘触发（ET）：** 当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次通知此事件。（直到你做了某些操作导致该描述符变成未就绪状态了，也就是说边缘触发只在状态由未就绪变为就绪时只通知一次）。

![](https://pic.imgdb.cn/item/622b31165baa1a80abfb08a7.png)

epoll是Linux目前大规模网络并发程序开发的首选模型。在绝大多数情况下性能远超select和poll。目前流行的高性能web服务器Nginx正式依赖于epoll提供的高效网络套接字轮询服务。但是，在并发连接不高的情况下，多线程+阻塞I/O方式可能性能更好。



## 3：进程通信方式及优缺点

1、管道（pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

2、有名管道（named pipe）：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程之间的通信。
3、消息队列（message queue）：消息队列是消息的链表，存放在内核中并由消息队列表示符标示。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限制等缺点。
4、共享内存（shared memory）：共享内存就是映射一段内被其它进程所访问的内存，共享内存由一个进程创建，但是多个进程都可以访问。共享内存是最快的IPC，它是针对其它进程通信方式运行效率低的而专门设计的。它往往与其它通信机制。如信号量，配合使用，来实现进程间的同步和通信。
5、套接字（socket）：套接字也是进程间的通信机制，与其它通信机制不同的是，它可以用于不同机器间的进程通信。
6、信号（signal）：信号是一种比较复杂的通信方式，用于通知接受进程进程某个时间已经发生。
7、信号量（semaphore）：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁的机制，防止某进程正在访问共享资源时，其它进程也访问该资源。因此它主要作为不同进程或者同一进程之间不同线程之间同步的手段。



## 4：进程、线程和协程

### 一、进程

  进程，直观点说，保存在硬盘上的程序运行以后，会在内存空间里形成一个独立的内存体，这个内存体**有自己独立的地址空间，有自己的堆**，上级挂靠单位是操作系统。**操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位**

![在这里插入图片描述](https://img-blog.csdn.net/20150603133335514)



![](https://pic.imgdb.cn/item/6229e4845baa1a80ab2c558d.png)



![](https://pic.imgdb.cn/item/6229e4d05baa1a80ab2c9148.png)



### 二、线程

**线程，有时被称为轻量级进程(Lightweight Process，LWP），是操作系统调度（CPU调度）执行的最小单位**

![在这里插入图片描述](https://static.oschina.net/uploads/space/2015/0529/133750_ldwM_1863332.jpg)

![](https://pic.imgdb.cn/item/6229e6245baa1a80ab2d8246.png)

![](https://pic.imgdb.cn/item/6229e6f15baa1a80ab2e1833.png)



### 三：进程、线程区别与联系

【区别】：

调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位；

并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行；

拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。进程所维护的是程序所包含的资源（静态资源）， 如：地址空间，打开的文件句柄集，文件系统状态，信号处理handler等；线程所维护的运行相关的资源（动态资源），如：运行栈，调度相关的控制信息，待处理的信号集等；

系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。

![](https://pic.imgdb.cn/item/6229f3b55baa1a80ab3735ea.png)

【联系】：

一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；

资源分配给进程，同一进程的所有线程共享该进程的所有资源；

处理机分给线程，即真正在处理机上运行的是线程；

线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。

### 四：协程

![在这里插入图片描述](http://5b0988e595225.cdn.sohucs.com/images/20180622/6765e36cc4604fba897976638af03524.jpeg)

协程，是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

  子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。

  协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。

```python
def A():
    print '1'
    print '2'
    print '3'

def B():
    print 'x'
    print 'y'
    print 'z'
```

假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：1 2 x y 3 z。

 协程的特点在于是一个线程执行，那和多线程比，协程有何优势？

极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；

不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。








## 5：死锁及解决

**产生条件：**

1. 互斥：至少有一个资源必须处于非共享模式，即一次只有一个进程可使用。如果另一进程申请该资源，那么申请进程应等到该资源释放为止。
2. 占有并等待：—个进程应占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有。
3. 非抢占：资源不能被抢占，即资源只能被进程在完成任务后自愿释放。
4. 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有。

我们强调所有四个条件必须同时成立才会出现死锁。循环等待条件意味着占有并等待条件，这样四个条件并不完全独立

有四种处理死锁的策略：
1)忽略该问题。也许如果你忽略它，它也会忽略你。
2)检测死锁并恢复。让死锁发生，检测它们是否发生，一旦发生死锁，采取行动解决问题。
3)仔细对资源进行分配，动态地避免死锁。
4)通过破坏引起死锁的四个必要条件之一，防止死锁的产生

**解决办法：**



操作系统层面：鸵鸟算法（当做什么都没发生）

银行家算法（预防） 

语言层面：解决死锁问题的方法是：一种是用synchronized，一种是用Lock显式锁实现。

## 6：fork()和execve()

![](https://pic.imgdb.cn/item/6229ecb25baa1a80ab32475d.png)

Linux中，fork()函数用来创建子进程，执行一次返回两个值，父进程中，返回子进程PID，子进程中，返回0



execve()函数用于在当前进程的上下文中加载并运行一个新程序

![](https://pic.imgdb.cn/item/6229ede85baa1a80ab333cc3.png)







## 7：CPU调度算法

**先到先服务调度算法（first-come,first-served (FCFS)**

**最短作业优先调度算法（shortest-job-first(SJF)schedulingalgorithm）**

**优先级调度算法（priority scheduling algorithm）**

**轮转法(round-robin,RR)**

**多级队列调度算法（multilevel queue scheduling algorithm）**

**多级反馈队列调度算法（multilevel feedback queue scheduling algorithm）**

![这里写图片描述](https://img-blog.csdn.net/20170407165752062?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzYxNjk0NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 8：虚拟内存(段页式存储)

虚拟内存提供了三个重要的能力:

1.  它将主存看成是一一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
2.  它为每个进程提供了一致的地址空间，从而简化了内存管理。
3.  它保护了每个进程的地址空间不被其他进程破坏。



![](https://pic.imgdb.cn/item/6229f03e5baa1a80ab34ec70.png)

在任意时刻，虚拟页面的集合都分为三个不相交的子集:
●未分配的: VM系统还未分配(或者创建)的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
●缓存的:当前已缓存在物理内存中的已分配页。
●未缓存的:未缓存在物理内存中的已分配页。



页表：

![](https://pic.imgdb.cn/item/6229f12a5baa1a80ab358556.png)



![](https://pic.imgdb.cn/item/6229f1ba5baa1a80ab35e447.png)



段页存储：把虚拟地址空间先分段，再分页，方便管理和寻址

![](https://pic.imgdb.cn/item/6229f3115baa1a80ab36c70c.png)

分段和分页的实现本质上是不同的：页面是定长的而段不是。







## 9：线程间通信方式

a) 互斥量(Mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。

b) 信号量(Semphares)：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。

c) 事件(Event):Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。



## 10：孤儿进程和僵尸进程

当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被保持在一-种已终止的状态中，直到被它的父进程回收(reaped)。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了但还未被回收的进程称为**僵尸进程**(zombie)。

如果一个父进程终止了，内核会安排init进程成为它的**孤儿进程**的养父。init 进程的PID为1，是在系统启动时由内核创建的，它不会终止，是所有进程的祖先。如果父进程没有回收它的僵死子进程就终止了，那么内核会安排init进程去回收它们。不过，长时间运行的程序，比如shell或者服务器，总是应该回收它们的僵死子进程。即使僵死子进程没有运行，它们仍然消耗系统的内存资源。

# Spring：

## 1：IOC



![img](https://img-blog.csdnimg.cn/20200328111026924.jpeg)

![img](https://img-blog.csdnimg.cn/20200328111107625.jpeg)



IOC解决高耦合：

![img](https://img-blog.csdnimg.cn/20200328111142617.jpeg)





## 2：AOP

#### JDK动态代理

通过委托类的引用**反射机制**（`InvocationHandler`与`Proxy`）来获取其接口，实现`invoke`方法来达到通过接口调用具体委托类的实现的目的；

使用时代码只需要使用接口类，而调用接口类中的方法，执行的则是委托类的具体实现；

反射机制动态生成代码，编译过程中产生新的类并重新加载到JVM；

#### CGLib动态代理

当**没有接口来进行代理**时，JDK动态代理可以替换为CGLib（*Code Generation Library*，一个[开源项目](https://github.com/cglib/cglib)）动态代理；

CGLib通过字节码技术为一个类创建子类，通过**拦截器** *Interceptor*将父类调用放在子类执行；

由于生成的子类是被`extends`的，因此不能对被`final`修饰的类进行代理；

动态生成代码，性能比JDK动态代理好；

## 3：解决循环依赖

循环依赖-->循环引用。--->即2个或以上bean 互相持有对方，最终形成闭环

![img](https://img-blog.csdn.net/20180330094859991?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MzgxODU1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



Spring是先将Bean对象实例化【依赖无参构造函数】--->再设置对象属性的

那么我们要解决循环引用也应该从初始化过程着手，对于单例来说，在Spring容器整个生命周期内，有且只有一个对象，所以很容易想到这个对象应该存在Cache中，Spring为了解决单例的循环依赖问题，使用了**三级缓存**。

这三级缓存分别指：

 singletonFactories ： 单例对象工厂的cache 
 earlySingletonObjects ：提前暴光的单例对象的Cache 。【用于检测循环引用，与singletonFactories互斥】
 singletonObjects：单例对象的cache

## 4：对象生命周期

![img](https://pic4.zhimg.com/80/v2-baaf7d50702f6d0935820b9415ff364c_1440w.jpg?source=1940ef5c)



作者：大闲人柴毛毛
链接：https://www.zhihu.com/question/38597960/answer/247019950
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



**1. 实例化Bean**

对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。 
对于ApplicationContext容器，当容器启动结束后，便实例化所有的bean。 
容器通过获取BeanDefinition对象中的信息进行实例化。并且这一步仅仅是简单的实例化，并未进行依赖注入。 
实例化对象被包装在BeanWrapper对象中，BeanWrapper提供了设置对象属性的接口，从而避免了使用反射机制设置属性。

**2. 设置对象属性（依赖注入）**

实例化后的对象被封装在BeanWrapper对象中，并且此时对象仍然是一个原生的状态，并没有进行依赖注入。 
紧接着，Spring根据BeanDefinition中的信息进行依赖注入。 
并且通过BeanWrapper提供的设置属性的接口完成依赖注入。

**3. 注入Aware接口**

紧接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给bean。

**4. BeanPostProcessor**

当经过上述几个步骤后，bean对象已经被正确构造，但如果你想要对象被使用前再进行一些自定义的处理，就可以通过BeanPostProcessor接口实现。 
该接口提供了两个函数：

- postProcessBeforeInitialzation( Object bean, String beanName ) 
  当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。 
  这个函数会先于InitialzationBean执行，因此称为前置处理。 
  所有Aware接口的注入就是在这一步完成的。
- postProcessAfterInitialzation( Object bean, String beanName ) 
  当前正在初始化的bean对象会被传递进来，我们就可以对这个bean作任何处理。 
  这个函数会在InitialzationBean完成后执行，因此称为后置处理。

**5. InitializingBean与init-method**

当BeanPostProcessor的前置处理完成后就会进入本阶段。 
InitializingBean接口只有一个函数：

- afterPropertiesSet()

这一阶段也可以在bean正式构造完成前增加我们自定义的逻辑，但它与前置处理不同，由于该函数并不会把当前bean对象传进来，因此在这一步没办法处理对象本身，只能增加一些额外的逻辑。 
若要使用它，我们需要让bean实现该接口，并把要增加的逻辑写在该函数中。然后Spring会在前置处理完成后检测当前bean是否实现了该接口，并执行afterPropertiesSet函数。

当然，Spring为了降低对客户代码的侵入性，给bean的配置提供了init-method属性，该属性指定了在这一阶段需要执行的函数名。Spring便会在初始化阶段执行我们设置的函数。init-method本质上仍然使用了InitializingBean接口。

**6. DisposableBean和destroy-method**







对象实例化

设置对象的属性

Aware接口

BeanPostProcessor前置处理

initializingBean

init-method

BeanPostProcessor后置处理

--------到这里Bean对象创建完成

disposableBean

destroy-method





## 5：事务隔离级别

**Spring事务隔离级别比数据库事务隔离级别多一个default**

**1) DEFAULT （默认）**
这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与JDBC的隔离级别相对应。

**2) READ_UNCOMMITTED （读未提交）**
这是事务最低的隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读。

**3) READ_COMMITTED （读已提交）**
保证一个事务修改的数据提交后才能被另外一个事务读取，另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻像读。

**4) REPEATABLE_READ （可重复读）**
这种事务隔离级别可以防止脏读、不可重复读，但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了不可重复读。

**5) SERIALIZABLE（串行化）**
这是花费最高代价但是最可靠的事务隔离级别，事务被处理为顺序执行。除了防止脏读、不可重复读外，还避免了幻像读。



## **6：Spring事务传播属性**

**1) required（默认属性）**
如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。
被设置成这个级别时，会为每一个被调用的方法创建一个逻辑事务域。如果前面的方法已经创建了事务，那么后面的方法支持当前的事务，如果当前没有事务会重新建立事务。

**2) Mandatory**
支持当前事务，如果当前没有事务，就抛出异常。

**3) Never**
以非事务方式执行，如果当前存在事务，则抛出异常。

**4) Not_supports**
以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

**5) requires_new**
新建事务，如果当前存在事务，把当前事务挂起。

**6) Supports**
支持当前事务，如果当前没有事务，就以非事务方式执行。

**7) Nested**
支持当前事务，新增Savepoint点，与当前事务同步提交或回滚。
嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。



## 7：动态代理和静态代理

静态代理：
由程序员创建或由特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。动态代理类：在程序运行时，运用反射机制动态创建而成。
由此可见，代理类可以为委托类预处理消息、把消息转发给委托类和事后处理消息等。

动态代理：

与静态代理类对照的是动态代理类，动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码。动态代理类不仅简化了编程工作，而且提高了软件系统的可扩展性，因为Java 反射机制可以生成任意类型的动态代理类。java.lang.reflect 包中的Proxy类和InvocationHandler 接口提供了生成动态代理类的能力。

## 8：Spring用到的设计模式

## 9：SpringMVC的流程

## 10：Spring框架中的Bean是线程安全的吗？如果不安全，如何处理

Spring容器本身没有提供Bean的线程安全策略，因此，也可以说Spring容器中的Bean不是线程安全的。



要处理线程安全问题，就要分情况来讨论



Spring中的作用域：1、sington 2、prototype：为每个B额按请求创建实例 3、request 4、session 5、global-session 全局作用域



对于线程安全问题：

1：对于prototype作用域，每次都是生成一个新的对象，所以不存在线程安全问题

2：sington作用域：默认就是线程不安全的，但是对于开发中大部分的Bean，其实是无状态的，不需要保证线程安全

但是如果要保证线程安全，可以将Bean的作用域改为prototype，比如像Model，View，另外还可以采用ThreadLocal来解决



## 11：SpringMVC中的控制器是不是单例模式，如果是，如何保证线程安全

控制器是单例模式

单例模式下就会有线程安全问题

Spring中保证线程安全的方法：
 1、将scope设置成非sington，prototype，request

 2、**最好的方式是将控制器（controller）设置成无状态**









# Redis Nginx：

## 1：Redis数据结构与对象

### 简单动态字符串

Redis 没有直接使用 语言传统的字符串表示（以空字符结尾的字符数组，以下简称C字符串），而是自己构建了一种名为简单动态字符串 (simple dynamic string, SDS) 的抽象类型，并将 SOS 用作 Redis 的默认字符串表示。

![](https://pic.imgdb.cn/item/622f43e15baa1a80abde2af6.png)



除了用来保存数据库中的字符串值之外， SOS 还被用作缓冲区 (buffer) 

![](https://pic.imgdb.cn/item/622f445a5baa1a80abde67b1.png)

SDS 遵循 字符串以空字符结尾的惯例，保存空字符的 字节空间不计算在 SDS的len 属性里面

#### SDS与C字符串的区别

##### 常数复杂度获取字符串长度

SDS有一个len属性

##### 杜绝缓冲区溢出

与C字符串不同， SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当 SDS-API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求，如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改
操作，所以使用 SOS 既不需要手动修改 SOS 的空间大小，也不会出现前面所说的缓冲区溢出问题。

##### 减少修改字符串时带来的内存重分配次数

为了避免C字符串的频繁修改内存缺陷， SDS 通过未使用空间解除了字符串长度和底层数组长度之间的关联：在 SDS 中， buf 数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，而这些字节的数量就由 SDS free 属性记录。
通过未使用空间， SDS 实现了**空间预分配**和**惰性空间释放**两种优化策略。

空间预分配用于优化 SDS 的字符串增长操作：当 SDS的API 对一个 SDS 进行修改，并且需要对 SDS 进行空间扩展的时候，程序不仅会为 SDS 分配修改所必须要的空间，还会为SDS分配额外的未使用空间。

惰性空间释放用于优化 SDS 的字符串缩短操作：当 SDS的API 需要缩短 SDS 保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用 free 属性将这些字节的数量记录起来，并等待将来使用。



##### 二进制安全

C字符串中的字符必须符合某种编码（比如 ASCil), 并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读人的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。

![](https://pic.imgdb.cn/item/622f47df5baa1a80abe043a7.png)



##### 兼容部分C字符串函数

![](https://pic.imgdb.cn/item/622f48265baa1a80abe077ca.png)



#### SDS-API

![](https://pic.imgdb.cn/item/622f48a05baa1a80abe0b214.png)





![](https://pic.imgdb.cn/item/622f48b25baa1a80abe0ba7e.png)



### 链表

链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。

#### 链表和链表节点的实现

![](https://pic.imgdb.cn/item/622f49bd5baa1a80abe17fbf.png)



![](https://pic.imgdb.cn/item/622f49d85baa1a80abe193ea.png)



![](https://pic.imgdb.cn/item/622f4a0f5baa1a80abe1bbd4.png)



#### 链表和链表节点的 API

![](https://pic.imgdb.cn/item/622f4aa15baa1a80abe27a6f.png)

##### 重点回顾

![](https://pic.imgdb.cn/item/622f4ab65baa1a80abe29015.png)



### 字典

字典，又称为符号表 (symbol table) 、关联数组 (associative array) 或映射 ,一种用于保存键值对 (key-value pair) 的抽象数据结构
在字典中，一个键 (key) 可以和一个值 (value) 进行关联（或者说将键映射为值），这些关联的键和值就称为键值对
字典中的每个键都是独一无二的，程序可以在字典中根据键查找与之关联的值，或者通过键来更新值，又或者根据键来删除整个键值对



Redis 的字典使用哈希表作为底层实现，一个哈希表里面可以有**多个哈希表节点**，而每个哈希表节点就保存了字典中的一个键值对。

![](https://pic.imgdb.cn/item/622f4c2e5baa1a80abe3fa26.png)



![](https://pic.imgdb.cn/item/622f4c5f5baa1a80abe42c36.png)



![](https://pic.imgdb.cn/item/622f4ca65baa1a80abe480c8.png)



Redis 的哈希表使用链地址法 (separate chaining) 来解决键冲突

随着操作的不断执行，哈希表保存的键值对会逐渐地增多或者减少，为了让哈希表的负载因子 (load factor) 维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。
扩展和收缩哈希表的工作可以通过执行 rehash (重新散列）操作来完成

![](https://pic.imgdb.cn/item/622f4d205baa1a80abe4edea.png)



![](https://pic.imgdb.cn/item/622f4d645baa1a80abe5241a.png)





### 跳跃表

跳跃表 (skiplist) 是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。
跳跃表支持平均 O(logN) 、最坏 O(N) 复杂度的节点查找，还可以通过顺序性操作来批量处理节点。
在大部分情况下，跳跃表的效率可以和平衡树相媳美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。

Redis 使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员 (member) 是比较长的字符串时， Redis 就会使用跳跃表来作为有序集合键的底层实现。

#### 跳跃表的实现

![](https://pic.imgdb.cn/item/622f4ee15baa1a80abe61671.png)



![](https://pic.imgdb.cn/item/622f4fa05baa1a80abe64d5c.png)



![](https://pic.imgdb.cn/item/622f4fb65baa1a80abe65107.png)



##### 跳跃表节点

![](https://pic.imgdb.cn/item/622f4fef5baa1a80abe65ce6.png)



![](https://pic.imgdb.cn/item/622f50455baa1a80abe6815d.png)



![](https://pic.imgdb.cn/item/622f50a55baa1a80abe69f3b.png)



![](https://pic.imgdb.cn/item/622f50d65baa1a80abe6b0a9.png)



### 整数集合

![](https://pic.imgdb.cn/item/622f515a5baa1a80abe6dcd1.png)



![](https://pic.imgdb.cn/item/622f51945baa1a80abe6f238.png)





### 压缩列表

​		  压缩列表 (ziplist) 是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis会使用压缩列表来做列表键的底层实现。

![](https://pic.imgdb.cn/item/622ff8f15baa1a80ab293499.png)





### 对象

​          在前面的数个章节里，我们陆续介绍了 Redis 用到的所有主要数据结构，比如简单动态字符串 (SDS) 、双端链表、字典、压缩列表、整数集合等等。
​		  Redis 并没有直接使用这些数据结构来实现键值对数据库，而是基千这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每种对象都用到了至少一种我们前面所介绍的数据结构。
​		  通过这五种不同类型的对象， Redis 可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，我们可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。
​		  除此之外， Redis 的对象系统还实现了基于引用计数技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放；另外， Redis 还通过引用计数技术实现了对象共享机制，这一机制可以在适当的条件下，通过让多个数据库键共享同一
个对象来节约内存。
​		  最后， Redis 的对象带有访问时间记录信息，该信息可以用于计算数据库键的空转时长，在服务器启用了 maxmemory 功能的情况下，空转时长较大的那些键可能会优先被服务器删除。



#### 对象的类型和编码

​		  Redis 使用对象来表示数据库中的键和值，每次当我们在 Redis 的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。

![](https://pic.imgdb.cn/item/622ffb0a5baa1a80ab2a0ba4.png)



![](https://pic.imgdb.cn/item/622ffb5a5baa1a80ab2a2baa.png)



对象的 ptr 指针指向对象的底层实现数据结构，而这些数据结构由对象的 encoding属性决定。
encoding 属性记录了对象所使用的编码，也即是说这个对象使用了什么数据结构作为对象的底层实现，这个属性的值可以是表 8-3 列出的常量的其中一个。

![](https://pic.imgdb.cn/item/622ffc1e5baa1a80ab2a70a4.png)



![](https://pic.imgdb.cn/item/622ffc575baa1a80ab2a86ef.png)



>   使用 OBJECT ENCODING 命令可以查看一个数据库键的值对象的编码：

![](https://pic.imgdb.cn/item/622ffcb35baa1a80ab2aa588.png)





## 2：Redis 5种基本数据类型

### 字符串对象(String)

![](https://pic.imgdb.cn/item/622ffe0e5baa1a80ab2b4bd0.png)



如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于 32 字节，那么字符串对象将使用一个简单动态字符串 (SDS) 来保存这个字符串值，并将对象的编码设置为raw

如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于 32 字节，那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。

![](https://pic.imgdb.cn/item/622ffee45baa1a80ab2bb474.png)



![](https://pic.imgdb.cn/item/622fff395baa1a80ab2bcfca.png)



![](https://pic.imgdb.cn/item/622fff9a5baa1a80ab2bfe90.png)



### 列表对象(List)

列表对象的编码可以是 ziplist 或者 linkedlist



### 哈希对象(Hash)

哈希对象的编码可以是 ziplist 或者 hashtable



### 集合对象(Set)

集合对象的编码可以是 intset 或者 hashtable



### 有序集合对象(Zset)

有序集合的编码可以是 ziplist 或者 skiplist。

ziplist 编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员 (member), 而第二个元素则保存元素的分值 (score) 。压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾的方向。

zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的 object 属性保存了元素的成员，而跳跃表节点的score 属性则保存了元素的分值。通过这个跳跃表，程序可以对有序集合进行范围型操作。比如 ZRANK ZRANGE 等命令就是基于跳跃表 API 来实现的。

除此之外， zset 结构中的 diet 字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素：字典的键保存了元素的成员，而字典的值则保存了元素的分值。通过这个字典，程序可以用 0(1) 复杂度查找给定成员的分值， ZSCORE命令就是根据这一特性实现的，而很多其他有序集合命令都在实现的内部用到了这一特性。

![](https://pic.imgdb.cn/item/623001dd5baa1a80ab2d10cd.png)



![](https://pic.imgdb.cn/item/6230020c5baa1a80ab2d2af9.png)



因为C语言并不具备自动内存回收功能，所以 Redis 在自己的对象系统中构建了一个引用计数 (reference counting) 技术实现的内存回收机制，通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。



重点回顾：

![](https://pic.imgdb.cn/item/6230027d5baa1a80ab2d72cf.png)





## 3：Redis数据库

本章将对 Redis 服务器的数据库实现进行详细介绍，说明服务器保存数据库的方法，客户端切换数据库的方法，数据库保存键值对的方法，以及针对数据库的添加、删除、查看、更新操作的实现方法等。除此之外，本章还会说明服务器保存键的过期时间的方法，以及服
务器自动删除过期键的方法

### 服务器中的数据库

![](https://pic.imgdb.cn/item/623006425baa1a80ab2f4692.png)



![](https://pic.imgdb.cn/item/6230066a5baa1a80ab2f56b8.png)



### 切换数据库

每个 Redis 客户端都有自己的目标数据库，每当客户端执行数据库写命令或者数据库读命令的时候，目标数据库就会成为这些命令的操作对象。默认情况下， Redis 客户端的目标数据库为 0号数据库，但客户端可以通过执行SELECT 命令来切换目标数据库。

![](https://pic.imgdb.cn/item/623006e65baa1a80ab2fa4e0.png)



在服务器内部，客户端状态 redisClie吐结构的 db 属性记录了客户端当前的目标数据库，这个属性是一个指向 redisDb 结构的指针

![](https://pic.imgdb.cn/item/623007475baa1a80ab2fd2fc.png)



### 数据库键空间



### 设置键的生存时间或过期时间



## 1：redis为什么快

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路I/O复用模型，非阻塞IO  （epoll）





## 3：持久化方式

**RDB 持久化**
将某个时间点的所有数据都存放到硬盘上。
可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。
如果系统发生故障，将会丢失最后一次创建快照之后的数据。
如果数据量很大，保存快照的时间会很长。
**AOF 持久化**
将写命令添加到 AOF 文件（Append Only File）的末尾。
使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：
选项同步频率always每个写命令都同步everysec每秒同步一次no让操作系统来决定何时同步
**always** 选项会严重减低服务器的性能；
**everysec** 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；
**no** 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量
随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

## 4：缓存过期淘汰策略

volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰
volatile-random从已设置过期时间的数据集中任意选择数据淘汰
allkeys-lru从所有数据集中挑选最近最少使用的数据淘汰
allkeys-random从所有数据集中任意选择数据进行淘汰
noeviction禁止驱逐数据

## 5：与mysql数据一致性

![img](https://img-blog.csdnimg.cn/20190701200701755.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Rpd2Vpa2FuZw==,size_16,color_FFFFFF,t_70)

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致。



1. 先更新数据库，再更新缓存
2. 先删除缓存，再更新数据库
3. 先更新数据库，再删除缓存











## 6：zset底层实现

跳跃表：



与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

## 7：缓存穿透、缓存击穿、缓存雪崩

缓存穿透：就是客户持续向服务器发起对不存在服务器中数据的请求。客户先在Redis中查询，查询不到后去数据库中查询。



缓存击穿：就是一个很热门的数据，突然失效，大量请求到服务器数据库中



缓存雪崩：就是大量数据同一时间失效。



打个比方，你是个很有钱的人，开满了百度云，腾讯视频各种杂七杂八的会员，但是你就是没有netflix的会员，然后你把这些账号和密码发布到一个你自己做的网站上，然后你有一个朋友每过十秒钟就查询你的网站，发现你的网站没有Netflix的会员后打电话向你要。你就相当于是个数据库，网站就是Redis。这就是缓存穿透。
大家都喜欢看腾讯视频上的《水果传》，但是你的会员突然到期了，大家在你的网站上看不到腾讯视频的账号，纷纷打电话向你询问，这就是缓存击穿
你的各种会员突然同一时间都失效了，那这就是缓存雪崩了。

放心，肯定有办法解决的。
**缓存穿透：**
      1.接口层增加校验，对传参进行个校验，比如说我们的id是从1开始的，那么id<=0的直接拦截；
      2.缓存中取不到的数据，在数据库中也没有取到，这时可以将key-value对写为key-null，这样可以防止攻击用    户反复用同一个id暴力攻击

​       3布隆过滤器

**缓存击穿**：
1：最好的办法就是设置热点数据永不过期，拿到刚才的比方里，那就是你买腾讯一个永久会员

**2：分布式锁**

在DB往数据库写入数据时，加锁，防止并发



**缓存雪崩：**

1.缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2.如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。





## 8：nginx作用

反向代理

动静分离

负载均衡

## 9：nginx负载均衡

**1、轮询（默认）**

**2、指定权重**

**3、IP绑定 ip_hash**



## 10：一致性哈希

通过哈希环解决





哈希环偏移：




通过虚拟地址解决





## 11：布隆过滤器原理







## 12：如何设计一个分布式锁，如何对锁性能进行优化

分布式锁的本质：就是所有进程都能访问到的一个地方，设置一个锁资源，让这些进程都来竞争锁资源，数据库，redis，zookeeper。通常对于分布式锁，会要求响应快、性能高、与业务无关。



Redis实现分布式锁：

SETNX key value：当key不存在时，将key设置为value，并返回1.如果key存在，就返回0



EXPIRE key locktime：设置key的有效时长。

DEL key：删除

GETSET key value：先GET，再SET，先返回key'对应的值，如果没有就返回空，然后将key设为value



1、最简单的分布式锁：SETNX 加锁，DEL解锁

```java
public boolean tryLock(RedisConnection coon){
    if(coon.SETNX("mykey","1")==1){
        return true;
    }else{
        return false;
    }
}
```



## 13：Redis如何配置Key的过期时间？他的实现原理是什么？

redis设置key的过期时间：1、EXPIRE 2、SETEX

实现原理：

1、定期删除，每隔一段时间，执行一次删除过期key的操作

2、懒汉式删除：当使用get，getset等指令去获取数据时，判断key是否过期。过期后，就把key删除，再执行后面的操作

redis是将两种方式结合使用

## 14：redis数据类型的底层



Redis中的string，key是sds类型，而value类型也是sds类型（所以通过type查看都是string），但**sds底层实现（通过命令encoding object [key]）查看)则有int、raw、embstr**，表示的是Redis底层的真实数据结构，在Redis中称为**encoding**









# Linux：



## 1：常见命令

* 搜索进程ID：`ps -ef | grep <进程名>`，`-e`相当于`-a`是全部列出，`-f`是显示UID等；
* 任务管理器：`top`；
* 查看CPU ：vmstat -n
* 内存使用情况：`free -m`；
* 统计：`wc`，统计单词个数使用`grep <单词> <文件地址> ｜ wc -o`；
* 修改用户权限：`chmod`；
* 设置进程优先级：`nice -n <优先级，越小优先级越高> bash`（开新bash运行），`renice -n <有年纪> -p <进程ID> -u <用户>`（修改进程优先级）；





## 2：孤儿进程和僵尸进程

**孤儿进程**

一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。

孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。

由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。

**僵尸进程**

一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。

僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。

系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。

要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。



## 3：通过进程id查看端口，通过端口号进程 id？

通过进程id查看占用的端口:


netstat -nap | grep 进程id
通过端口号查看占用的进程id :

netstat -nap | grep 端口号



## 4：Linux查询连接数



一、查看哪些IP连接本机

netstat -an

二、查看TCP连接数

1)统计80端口连接数
netstat -nat|grep -i "80"|wc -l

2）统计httpd协议连接数
ps -ef|grep httpd|wc -l





## 5：如何查看占用内存比较多的进程？

ps aux | sort -k4nr | head -N



# 设计模式：

## 1：单例

```java
//饿汉式(静态变量)

class Singleton {
   
   //1. 构造器私有化, 外部能new
   private Singleton() {
      
   }
   
   //2.本类内部创建对象实例
   private final static Singleton instance = new Singleton();
   
   //3. 提供一个公有的静态方法，返回实例对象
   public static Singleton getInstance() {
      return instance;
   }
   
}
```



```java
class Singleton {
   private static Singleton instance;
   
   private Singleton() {}
   
   //提供一个静态的公有方法，当使用到该方法时，才去创建 instance
   //即懒汉式
   public static Singleton getInstance() {
      if(instance == null) {
         instance = new Singleton();
      }
      return instance;
   }
}
```



```java
// 静态内部类完成， 推荐使用
class Singleton {
   private static volatile Singleton instance;
   
   //构造器私有化
   private Singleton() {}
   
   //写一个静态内部类,该类中有一个静态属性 Singleton
   private static class SingletonInstance {
      private static final Singleton INSTANCE = new Singleton(); 
   }
   
   //提供一个静态的公有方法，直接返回SingletonInstance.INSTANCE
   
   public static synchronized Singleton getInstance() {
      
      return SingletonInstance.INSTANCE;
   }
}
```

```java
//双端锁+volatile
public class SingletonTest09 {
    private SingletonTest09(){}
    
    private static volatile SingletonTest09 instace;
    
    public static SingletonTest09 getInstance(){
        if (instace==null){
            synchronized (SingletonTest09.class){
                if (instace==null){
                    instace=new SingletonTest09();
                }
            }
        }
        
        return instace;
    }
    
}
```



```java
//使用枚举，可以实现单例, 推荐
enum Singleton {
   INSTANCE; //属性
   
}
```





## 2：工厂方法

定义创建对象的接口，让子类决定实例化哪种工厂类，解决接口选择问题，扩展性高：

```java
// 定义接口
public interface Shape {
    void draw();
}

// 定义实现
public class Rectangle implements Shape {
    @Override
    public void draw() { /*draw rectangle*/ }
}

// 定义实现
public class Circle implements Shape {
    @Override
    public void draw() { /*draw circle*/ }
}

// 定义工厂
public class ShapeFactory {
    public Shape getShape(String shapeType) {
        switch(shapeType) {
            case "rectangle":
                return new Rectangle();
            case "circle":
                return new Circle();
            default:
                return null;
        }
    }
}
```



## 3：抽象工厂

生产工厂的工厂：

```java
// 定义接口1
public interface Shape {
    void draw();
}

// 定义接口1实现
public class Rectangle implements Shape {
    @Override
    public void draw() { /*draw rectangle*/ }
}

// 定义接口1实现
public class Circle implements Shape {
    @Override
    public void draw() { /*draw circle*/ }
}

// 定义接口2
public interface Color {
    void fill();
}

// 定义接口2实现
public class Red implements Color {
    @Override
    public void fill() { /*fill red*/ }
}

// 定义接口2实现
public class Green implements Color {
    @Override
    public void fill() { /*fill green*/ }
}

// 定义抽象工厂
public abstract class AbstractFactory {
    public abstract Shape getShape(String shapeType);
    public abstract Color getColor(String colorType);
}

// 扩展抽象工厂，生成实体类对象
public class ShapeFactory extends AbstractFactory {
    @Override
    public Shape getShape(String shapeType) {
        switch(shapeType) {
            case "rectangle":
                return new Rectangle();
            case "circle":
                return new Circle();
            default:
                return null;
        }
    }
    
    @Override
    public Color getColor(String colorType) {
        return null;
    }
}

// 工厂生成器
public class FactoryProducer {
    public static AbstractFactory getFactory(String factoryType) {
        switch(factoryType){
            case "shape":
                return new ShapeFactory();
            case "color":
                return new ColorFactory();
            default:
                return null;
        }
    }
}
```



-   工厂方法：多个工厂类，一个产品抽象类，利用多态创建不同的产品对象，避免了大量的if-else判断。
-   抽象工厂：多个工厂类，多个产品抽象类，产品子类分组，同一个工厂实现类创建同组中的不同产品，减少了工厂子类的数量。



工厂模式就是为了**方便创建同一接口定义的具有复杂参数和初始化步骤的不同对象**。工厂模式一般用来创建复杂对象。只需用new就可以创建成功的简单对象，无需使用工厂模式，否则会增加系统的复杂度。





## 4：适配器模式

让不兼容的类可以相互工作：

```java
// 兼容位置
public interface MobilePhone {
    public void charge(V5 v5){ /*需要使用5V*/ }
}

// 兼容来源
public class V220 {
    public void provide220V( /*提供220V*/ )
}

// 兼容目标
public interface V5 {
    public void provide5V();
}

// 适配器
public class Adapter implements V5 {
    private V220 v220;
    
    public Adapter(V220 v220) {
        this.v220 = v220;
    }
    
    @Override 
    public void provide5V() {
        this.v220.provide220V();
        /*220V转5V的行为*/
    }
}

// 使用
mobilePhone.charge(new Adapter(new V220()));
```





## 5：建造者模式

解决复杂对象创建过程：

```java
public class User {
    // 类内字段都为final
    private final String firstName;     // 必传参数
    private final String lastName;      // 必传参数
    private final int age;              // 可选参数
    private final String phone;         // 可选参数
    private final String address;       // 可选参数

    // 构造函数私有，参数为builder
    private User(UserBuilder builder) {
        this.firstName = builder.firstName;
        this.lastName = builder.lastName;
        this.age = builder.age;
        this.phone = builder.phone;
        this.address = builder.address;
    }

    public String getFirstName() {
        return firstName;
    }

    public String getLastName() {
        return lastName;
    }

    public int getAge() {
        return age;
    }

    public String getPhone() {
        return phone;
    }

    public String getAddress() {
        return address;
    }

    // 建造者为静态内部类
    public static class UserBuilder {
        // 必选参数为final
        private final String firstName;
        private final String lastName;
        private int age;
        private String phone;
        private String address;

        // 必选参数在构造builder时就需要提供
        public UserBuilder(String firstName, String lastName) {
            this.firstName = firstName;
            this.lastName = lastName;
        }

        // 其他参数可选择性使用
        public UserBuilder age(int age) {
            this.age = age;
            return this;
        }
        public UserBuilder phone(String phone) {
            this.phone = phone;
            return this;
        }
        public UserBuilder address(String address) {
            this.address = address;
            return this;
        }
        
        public User build() {
            return new User(this);
        }
    }
}

// 具体使用
User user = new User.UserBuilder("firstName", "lastName").age(10).build();
```







# 场景题

## 1：海量数据下，如何快速查找一条记录



## 2：微服务介绍





## 3：敏感词过滤

字符串匹配算法

KMP算法

trie树（字典树），共享字符串的公共前缀



## 4：如何只用2GB的内存从20亿/40亿/80亿个整数中找出出现次数最多的数



分治法，哈希映射



## 5：如何判断一个数是否在40亿个整数中

bitmap思想，位图法



## 6：请你说说海量日志按ip出现次数排序

IP地址最多有2^32=4G种取值可能，所以不能完全加载到内存中。 
可以考虑分而治之的策略，按照IP地址的hash(IP)%1024值，将海量日志存储到1024个小文件中。每个小文件最多包含4M个IP地址。 
对于每个小文件，可以构建一个IP作为key，出现次数作为value的hash_map，并记录当前出现次数最多的1个IP地址。 
有了1024个小文件中的出现次数最多的IP，我们就可以轻松得到总体上出现次数最多的IP。 